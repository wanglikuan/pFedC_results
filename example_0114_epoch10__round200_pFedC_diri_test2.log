2022-01-14 22:23:26:INFO:-------------Round number: 0-------------
2022-01-14 22:23:26:INFO:-------------Sending models-------------
2022-01-14 22:23:26:INFO:-------------Evaluating models-------------
2022-01-14 22:23:26:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:23:26:INFO:Accuracy = [0.893455098934551, 0.9147640791476408, 0.878016960208741, 0.9130245705588171, 0.9254185692541856, 0.07653837790824092, 0.10219612959338986, 0.12198303979125896, 0.10437051532941943, 0.8804087845183736]
2022-01-14 22:23:26:INFO:Loss = [0.6699720200934496, 0.6503740993757097, 0.6630385297618501, 0.6528492484773908, 0.6616784489188513, 0.7392249353089055, 0.7397243823142486, 0.7396344595511184, 0.7461297097323277, 0.6709170513216323]
2022-01-14 22:23:26:INFO:-------------Training local models-------------
2022-01-14 22:23:58:INFO:-------------Aggregating local models-------------
2022-01-14 22:23:59:INFO:-------------Round number: 1-------------
2022-01-14 22:23:59:INFO:-------------Sending models-------------
2022-01-14 22:23:59:INFO:-------------Evaluating models-------------
2022-01-14 22:23:59:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:23:59:INFO:Accuracy = [0.8417047184170472, 0.8873668188736682, 0.8614916286149162, 0.8867145031528593, 0.8586649271580779, 0.8310502283105022, 0.8317025440313112, 0.8043052837573386, 0.852576647097195, 0.6927592954990215]
2022-01-14 22:23:59:INFO:Loss = [0.4527441736348791, 0.4908235423699439, 0.5173093215243457, 0.4504228402808014, 0.476132203986215, 0.556700100151449, 0.532781132610499, 0.5486598701859641, 0.5135741785855547, 0.6330705212105562]
2022-01-14 22:23:59:INFO:-------------Training local models-------------
2022-01-14 22:24:31:INFO:-------------Aggregating local models-------------
2022-01-14 22:24:31:INFO:-------------Round number: 2-------------
2022-01-14 22:24:31:INFO:-------------Sending models-------------
2022-01-14 22:24:31:INFO:-------------Evaluating models-------------
2022-01-14 22:24:31:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:24:31:INFO:Accuracy = [0.8534464013916069, 0.8869319417264623, 0.8701891715590345, 0.8838878016960209, 0.8540987171124157, 0.8662752772341813, 0.8606218743205044, 0.8410524026962383, 0.8760600130463144, 0.7838660578386606]
2022-01-14 22:24:31:INFO:Loss = [0.40328946405024174, 0.3895005347342057, 0.4600404024401173, 0.36276890697076375, 0.38244393764938134, 0.44921673115348526, 0.4475724596897139, 0.4649045681919085, 0.44049223404597215, 0.5510565465391913]
2022-01-14 22:24:31:INFO:-------------Training local models-------------
2022-01-14 22:25:03:INFO:-------------Aggregating local models-------------
2022-01-14 22:25:04:INFO:-------------Round number: 3-------------
2022-01-14 22:25:04:INFO:-------------Sending models-------------
2022-01-14 22:25:04:INFO:-------------Evaluating models-------------
2022-01-14 22:25:04:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:25:04:INFO:Accuracy = [0.84779299847793, 0.8862796260056534, 0.8656229615133725, 0.8847575559904327, 0.857795172863666, 0.867797347249402, 0.8588823657316808, 0.8482278756251359, 0.882800608828006, 0.8258317025440313]
2022-01-14 22:25:04:INFO:Loss = [0.3999896795027384, 0.3259984464899992, 0.4464797016794551, 0.3251350950895217, 0.33589573759544306, 0.3896641495254253, 0.4149088610273894, 0.42448776468608684, 0.40962583887540444, 0.5121333332982212]
2022-01-14 22:25:04:INFO:-------------Training local models-------------
2022-01-14 22:25:36:INFO:-------------Aggregating local models-------------
2022-01-14 22:25:36:INFO:-------------Round number: 4-------------
2022-01-14 22:25:36:INFO:-------------Sending models-------------
2022-01-14 22:25:36:INFO:-------------Evaluating models-------------
2022-01-14 22:25:36:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:25:36:INFO:Accuracy = [0.8353989997825614, 0.8845401174168297, 0.8610567514677103, 0.882800608828006, 0.8647532072189607, 0.8704066101326375, 0.8608393128941074, 0.8510545770819743, 0.8838878016960209, 0.8438791041530768]
2022-01-14 22:25:36:INFO:Loss = [0.4041101258032625, 0.2818779653326247, 0.4432082471680151, 0.30493215133727025, 0.3078691892866163, 0.35594859352903563, 0.3986165191970926, 0.400734230375983, 0.39387677195574095, 0.49081027253516135]
2022-01-14 22:25:36:INFO:-------------Training local models-------------
2022-01-14 22:26:08:INFO:-------------Aggregating local models-------------
2022-01-14 22:26:09:INFO:-------------Round number: 5-------------
2022-01-14 22:26:09:INFO:-------------Sending models-------------
2022-01-14 22:26:09:INFO:-------------Evaluating models-------------
2022-01-14 22:26:09:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:26:09:INFO:Accuracy = [0.8269188954120461, 0.893237660360948, 0.8597521200260926, 0.8817134159599913, 0.8723635572950641, 0.8704066101326375, 0.862796260056534, 0.8534464013916069, 0.8841052402696238, 0.8549684714068275]
2022-01-14 22:26:09:INFO:Loss = [0.4093651951418853, 0.25074705030144584, 0.44206642765903353, 0.2928414891482454, 0.28905831396241155, 0.33774356028479413, 0.38819876792742447, 0.38585342570027986, 0.38582015216794446, 0.47830217314718415]
2022-01-14 22:26:09:INFO:-------------Training local models-------------
2022-01-14 22:26:41:INFO:-------------Aggregating local models-------------
2022-01-14 22:26:41:INFO:-------------Round number: 6-------------
2022-01-14 22:26:41:INFO:-------------Sending models-------------
2022-01-14 22:26:41:INFO:-------------Evaluating models-------------
2022-01-14 22:26:42:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:26:42:INFO:Accuracy = [0.8149597738638834, 0.9001956947162426, 0.862796260056534, 0.883018047401609, 0.8769297673407263, 0.8658404000869754, 0.8625788214829311, 0.8569254185692542, 0.8841052402696238, 0.8588823657316808]
2022-01-14 22:26:42:INFO:Loss = [0.4134335824946368, 0.22865114717781349, 0.4411363087039239, 0.28466895330487907, 0.27578809051022135, 0.32833858824995815, 0.38053361376110406, 0.37572725214591446, 0.3817997755769136, 0.47084895528652054]
2022-01-14 22:26:42:INFO:-------------Training local models-------------
2022-01-14 22:27:13:INFO:-------------Aggregating local models-------------
2022-01-14 22:27:14:INFO:-------------Round number: 7-------------
2022-01-14 22:27:14:INFO:-------------Sending models-------------
2022-01-14 22:27:14:INFO:-------------Evaluating models-------------
2022-01-14 22:27:14:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:27:14:INFO:Accuracy = [0.8106110023918243, 0.903457273320287, 0.8669275929549902, 0.8856273102848445, 0.8814959773863883, 0.8634485757773429, 0.8658404000869754, 0.863013698630137, 0.8841052402696238, 0.8604044357469015]
2022-01-14 22:27:14:INFO:Loss = [0.415344280204435, 0.21276645773939123, 0.4400932052230232, 0.27824892040480204, 0.2661778359151656, 0.3235998361082482, 0.37441103086770583, 0.3680462720301703, 0.37976212538418325, 0.4662199856218896]
2022-01-14 22:27:14:INFO:-------------Training local models-------------
2022-01-14 22:27:46:INFO:-------------Aggregating local models-------------
2022-01-14 22:27:46:INFO:-------------Round number: 8-------------
2022-01-14 22:27:46:INFO:-------------Sending models-------------
2022-01-14 22:27:46:INFO:-------------Evaluating models-------------
2022-01-14 22:27:47:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:27:47:INFO:Accuracy = [0.8125679495542509, 0.903239834746684, 0.8684496629702109, 0.8884540117416829, 0.8841052402696238, 0.8595346814524897, 0.8697542944118286, 0.8673624701021961, 0.8841052402696238, 0.8606218743205044]
2022-01-14 22:27:47:INFO:Loss = [0.4150558637365396, 0.20120682875794071, 0.43884149888205554, 0.27261375627853257, 0.259001544366989, 0.32136653373445195, 0.3691678698214954, 0.36160141108703386, 0.37860877109943825, 0.4629064728215314]
2022-01-14 22:27:47:INFO:-------------Training local models-------------
2022-01-14 22:28:18:INFO:-------------Aggregating local models-------------
2022-01-14 22:28:19:INFO:-------------Round number: 9-------------
2022-01-14 22:28:19:INFO:-------------Sending models-------------
2022-01-14 22:28:19:INFO:-------------Evaluating models-------------
2022-01-14 22:28:19:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:28:19:INFO:Accuracy = [0.8177864753207219, 0.9019352033050663, 0.8695368558382257, 0.8938899760817569, 0.8862796260056534, 0.8586649271580779, 0.8738856273102849, 0.8710589258534464, 0.8841052402696238, 0.8608393128941074]
2022-01-14 22:28:19:INFO:Loss = [0.41306939839077034, 0.1926867228929236, 0.43731758729126413, 0.26740946580930675, 0.25349434733327625, 0.32049344514828126, 0.36446703503717964, 0.35586030087161385, 0.3777855115169694, 0.46003470791875994]
2022-01-14 22:28:19:INFO:-------------Training local models-------------
2022-01-14 22:28:51:INFO:-------------Aggregating local models-------------
2022-01-14 22:28:51:INFO:-------------Round number: 10-------------
2022-01-14 22:28:51:INFO:-------------Sending models-------------
2022-01-14 22:28:52:INFO:-------------Evaluating models-------------
2022-01-14 22:28:52:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:28:52:INFO:Accuracy = [0.8206131767775603, 0.9041095890410958, 0.8701891715590345, 0.898673624701022, 0.8875842574472711, 0.857795172863666, 0.8804087845183736, 0.8749728201782996, 0.8841052402696238, 0.8608393128941074]
2022-01-14 22:28:52:INFO:Loss = [0.4098759374803932, 0.18628907117680377, 0.435529927538931, 0.2625377936999812, 0.24912449144988127, 0.32034411497278836, 0.36015073297594724, 0.350612671891214, 0.377018303162493, 0.4572042309142249]
2022-01-14 22:28:52:INFO:-------------Training local models-------------
2022-01-14 22:29:23:INFO:-------------Aggregating local models-------------
2022-01-14 22:29:24:INFO:-------------Round number: 11-------------
2022-01-14 22:29:24:INFO:-------------Sending models-------------
2022-01-14 22:29:24:INFO:-------------Evaluating models-------------
2022-01-14 22:29:24:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:29:24:INFO:Accuracy = [0.8258317025440313, 0.9045444661883018, 0.8710589258534464, 0.903457273320287, 0.8901935203305066, 0.8567079799956512, 0.8849749945640356, 0.8797564687975646, 0.8841052402696238, 0.8606218743205044]
2022-01-14 22:29:24:INFO:Loss = [0.4059478938784596, 0.18137667191954612, 0.4335618417394765, 0.2580033193025872, 0.24557938440437574, 0.3205233342035516, 0.35620799461386937, 0.345797221359695, 0.3762456051888648, 0.4543293648476162]
2022-01-14 22:29:24:INFO:-------------Training local models-------------
2022-01-14 22:29:56:INFO:-------------Aggregating local models-------------
2022-01-14 22:29:57:INFO:-------------Round number: 12-------------
2022-01-14 22:29:57:INFO:-------------Sending models-------------
2022-01-14 22:29:57:INFO:-------------Evaluating models-------------
2022-01-14 22:29:57:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:29:57:INFO:Accuracy = [0.8306153511632963, 0.9060665362035225, 0.8710589258534464, 0.9056316590563166, 0.8912807131985214, 0.8573602957164601, 0.8895412046096978, 0.8836703631224179, 0.8841052402696238, 0.8608393128941074]
2022-01-14 22:29:57:INFO:Loss = [0.4015390917880651, 0.17745816368890338, 0.43148006335260103, 0.2537878048760121, 0.24259624039975206, 0.32084551951237417, 0.3525597081791223, 0.341376305082254, 0.37540539360829356, 0.451374042583992]
2022-01-14 22:29:57:INFO:-------------Training local models-------------
2022-01-14 22:30:28:INFO:-------------Aggregating local models-------------
2022-01-14 22:30:29:INFO:-------------Round number: 13-------------
2022-01-14 22:30:29:INFO:-------------Sending models-------------
2022-01-14 22:30:29:INFO:-------------Evaluating models-------------
2022-01-14 22:30:29:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:30:29:INFO:Accuracy = [0.8349641226353555, 0.9082409219395521, 0.87279843444227, 0.9069362904979343, 0.8943248532289628, 0.857577734290063, 0.8936725375081539, 0.8878016960208741, 0.8841052402696238, 0.8608393128941074]
2022-01-14 22:30:29:INFO:Loss = [0.3969059552347612, 0.17420604422833882, 0.42937285834895034, 0.24988790486509332, 0.24002942765824364, 0.3212465097280035, 0.3492360545719615, 0.3373506992103973, 0.3745625760852476, 0.4484351537241814]
2022-01-14 22:30:29:INFO:-------------Training local models-------------
2022-01-14 22:31:01:INFO:-------------Aggregating local models-------------
2022-01-14 22:31:02:INFO:-------------Round number: 14-------------
2022-01-14 22:31:02:INFO:-------------Sending models-------------
2022-01-14 22:31:02:INFO:-------------Evaluating models-------------
2022-01-14 22:31:02:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:31:02:INFO:Accuracy = [0.8382257012393999, 0.9112850619699935, 0.8738856273102849, 0.908458360513155, 0.898021308980213, 0.8586649271580779, 0.8960643618177865, 0.8897586431833007, 0.8843226788432268, 0.8608393128941074]
2022-01-14 22:31:02:INFO:Loss = [0.39223000778735434, 0.17141493598293253, 0.427286641639144, 0.2463228707687792, 0.23776583633047213, 0.3215948548379562, 0.34622349699000904, 0.33367738317597795, 0.37369223391928, 0.44551055318331473]
2022-01-14 22:31:02:INFO:-------------Training local models-------------
2022-01-14 22:31:34:INFO:-------------Aggregating local models-------------
2022-01-14 22:31:34:INFO:-------------Round number: 15-------------
2022-01-14 22:31:34:INFO:-------------Sending models-------------
2022-01-14 22:31:34:INFO:-------------Evaluating models-------------
2022-01-14 22:31:34:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:31:34:INFO:Accuracy = [0.8397477712546205, 0.91324200913242, 0.8769297673407263, 0.9108501848227876, 0.9004131332898456, 0.8588823657316808, 0.8975864318330071, 0.893237660360948, 0.8843226788432268, 0.8608393128941074]
2022-01-14 22:31:34:INFO:Loss = [0.38758028882419376, 0.16891352739802737, 0.42525253506162886, 0.24303749780868047, 0.2356877169563413, 0.3218894156835533, 0.34345905594167264, 0.3303048282526158, 0.37282528357909783, 0.4426124816690354]
2022-01-14 22:31:34:INFO:-------------Training local models-------------
2022-01-14 22:32:06:INFO:-------------Aggregating local models-------------
2022-01-14 22:32:07:INFO:-------------Round number: 16-------------
2022-01-14 22:32:07:INFO:-------------Sending models-------------
2022-01-14 22:32:07:INFO:-------------Evaluating models-------------
2022-01-14 22:32:07:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:32:07:INFO:Accuracy = [0.8419221569906501, 0.9158512720156555, 0.8795390302239617, 0.9121548162644053, 0.9036747118938899, 0.8595346814524897, 0.8991085018482279, 0.8930202217873451, 0.8851924331376386, 0.8612741900413133]
2022-01-14 22:32:07:INFO:Loss = [0.38302057164968856, 0.16664287932590743, 0.42319872151162363, 0.2400281506211455, 0.23373128579982932, 0.3219914389217313, 0.3409003964632893, 0.3271943841345311, 0.3719756779585246, 0.43975352211975843]
2022-01-14 22:32:07:INFO:-------------Training local models-------------
2022-01-14 22:32:39:INFO:-------------Aggregating local models-------------
2022-01-14 22:32:39:INFO:-------------Round number: 17-------------
2022-01-14 22:32:39:INFO:-------------Sending models-------------
2022-01-14 22:32:39:INFO:-------------Evaluating models-------------
2022-01-14 22:32:39:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:32:39:INFO:Accuracy = [0.8438791041530768, 0.9178082191780822, 0.8825831702544031, 0.9130245705588171, 0.9078060447923462, 0.8599695585996956, 0.9017177647314634, 0.8947597303761687, 0.8854098717112415, 0.8610567514677103]
2022-01-14 22:32:39:INFO:Loss = [0.3785888464700127, 0.1645654417365015, 0.4211179513522108, 0.23725198792531815, 0.23185534184695522, 0.3218629960763319, 0.3385075290800178, 0.32431563550723214, 0.3711555645544755, 0.43695364165245176]
2022-01-14 22:32:39:INFO:-------------Training local models-------------
2022-01-14 22:33:11:INFO:-------------Aggregating local models-------------
2022-01-14 22:33:12:INFO:-------------Round number: 18-------------
2022-01-14 22:33:12:INFO:-------------Sending models-------------
2022-01-14 22:33:12:INFO:-------------Evaluating models-------------
2022-01-14 22:33:12:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:33:12:INFO:Accuracy = [0.8464883670363123, 0.9188954120460969, 0.8838878016960209, 0.9147640791476408, 0.9128071319852141, 0.8604044357469015, 0.9030223961730811, 0.8969341161121983, 0.8860621874320505, 0.8617090671885193]
2022-01-14 22:33:12:INFO:Loss = [0.3743000821188219, 0.1626281228575027, 0.4190498752458534, 0.23468965179991413, 0.2300341651152441, 0.32153728961455325, 0.33629550626411325, 0.32165428538322544, 0.37036182778143445, 0.4342265634875073]
2022-01-14 22:33:12:INFO:-------------Training local models-------------
2022-01-14 22:33:44:INFO:-------------Aggregating local models-------------
2022-01-14 22:33:44:INFO:-------------Round number: 19-------------
2022-01-14 22:33:44:INFO:-------------Sending models-------------
2022-01-14 22:33:44:INFO:-------------Evaluating models-------------
2022-01-14 22:33:44:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:33:44:INFO:Accuracy = [0.8484453141987388, 0.9204174820613177, 0.8854098717112415, 0.9154163948684496, 0.9151989562948467, 0.8610567514677103, 0.9043270276146989, 0.8991085018482279, 0.8875842574472711, 0.8617090671885193]
2022-01-14 22:33:44:INFO:Loss = [0.37015989618190603, 0.16080871998090648, 0.41700197761930213, 0.23231211105928293, 0.2282720842733799, 0.32105060912256406, 0.3342480805405736, 0.3192023803533836, 0.3696485761490323, 0.43157378127810586]
2022-01-14 22:33:44:INFO:-------------Training local models-------------
2022-01-14 22:34:16:INFO:-------------Aggregating local models-------------
2022-01-14 22:34:17:INFO:-------------Round number: 20-------------
2022-01-14 22:34:17:INFO:-------------Sending models-------------
2022-01-14 22:34:17:INFO:-------------Evaluating models-------------
2022-01-14 22:34:17:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:34:17:INFO:Accuracy = [0.8508371385083714, 0.9212872363557295, 0.8854098717112415, 0.9160687105892585, 0.9191128506196999, 0.8619265057621222, 0.9051967819091107, 0.9001956947162426, 0.88823657316808, 0.8619265057621222]
2022-01-14 22:34:17:INFO:Loss = [0.3661793010852762, 0.15908899437636137, 0.41497906392501355, 0.23010967416835817, 0.22655271554264905, 0.32040539690410624, 0.33235958286175904, 0.3169306383362047, 0.3690102767882683, 0.4290087691094717]
2022-01-14 22:34:17:INFO:-------------Training local models-------------
2022-01-14 22:34:49:INFO:-------------Aggregating local models-------------
2022-01-14 22:34:49:INFO:-------------Round number: 21-------------
2022-01-14 22:34:49:INFO:-------------Sending models-------------
2022-01-14 22:34:49:INFO:-------------Evaluating models-------------
2022-01-14 22:34:49:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:34:49:INFO:Accuracy = [0.8532289628180039, 0.9223744292237442, 0.8860621874320505, 0.9165035877364645, 0.9206349206349206, 0.862796260056534, 0.9065014133507284, 0.9008480104370515, 0.8897586431833007, 0.8621439443357252]
2022-01-14 22:34:49:INFO:Loss = [0.3623602534971352, 0.1574621185541188, 0.4129636423832106, 0.22805905925203843, 0.2248672902005214, 0.31962244002072365, 0.3306139559562173, 0.3148008631734199, 0.36840247333772314, 0.42652156679964154]
2022-01-14 22:34:49:INFO:-------------Training local models-------------
2022-01-14 22:35:21:INFO:-------------Aggregating local models-------------
2022-01-14 22:35:22:INFO:-------------Round number: 22-------------
2022-01-14 22:35:22:INFO:-------------Sending models-------------
2022-01-14 22:35:22:INFO:-------------Evaluating models-------------
2022-01-14 22:35:22:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:35:22:INFO:Accuracy = [0.8567079799956512, 0.9232441835181561, 0.8869319417264623, 0.9171559034572733, 0.9228093063709502, 0.8647532072189607, 0.9075886062187432, 0.9015003261578604, 0.8904109589041096, 0.8625788214829311]
2022-01-14 22:35:22:INFO:Loss = [0.35871873635541107, 0.15592450697253843, 0.4109541652494809, 0.22615899453793697, 0.22321094142721212, 0.3186955119205335, 0.3290008700580931, 0.31279843473829455, 0.36784080886941184, 0.42410270350528173]
2022-01-14 22:35:22:INFO:-------------Training local models-------------
2022-01-14 22:35:54:INFO:-------------Aggregating local models-------------
2022-01-14 22:35:54:INFO:-------------Round number: 23-------------
2022-01-14 22:35:54:INFO:-------------Sending models-------------
2022-01-14 22:35:54:INFO:-------------Evaluating models-------------
2022-01-14 22:35:54:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:35:54:INFO:Accuracy = [0.8588823657316808, 0.923896499238965, 0.8869319417264623, 0.9178082191780822, 0.9241139378125679, 0.8660578386605784, 0.9082409219395521, 0.9028049575994781, 0.8917155903457273, 0.862796260056534]
2022-01-14 22:35:54:INFO:Loss = [0.35523854363432256, 0.15446492862967873, 0.4089511699007472, 0.22438755233369215, 0.22158961177992006, 0.31764437514392707, 0.327496909046915, 0.31090336971281707, 0.3673278032706108, 0.4217449459790006]
2022-01-14 22:35:54:INFO:-------------Training local models-------------
2022-01-14 22:36:26:INFO:-------------Aggregating local models-------------
2022-01-14 22:36:27:INFO:-------------Round number: 24-------------
2022-01-14 22:36:27:INFO:-------------Sending models-------------
2022-01-14 22:36:27:INFO:-------------Evaluating models-------------
2022-01-14 22:36:27:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:36:27:INFO:Accuracy = [0.8601869971732985, 0.9247662535333768, 0.8869319417264623, 0.9193302891933028, 0.9260708849749946, 0.8667101543813872, 0.9093281148075668, 0.903457273320287, 0.8930202217873451, 0.863013698630137]
2022-01-14 22:36:27:INFO:Loss = [0.3519226003576039, 0.1530837477136737, 0.4069533222102323, 0.22273503782802853, 0.22000060521460973, 0.3164867911504322, 0.32609899950462407, 0.3091054000809933, 0.36684485362040453, 0.419450822775966]
2022-01-14 22:36:27:INFO:-------------Training local models-------------
2022-01-14 22:36:59:INFO:-------------Aggregating local models-------------
2022-01-14 22:36:59:INFO:-------------Round number: 25-------------
2022-01-14 22:36:59:INFO:-------------Sending models-------------
2022-01-14 22:36:59:INFO:-------------Evaluating models-------------
2022-01-14 22:36:59:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:36:59:INFO:Accuracy = [0.8610567514677103, 0.9256360078277887, 0.888019134594477, 0.9199826049141118, 0.9271580778430093, 0.868014785823005, 0.9097629919547727, 0.903457273320287, 0.893237660360948, 0.8634485757773429]
2022-01-14 22:36:59:INFO:Loss = [0.34878695500468027, 0.15176554163598954, 0.40497986490080456, 0.22119398163627507, 0.21845544627436808, 0.31528989977984373, 0.3248127362350454, 0.30740426530629483, 0.3663967243413668, 0.41723114785444254]
2022-01-14 22:36:59:INFO:-------------Training local models-------------
2022-01-14 22:37:31:INFO:-------------Aggregating local models-------------
2022-01-14 22:37:32:INFO:-------------Round number: 26-------------
2022-01-14 22:37:32:INFO:-------------Sending models-------------
2022-01-14 22:37:32:INFO:-------------Evaluating models-------------
2022-01-14 22:37:32:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:37:32:INFO:Accuracy = [0.8643183300717547, 0.9269406392694064, 0.8886714503152859, 0.9217221135029354, 0.92868014785823, 0.8697542944118286, 0.9101978691019786, 0.903457273320287, 0.8936725375081539, 0.8636660143509458]
2022-01-14 22:37:32:INFO:Loss = [0.3457974759741286, 0.1504977820689449, 0.4030389967439305, 0.21976081133636038, 0.21696605372584762, 0.3140599519106195, 0.32361835244770465, 0.3057949893339269, 0.36597604743844625, 0.4150965325332851]
2022-01-14 22:37:32:INFO:-------------Training local models-------------
2022-01-14 22:38:04:INFO:-------------Aggregating local models-------------
2022-01-14 22:38:04:INFO:-------------Round number: 27-------------
2022-01-14 22:38:04:INFO:-------------Sending models-------------
2022-01-14 22:38:04:INFO:-------------Evaluating models-------------
2022-01-14 22:38:04:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:38:04:INFO:Accuracy = [0.8671450315285931, 0.9269406392694064, 0.8888888888888888, 0.9234616220917591, 0.9297673407262448, 0.8701891715590345, 0.9110676233963905, 0.903457273320287, 0.8941074146553598, 0.8643183300717547]
2022-01-14 22:38:04:INFO:Loss = [0.34294835194564827, 0.1492784270849093, 0.40115028286351134, 0.21843095392457149, 0.2155430858689657, 0.3128038172136849, 0.3224976350407834, 0.3042777378911873, 0.365584500166544, 0.41303035017362366]
2022-01-14 22:38:04:INFO:-------------Training local models-------------
2022-01-14 22:38:36:INFO:-------------Aggregating local models-------------
2022-01-14 22:38:37:INFO:-------------Round number: 28-------------
2022-01-14 22:38:37:INFO:-------------Sending models-------------
2022-01-14 22:38:37:INFO:-------------Evaluating models-------------
2022-01-14 22:38:37:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:38:37:INFO:Accuracy = [0.8697542944118286, 0.9271580778430093, 0.88823657316808, 0.9243313763861709, 0.9299847792998478, 0.8712763644270494, 0.9110676233963905, 0.903457273320287, 0.8949771689497716, 0.8645357686453576]
2022-01-14 22:38:37:INFO:Loss = [0.34023443858636265, 0.14810529975254988, 0.3993007667348464, 0.21718664928049838, 0.21418526829772688, 0.3115060806608953, 0.3214427019940974, 0.3028277044397035, 0.36522258466149526, 0.41103746207395725]
2022-01-14 22:38:37:INFO:-------------Training local models-------------
2022-01-14 22:39:09:INFO:-------------Aggregating local models-------------
2022-01-14 22:39:09:INFO:-------------Round number: 29-------------
2022-01-14 22:39:09:INFO:-------------Sending models-------------
2022-01-14 22:39:09:INFO:-------------Evaluating models-------------
2022-01-14 22:39:10:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:39:10:INFO:Accuracy = [0.8714938030006523, 0.928897586431833, 0.88823657316808, 0.9252011306805827, 0.9306370950206566, 0.8723635572950641, 0.9119373776908023, 0.9045444661883018, 0.8951946075233747, 0.8651880843661666]
2022-01-14 22:39:10:INFO:Loss = [0.3376622581294535, 0.14697084110539027, 0.39749027938984177, 0.21601740331627461, 0.21288120554670287, 0.3102200218744877, 0.32046050385244057, 0.3014242262621267, 0.36487729785902434, 0.4091050026582011]
2022-01-14 22:39:10:INFO:-------------Training local models-------------
2022-01-14 22:39:41:INFO:-------------Aggregating local models-------------
2022-01-14 22:39:42:INFO:-------------Round number: 30-------------
2022-01-14 22:39:42:INFO:-------------Sending models-------------
2022-01-14 22:39:42:INFO:-------------Evaluating models-------------
2022-01-14 22:39:42:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:39:42:INFO:Accuracy = [0.8734507501630789, 0.9295499021526419, 0.8893237660360948, 0.9262883235485975, 0.9310719721678625, 0.8732333115894759, 0.9121548162644053, 0.9049793433355077, 0.8954120460969776, 0.8647532072189607]
2022-01-14 22:39:42:INFO:Loss = [0.3352017159757305, 0.14587414997222178, 0.39573127904456395, 0.21492643698583783, 0.21164145998649764, 0.30893944309738647, 0.31951928978821714, 0.30006295204012035, 0.36453985869948785, 0.4072384330971868]
2022-01-14 22:39:42:INFO:-------------Training local models-------------
2022-01-14 22:40:14:INFO:-------------Aggregating local models-------------
2022-01-14 22:40:14:INFO:-------------Round number: 31-------------
2022-01-14 22:40:14:INFO:-------------Sending models-------------
2022-01-14 22:40:14:INFO:-------------Evaluating models-------------
2022-01-14 22:40:15:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:40:15:INFO:Accuracy = [0.8760600130463144, 0.9304196564470537, 0.8895412046096978, 0.9265057621222005, 0.9315068493150684, 0.8738856273102849, 0.9123722548380082, 0.9047619047619048, 0.8956294846705806, 0.8654055229397695]
2022-01-14 22:40:15:INFO:Loss = [0.332862108125902, 0.1448127288680601, 0.39402116224031825, 0.21391272826528204, 0.21046183629044574, 0.3076786971388267, 0.3186259268229231, 0.298747509266911, 0.36421913515538856, 0.40543140407865713]
2022-01-14 22:40:15:INFO:-------------Training local models-------------
2022-01-14 22:40:46:INFO:-------------Aggregating local models-------------
2022-01-14 22:40:47:INFO:-------------Round number: 32-------------
2022-01-14 22:40:47:INFO:-------------Sending models-------------
2022-01-14 22:40:47:INFO:-------------Evaluating models-------------
2022-01-14 22:40:47:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:40:47:INFO:Accuracy = [0.8788867145031528, 0.9306370950206566, 0.8899760817569037, 0.9267232006958034, 0.9323766036094803, 0.8747553816046967, 0.9125896934116112, 0.9060665362035225, 0.8958469232441835, 0.8651880843661666]
2022-01-14 22:40:47:INFO:Loss = [0.33062859375732395, 0.14377645684416693, 0.3923654657077325, 0.21297135600033146, 0.20934230922798786, 0.3064546469088391, 0.3177754890299632, 0.29748208132582293, 0.3639166112896794, 0.403683557226435]
2022-01-14 22:40:47:INFO:-------------Training local models-------------
2022-01-14 22:41:19:INFO:-------------Aggregating local models-------------
2022-01-14 22:41:19:INFO:-------------Round number: 33-------------
2022-01-14 22:41:19:INFO:-------------Sending models-------------
2022-01-14 22:41:19:INFO:-------------Evaluating models-------------
2022-01-14 22:41:20:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:41:20:INFO:Accuracy = [0.8808436616655795, 0.9323766036094803, 0.8901935203305066, 0.9267232006958034, 0.9332463579038921, 0.8751902587519026, 0.9125896934116112, 0.9069362904979343, 0.8960643618177865, 0.8656229615133725]
2022-01-14 22:41:20:INFO:Loss = [0.32850139859211647, 0.14276793426333353, 0.3907524056988672, 0.2121000764380179, 0.20826639968398242, 0.30523775820751986, 0.316953660328187, 0.2962525307005836, 0.36362392893338474, 0.40198649740614895]
2022-01-14 22:41:20:INFO:-------------Training local models-------------
2022-01-14 22:41:51:INFO:-------------Aggregating local models-------------
2022-01-14 22:41:52:INFO:-------------Round number: 34-------------
2022-01-14 22:41:52:INFO:-------------Sending models-------------
2022-01-14 22:41:52:INFO:-------------Evaluating models-------------
2022-01-14 22:41:52:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:41:52:INFO:Accuracy = [0.882800608828006, 0.933681235051098, 0.8904109589041096, 0.9271580778430093, 0.9341161121983039, 0.8760600130463144, 0.9128071319852141, 0.9075886062187432, 0.8960643618177865, 0.8658404000869754]
2022-01-14 22:41:52:INFO:Loss = [0.3264683070150361, 0.14179298367524334, 0.3891887156017946, 0.21128617285958476, 0.20724198193827295, 0.30402832328749746, 0.31615479132374186, 0.2950677135714742, 0.36334303365738335, 0.400335366867398]
2022-01-14 22:41:52:INFO:-------------Training local models-------------
2022-01-14 22:42:24:INFO:-------------Aggregating local models-------------
2022-01-14 22:42:24:INFO:-------------Round number: 35-------------
2022-01-14 22:42:24:INFO:-------------Sending models-------------
2022-01-14 22:42:25:INFO:-------------Evaluating models-------------
2022-01-14 22:42:25:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:42:25:INFO:Accuracy = [0.8845401174168297, 0.9345509893455098, 0.8904109589041096, 0.9280278321374211, 0.9341161121983039, 0.8775820830615351, 0.9128071319852141, 0.9091106762339639, 0.8967166775385953, 0.8662752772341813]
2022-01-14 22:42:25:INFO:Loss = [0.32452601572284734, 0.14084960502305252, 0.3876714839797318, 0.21053125531219571, 0.20626892111141956, 0.3028424677293129, 0.3153808095180463, 0.29390848265252245, 0.3630705130250114, 0.3987331962623297]
2022-01-14 22:42:25:INFO:-------------Training local models-------------
2022-01-14 22:42:56:INFO:-------------Aggregating local models-------------
2022-01-14 22:42:57:INFO:-------------Round number: 36-------------
2022-01-14 22:42:57:INFO:-------------Sending models-------------
2022-01-14 22:42:57:INFO:-------------Evaluating models-------------
2022-01-14 22:42:57:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:42:57:INFO:Accuracy = [0.8858447488584474, 0.9352033050663188, 0.8899760817569037, 0.9278103935638182, 0.9343335507719069, 0.8786692759295499, 0.91324200913242, 0.9101978691019786, 0.8967166775385953, 0.8662752772341813]
2022-01-14 22:42:57:INFO:Loss = [0.3226690240753934, 0.1399319953519355, 0.3862066471919198, 0.20983106913792293, 0.20533513178667984, 0.30167752171475354, 0.3146239129522567, 0.29278648166972854, 0.36282016643063086, 0.39718194424544706]
2022-01-14 22:42:57:INFO:-------------Training local models-------------
2022-01-14 22:43:29:INFO:-------------Aggregating local models-------------
2022-01-14 22:43:30:INFO:-------------Round number: 37-------------
2022-01-14 22:43:30:INFO:-------------Sending models-------------
2022-01-14 22:43:30:INFO:-------------Evaluating models-------------
2022-01-14 22:43:30:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:43:30:INFO:Accuracy = [0.8867145031528593, 0.9362904979343335, 0.8901935203305066, 0.9282452707110241, 0.9345509893455098, 0.8797564687975646, 0.91324200913242, 0.9099804305283757, 0.8973689932594042, 0.8671450315285931]
2022-01-14 22:43:30:INFO:Loss = [0.32089489390319503, 0.1390397361243325, 0.38479859739936184, 0.20918055131904267, 0.20444781714857455, 0.30053613579844773, 0.313901176319137, 0.291701890135139, 0.3625833750704719, 0.3956777976381739]
2022-01-14 22:43:30:INFO:-------------Training local models-------------
2022-01-14 22:44:02:INFO:-------------Aggregating local models-------------
2022-01-14 22:44:02:INFO:-------------Round number: 38-------------
2022-01-14 22:44:02:INFO:-------------Sending models-------------
2022-01-14 22:44:02:INFO:-------------Evaluating models-------------
2022-01-14 22:44:02:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:44:02:INFO:Accuracy = [0.8873668188736682, 0.9373776908023483, 0.8910632746249184, 0.9280278321374211, 0.9354207436399217, 0.8804087845183736, 0.91324200913242, 0.9101978691019786, 0.8978038704066101, 0.868014785823005]
2022-01-14 22:44:02:INFO:Loss = [0.3191954867289995, 0.13817114886881635, 0.3834462689961181, 0.20857700690980774, 0.20359956812359364, 0.2994368795919487, 0.3132039467010515, 0.2906500232303645, 0.36236968584370133, 0.3942194179143529]
2022-01-14 22:44:02:INFO:-------------Training local models-------------
2022-01-14 22:44:34:INFO:-------------Aggregating local models-------------
2022-01-14 22:44:35:INFO:-------------Round number: 39-------------
2022-01-14 22:44:35:INFO:-------------Sending models-------------
2022-01-14 22:44:35:INFO:-------------Evaluating models-------------
2022-01-14 22:44:35:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:44:35:INFO:Accuracy = [0.8878016960208741, 0.9378125679495543, 0.8912807131985214, 0.9275929549902152, 0.9358556207871276, 0.8810611002391824, 0.9130245705588171, 0.9112850619699935, 0.898021308980213, 0.8684496629702109]
2022-01-14 22:44:35:INFO:Loss = [0.3175632458709083, 0.1373216294630915, 0.3821565529478027, 0.20801278469249698, 0.2027920808430573, 0.2983751370667541, 0.3125342632434589, 0.28963229547298636, 0.36217595808850234, 0.39280017394754546]
2022-01-14 22:44:35:INFO:-------------Training local models-------------
2022-01-14 22:45:07:INFO:-------------Aggregating local models-------------
2022-01-14 22:45:07:INFO:-------------Round number: 40-------------
2022-01-14 22:45:07:INFO:-------------Sending models-------------
2022-01-14 22:45:07:INFO:-------------Evaluating models-------------
2022-01-14 22:45:07:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:45:07:INFO:Accuracy = [0.8886714503152859, 0.9386823222439661, 0.8914981517721243, 0.9275929549902152, 0.9360730593607306, 0.8819308545335942, 0.9130245705588171, 0.9112850619699935, 0.898238747553816, 0.8684496629702109]
2022-01-14 22:45:07:INFO:Loss = [0.3159946753275855, 0.1364924371573164, 0.3809236278207144, 0.20748799635518292, 0.20202197984278536, 0.2973538477051332, 0.3118789559497769, 0.28865129168956494, 0.36201073685519713, 0.3914323101746849]
2022-01-14 22:45:07:INFO:-------------Training local models-------------
2022-01-14 22:45:39:INFO:-------------Aggregating local models-------------
2022-01-14 22:45:40:INFO:-------------Round number: 41-------------
2022-01-14 22:45:40:INFO:-------------Sending models-------------
2022-01-14 22:45:40:INFO:-------------Evaluating models-------------
2022-01-14 22:45:40:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:45:40:INFO:Accuracy = [0.8895412046096978, 0.9395520765383779, 0.8917155903457273, 0.9278103935638182, 0.9360730593607306, 0.8819308545335942, 0.9130245705588171, 0.9115025005435964, 0.898456186127419, 0.8688845401174168]
2022-01-14 22:45:40:INFO:Loss = [0.3144861764656159, 0.1356791667592114, 0.37974301921739867, 0.20699544729912028, 0.2012861278769874, 0.2963668110989606, 0.3112390655873604, 0.28769760168804825, 0.3618598122863512, 0.39010567347382713]
2022-01-14 22:45:40:INFO:-------------Training local models-------------
2022-01-14 22:46:12:INFO:-------------Aggregating local models-------------
2022-01-14 22:46:12:INFO:-------------Round number: 42-------------
2022-01-14 22:46:12:INFO:-------------Sending models-------------
2022-01-14 22:46:12:INFO:-------------Evaluating models-------------
2022-01-14 22:46:12:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:46:12:INFO:Accuracy = [0.8899760817569037, 0.9399869536855838, 0.8923679060665362, 0.9275929549902152, 0.9362904979343335, 0.8823657316808001, 0.9130245705588171, 0.9112850619699935, 0.8991085018482279, 0.8691019786910198]
2022-01-14 22:46:12:INFO:Loss = [0.3130394269408486, 0.13489003102539626, 0.37861455333243776, 0.2065431710203307, 0.2005853613295687, 0.2954064032266558, 0.31062899983492986, 0.2867778531962512, 0.3617283530786648, 0.38881994131370323]
2022-01-14 22:46:12:INFO:-------------Training local models-------------
2022-01-14 22:46:44:INFO:-------------Aggregating local models-------------
2022-01-14 22:46:45:INFO:-------------Round number: 43-------------
2022-01-14 22:46:45:INFO:-------------Sending models-------------
2022-01-14 22:46:45:INFO:-------------Evaluating models-------------
2022-01-14 22:46:45:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:46:45:INFO:Accuracy = [0.8908458360513155, 0.9406392694063926, 0.893237660360948, 0.9280278321374211, 0.9369428136551424, 0.883452924548815, 0.9130245705588171, 0.9110676233963905, 0.8991085018482279, 0.8695368558382257]
2022-01-14 22:46:45:INFO:Loss = [0.3116433481196463, 0.1341253006491868, 0.3775362245905371, 0.20611390068409302, 0.19991322642825177, 0.2944925571105081, 0.3100316808966543, 0.2858860253893138, 0.3616025782490022, 0.38757288584931265]
2022-01-14 22:46:45:INFO:-------------Training local models-------------
2022-01-14 22:47:17:INFO:-------------Aggregating local models-------------
2022-01-14 22:47:17:INFO:-------------Round number: 44-------------
2022-01-14 22:47:17:INFO:-------------Sending models-------------
2022-01-14 22:47:17:INFO:-------------Evaluating models-------------
2022-01-14 22:47:18:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:47:18:INFO:Accuracy = [0.8912807131985214, 0.9408567079799957, 0.8938899760817569, 0.92868014785823, 0.9373776908023483, 0.8841052402696238, 0.91324200913242, 0.9115025005435964, 0.8993259404218308, 0.8691019786910198]
2022-01-14 22:47:18:INFO:Loss = [0.31029683412354425, 0.13338512922180515, 0.37650211590791177, 0.20571540871979188, 0.1992610896934562, 0.29359421705695793, 0.309442443584061, 0.2850146385111723, 0.36150238017422653, 0.38636217244858134]
2022-01-14 22:47:18:INFO:-------------Training local models-------------
2022-01-14 22:47:49:INFO:-------------Aggregating local models-------------
2022-01-14 22:47:50:INFO:-------------Round number: 45-------------
2022-01-14 22:47:50:INFO:-------------Sending models-------------
2022-01-14 22:47:50:INFO:-------------Evaluating models-------------
2022-01-14 22:47:50:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:47:50:INFO:Accuracy = [0.8917155903457273, 0.9417264622744075, 0.8947597303761687, 0.929115025005436, 0.9375951293759512, 0.8843226788432268, 0.91324200913242, 0.9115025005435964, 0.8995433789954338, 0.8695368558382257]
2022-01-14 22:47:50:INFO:Loss = [0.3090014701836502, 0.13266573868104453, 0.3755115783556125, 0.20534022981782407, 0.1986383753690621, 0.2927296889569103, 0.3088762953025255, 0.2841670088844035, 0.36141610909265004, 0.3851780863777222]
2022-01-14 22:47:50:INFO:-------------Training local models-------------
2022-01-14 22:48:22:INFO:-------------Aggregating local models-------------
2022-01-14 22:48:22:INFO:-------------Round number: 46-------------
2022-01-14 22:48:22:INFO:-------------Sending models-------------
2022-01-14 22:48:22:INFO:-------------Evaluating models-------------
2022-01-14 22:48:23:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:48:23:INFO:Accuracy = [0.8925853446401392, 0.9423787779952163, 0.8947597303761687, 0.928897586431833, 0.9375951293759512, 0.8847575559904327, 0.91324200913242, 0.9121548162644053, 0.8995433789954338, 0.8695368558382257]
2022-01-14 22:48:23:INFO:Loss = [0.3077554273147902, 0.1319666758023634, 0.3745616786956257, 0.20498889874693052, 0.1980449209830213, 0.29188483345463456, 0.30832472942559125, 0.28334456802687086, 0.36134295487511064, 0.38402962007506275]
2022-01-14 22:48:23:INFO:-------------Training local models-------------
2022-01-14 22:48:54:INFO:-------------Aggregating local models-------------
2022-01-14 22:48:55:INFO:-------------Round number: 47-------------
2022-01-14 22:48:55:INFO:-------------Sending models-------------
2022-01-14 22:48:55:INFO:-------------Evaluating models-------------
2022-01-14 22:48:55:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:48:55:INFO:Accuracy = [0.8928027832137421, 0.9428136551424222, 0.8954120460969776, 0.9293324635790389, 0.9375951293759512, 0.8851924331376386, 0.91324200913242, 0.9123722548380082, 0.8993259404218308, 0.8699717329854316]
2022-01-14 22:48:55:INFO:Loss = [0.30655218294775, 0.13129149582013236, 0.37365233237200235, 0.20465429842480784, 0.19747839860591182, 0.29105657421910675, 0.3077910027551665, 0.2825505684636689, 0.3612817112120202, 0.38291611555485033]
2022-01-14 22:48:55:INFO:-------------Training local models-------------
2022-01-14 22:49:27:INFO:-------------Aggregating local models-------------
2022-01-14 22:49:27:INFO:-------------Round number: 48-------------
2022-01-14 22:49:27:INFO:-------------Sending models-------------
2022-01-14 22:49:27:INFO:-------------Evaluating models-------------
2022-01-14 22:49:28:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:49:28:INFO:Accuracy = [0.893455098934551, 0.9432485322896281, 0.8956294846705806, 0.9304196564470537, 0.9378125679495543, 0.8856273102848445, 0.913676886279626, 0.9121548162644053, 0.8993259404218308, 0.8699717329854316]
2022-01-14 22:49:28:INFO:Loss = [0.3053996684545961, 0.1306313882841299, 0.37278216113729246, 0.2043435817945893, 0.19692950110854068, 0.29027611413206333, 0.3072782197485107, 0.2817870700281628, 0.3612383831435841, 0.3818317186059019]
2022-01-14 22:49:28:INFO:-------------Training local models-------------
2022-01-14 22:49:59:INFO:-------------Aggregating local models-------------
2022-01-14 22:50:00:INFO:-------------Round number: 49-------------
2022-01-14 22:50:00:INFO:-------------Sending models-------------
2022-01-14 22:50:00:INFO:-------------Evaluating models-------------
2022-01-14 22:50:00:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:50:00:INFO:Accuracy = [0.8938899760817569, 0.9432485322896281, 0.8964992389649924, 0.9308545335942596, 0.9382474450967602, 0.8867145031528593, 0.913894324853229, 0.91324200913242, 0.8997608175690367, 0.8712763644270494]
2022-01-14 22:50:00:INFO:Loss = [0.3042910946008721, 0.12998779810614525, 0.3719466953389972, 0.20406112072151072, 0.1963973503547323, 0.28955259489832225, 0.30678387303596877, 0.281047206688969, 0.36121238941751693, 0.38076893180552757]
2022-01-14 22:50:00:INFO:-------------Training local models-------------
2022-01-14 22:50:32:INFO:-------------Aggregating local models-------------
2022-01-14 22:50:32:INFO:-------------Round number: 50-------------
2022-01-14 22:50:32:INFO:-------------Sending models-------------
2022-01-14 22:50:32:INFO:-------------Evaluating models-------------
2022-01-14 22:50:33:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:50:33:INFO:Accuracy = [0.8949771689497716, 0.9434659708632311, 0.8967166775385953, 0.9304196564470537, 0.9386823222439661, 0.8878016960208741, 0.913894324853229, 0.91324200913242, 0.9001956947162426, 0.8712763644270494]
2022-01-14 22:50:33:INFO:Loss = [0.30321900933300727, 0.12935804126714442, 0.37116576822955144, 0.20379263276948759, 0.19588324538647275, 0.2888678168682491, 0.3063099829384976, 0.2803420753218335, 0.36120016645143943, 0.37973709341631096]
2022-01-14 22:50:33:INFO:-------------Training local models-------------
2022-01-14 22:51:04:INFO:-------------Aggregating local models-------------
2022-01-14 22:51:05:INFO:-------------Round number: 51-------------
2022-01-14 22:51:05:INFO:-------------Sending models-------------
2022-01-14 22:51:05:INFO:-------------Evaluating models-------------
2022-01-14 22:51:05:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:51:05:INFO:Accuracy = [0.8956294846705806, 0.9434659708632311, 0.8964992389649924, 0.9306370950206566, 0.9386823222439661, 0.8888888888888888, 0.913894324853229, 0.9128071319852141, 0.9004131332898456, 0.8714938030006523]
2022-01-14 22:51:05:INFO:Loss = [0.30218105337831713, 0.12874714604380053, 0.37040302509726086, 0.20354717071692868, 0.19538261090957315, 0.28821430271898446, 0.3058451974608942, 0.27965561814588874, 0.36120154012549366, 0.3787272006402519]
2022-01-14 22:51:05:INFO:-------------Training local models-------------
2022-01-14 22:51:37:INFO:-------------Aggregating local models-------------
2022-01-14 22:51:37:INFO:-------------Round number: 52-------------
2022-01-14 22:51:37:INFO:-------------Sending models-------------
2022-01-14 22:51:37:INFO:-------------Evaluating models-------------
2022-01-14 22:51:38:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:51:38:INFO:Accuracy = [0.8960643618177865, 0.94411828658404, 0.8967166775385953, 0.9306370950206566, 0.938899760817569, 0.8895412046096978, 0.9143292020004349, 0.9130245705588171, 0.9004131332898456, 0.8717112415742553]
2022-01-14 22:51:38:INFO:Loss = [0.30117613895555306, 0.1281517549945136, 0.36966073144939376, 0.2033234876859994, 0.19489803984574933, 0.2875868493767431, 0.30539072446343246, 0.2789824505078489, 0.3612072849583561, 0.37772997035360933]
2022-01-14 22:51:38:INFO:-------------Training local models-------------
2022-01-14 22:52:09:INFO:-------------Aggregating local models-------------
2022-01-14 22:52:10:INFO:-------------Round number: 53-------------
2022-01-14 22:52:10:INFO:-------------Sending models-------------
2022-01-14 22:52:10:INFO:-------------Evaluating models-------------
2022-01-14 22:52:10:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:52:10:INFO:Accuracy = [0.8969341161121983, 0.943900848010437, 0.8969341161121983, 0.9310719721678625, 0.939117199391172, 0.8901935203305066, 0.9143292020004349, 0.9141117634268319, 0.9008480104370515, 0.8719286801478582]
2022-01-14 22:52:10:INFO:Loss = [0.30020849406192696, 0.12757278256366164, 0.3689573433543923, 0.20311217161219375, 0.19443137758310416, 0.28698666443413734, 0.3049553332139391, 0.2783381875416213, 0.3612231055352975, 0.37676207393263134]
2022-01-14 22:52:10:INFO:-------------Training local models-------------
2022-01-14 22:52:42:INFO:-------------Aggregating local models-------------
2022-01-14 22:52:42:INFO:-------------Round number: 54-------------
2022-01-14 22:52:42:INFO:-------------Sending models-------------
2022-01-14 22:52:42:INFO:-------------Evaluating models-------------
2022-01-14 22:52:42:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:52:42:INFO:Accuracy = [0.8973689932594042, 0.94411828658404, 0.8973689932594042, 0.9315068493150684, 0.939117199391172, 0.8908458360513155, 0.9145466405740378, 0.913459447706023, 0.9012828875842575, 0.8719286801478582]
2022-01-14 22:52:42:INFO:Loss = [0.29927257369838667, 0.12700280366605887, 0.36827605427240284, 0.20291768342616398, 0.1939771572275337, 0.2864289333418169, 0.30453384115248183, 0.2777177961075668, 0.361248385587081, 0.3758177226618656]
2022-01-14 22:52:42:INFO:-------------Training local models-------------
2022-01-14 22:53:14:INFO:-------------Aggregating local models-------------
2022-01-14 22:53:15:INFO:-------------Round number: 55-------------
2022-01-14 22:53:15:INFO:-------------Sending models-------------
2022-01-14 22:53:15:INFO:-------------Evaluating models-------------
2022-01-14 22:53:15:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:53:15:INFO:Accuracy = [0.8969341161121983, 0.943900848010437, 0.8973689932594042, 0.9315068493150684, 0.939117199391172, 0.8921504674929333, 0.9145466405740378, 0.913676886279626, 0.9015003261578604, 0.8721461187214612]
2022-01-14 22:53:15:INFO:Loss = [0.2983671819119411, 0.12645001504672512, 0.36761700084046073, 0.20273031513861767, 0.1935382854641948, 0.28590246100494265, 0.30411622608035954, 0.27711221451960605, 0.3612841334393843, 0.3748980003177877]
2022-01-14 22:53:15:INFO:-------------Training local models-------------
2022-01-14 22:53:47:INFO:-------------Aggregating local models-------------
2022-01-14 22:53:47:INFO:-------------Round number: 56-------------
2022-01-14 22:53:47:INFO:-------------Sending models-------------
2022-01-14 22:53:47:INFO:-------------Evaluating models-------------
2022-01-14 22:53:47:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:53:47:INFO:Accuracy = [0.8971515546858012, 0.943900848010437, 0.8978038704066101, 0.9308545335942596, 0.9395520765383779, 0.8921504674929333, 0.9145466405740378, 0.913459447706023, 0.9019352033050663, 0.8723635572950641]
2022-01-14 22:53:47:INFO:Loss = [0.29748504643856166, 0.12591159504198726, 0.3669826936533988, 0.20255069262206868, 0.19312056648560105, 0.28540004148727366, 0.3037071143656105, 0.2765348851442685, 0.36132120397198325, 0.3739984484160745]
2022-01-14 22:53:47:INFO:-------------Training local models-------------
2022-01-14 22:54:19:INFO:-------------Aggregating local models-------------
2022-01-14 22:54:20:INFO:-------------Round number: 57-------------
2022-01-14 22:54:20:INFO:-------------Sending models-------------
2022-01-14 22:54:20:INFO:-------------Evaluating models-------------
2022-01-14 22:54:20:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:54:20:INFO:Accuracy = [0.8978038704066101, 0.94411828658404, 0.898238747553816, 0.9306370950206566, 0.9395520765383779, 0.8930202217873451, 0.9145466405740378, 0.913676886279626, 0.9019352033050663, 0.8723635572950641]
2022-01-14 22:54:20:INFO:Loss = [0.2966262990144871, 0.1253884388362335, 0.36638086283484594, 0.20238304475503255, 0.19271713256014575, 0.2849203271520842, 0.3033153180687542, 0.2759824553346632, 0.3613708938409348, 0.37311813812043737]
2022-01-14 22:54:20:INFO:-------------Training local models-------------
2022-01-14 22:54:51:INFO:-------------Aggregating local models-------------
2022-01-14 22:54:52:INFO:-------------Round number: 58-------------
2022-01-14 22:54:52:INFO:-------------Sending models-------------
2022-01-14 22:54:52:INFO:-------------Evaluating models-------------
2022-01-14 22:54:52:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:54:52:INFO:Accuracy = [0.8975864318330071, 0.94411828658404, 0.898673624701022, 0.9306370950206566, 0.9395520765383779, 0.8936725375081539, 0.9145466405740378, 0.913894324853229, 0.9012828875842575, 0.87279843444227]
2022-01-14 22:54:52:INFO:Loss = [0.29579066074779126, 0.12487822469867044, 0.36579707118671023, 0.20222962338040568, 0.19232309177282175, 0.28446712337498486, 0.3029279397191985, 0.27544540461172484, 0.36142849543997446, 0.37225836731555645]
2022-01-14 22:54:52:INFO:-------------Training local models-------------
2022-01-14 22:55:24:INFO:-------------Aggregating local models-------------
2022-01-14 22:55:24:INFO:-------------Round number: 59-------------
2022-01-14 22:55:24:INFO:-------------Sending models-------------
2022-01-14 22:55:25:INFO:-------------Evaluating models-------------
2022-01-14 22:55:25:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:55:25:INFO:Accuracy = [0.8978038704066101, 0.9447706023048489, 0.8988910632746249, 0.9308545335942596, 0.9406392694063926, 0.8941074146553598, 0.9145466405740378, 0.913894324853229, 0.9015003261578604, 0.873015873015873]
2022-01-14 22:55:25:INFO:Loss = [0.2949877089850697, 0.12438542878066514, 0.3652338469942451, 0.20208794656628074, 0.1919388482455471, 0.28404144736278314, 0.30255788933593786, 0.274933259241555, 0.361497786319198, 0.37143185296668796]
2022-01-14 22:55:25:INFO:-------------Training local models-------------
2022-01-14 22:55:56:INFO:-------------Aggregating local models-------------
2022-01-14 22:55:57:INFO:-------------Round number: 60-------------
2022-01-14 22:55:57:INFO:-------------Sending models-------------
2022-01-14 22:55:57:INFO:-------------Evaluating models-------------
2022-01-14 22:55:57:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:55:57:INFO:Accuracy = [0.898021308980213, 0.9456403565992607, 0.8988910632746249, 0.9306370950206566, 0.9406392694063926, 0.8943248532289628, 0.9145466405740378, 0.9143292020004349, 0.9019352033050663, 0.8738856273102849]
2022-01-14 22:55:57:INFO:Loss = [0.2942059237579476, 0.12390644860843827, 0.36469374882364813, 0.2019565396668411, 0.19156752128315435, 0.2836104259460923, 0.3021956663433704, 0.2744302114899181, 0.3615736591379058, 0.370616661071527]
2022-01-14 22:55:57:INFO:-------------Training local models-------------
2022-01-14 22:56:29:INFO:-------------Aggregating local models-------------
2022-01-14 22:56:29:INFO:-------------Round number: 61-------------
2022-01-14 22:56:29:INFO:-------------Sending models-------------
2022-01-14 22:56:29:INFO:-------------Evaluating models-------------
2022-01-14 22:56:30:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:56:30:INFO:Accuracy = [0.898021308980213, 0.9460752337464666, 0.8993259404218308, 0.9308545335942596, 0.9406392694063926, 0.8943248532289628, 0.9147640791476408, 0.9149815177212437, 0.9019352033050663, 0.8736681887366818]
2022-01-14 22:56:30:INFO:Loss = [0.29344804505772537, 0.12344010498785635, 0.3641768249565477, 0.2018318108203905, 0.19120835876118134, 0.2832099313519257, 0.30184323421916015, 0.2739484575451527, 0.36165721681823626, 0.36981842271783855]
2022-01-14 22:56:30:INFO:-------------Training local models-------------
2022-01-14 22:57:01:INFO:-------------Aggregating local models-------------
2022-01-14 22:57:02:INFO:-------------Round number: 62-------------
2022-01-14 22:57:02:INFO:-------------Sending models-------------
2022-01-14 22:57:02:INFO:-------------Evaluating models-------------
2022-01-14 22:57:02:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:57:02:INFO:Accuracy = [0.898021308980213, 0.9462926723200695, 0.8999782561426397, 0.9315068493150684, 0.9408567079799957, 0.8945422918025657, 0.9147640791476408, 0.9149815177212437, 0.9021526418786693, 0.8734507501630789]
2022-01-14 22:57:02:INFO:Loss = [0.29271858012865964, 0.12298744931745621, 0.363671300572685, 0.20171495232159584, 0.1908553456972402, 0.28283254204339797, 0.30149478501139365, 0.2734791505315463, 0.36174943077011035, 0.36904238815252105]
2022-01-14 22:57:02:INFO:-------------Training local models-------------
2022-01-14 22:57:34:INFO:-------------Aggregating local models-------------
2022-01-14 22:57:34:INFO:-------------Round number: 63-------------
2022-01-14 22:57:34:INFO:-------------Sending models-------------
2022-01-14 22:57:34:INFO:-------------Evaluating models-------------
2022-01-14 22:57:34:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:57:34:INFO:Accuracy = [0.898456186127419, 0.9467275494672754, 0.8995433789954338, 0.9308545335942596, 0.9410741465535986, 0.8951946075233747, 0.9147640791476408, 0.9158512720156555, 0.9023700804522722, 0.8736681887366818]
2022-01-14 22:57:34:INFO:Loss = [0.2920045381522832, 0.12254554741108117, 0.36320092137243315, 0.20160752758132391, 0.1905179772503421, 0.28247491807368436, 0.3011632683404619, 0.2730339822229729, 0.36185399533515883, 0.3682869009155283]
2022-01-14 22:57:34:INFO:-------------Training local models-------------
2022-01-14 22:58:06:INFO:-------------Aggregating local models-------------
2022-01-14 22:58:07:INFO:-------------Round number: 64-------------
2022-01-14 22:58:07:INFO:-------------Sending models-------------
2022-01-14 22:58:07:INFO:-------------Evaluating models-------------
2022-01-14 22:58:07:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:58:07:INFO:Accuracy = [0.898456186127419, 0.9467275494672754, 0.8997608175690367, 0.9306370950206566, 0.9412915851272016, 0.8954120460969776, 0.9145466405740378, 0.9156338334420526, 0.9019352033050663, 0.8736681887366818]
2022-01-14 22:58:07:INFO:Loss = [0.2913136161522025, 0.12211266474302285, 0.3627477714562911, 0.20150748895348133, 0.1901935077206212, 0.28214680487622135, 0.3008423388251309, 0.27260957628366883, 0.3619610883681334, 0.36755088177354384]
2022-01-14 22:58:07:INFO:-------------Training local models-------------
2022-01-14 22:58:39:INFO:-------------Aggregating local models-------------
2022-01-14 22:58:39:INFO:-------------Round number: 65-------------
2022-01-14 22:58:39:INFO:-------------Sending models-------------
2022-01-14 22:58:39:INFO:-------------Evaluating models-------------
2022-01-14 22:58:39:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:58:39:INFO:Accuracy = [0.898673624701022, 0.9469449880408785, 0.8997608175690367, 0.9304196564470537, 0.9417264622744075, 0.8956294846705806, 0.9147640791476408, 0.9156338334420526, 0.9012828875842575, 0.8738856273102849]
2022-01-14 22:58:39:INFO:Loss = [0.2906425675932317, 0.12168803355025962, 0.3623086741021189, 0.2014143622509848, 0.18987796397657064, 0.28184170228234023, 0.3005252425446171, 0.272199547083606, 0.36207143267332664, 0.36683073451405457]
2022-01-14 22:58:39:INFO:-------------Training local models-------------
2022-01-14 22:59:11:INFO:-------------Aggregating local models-------------
2022-01-14 22:59:12:INFO:-------------Round number: 66-------------
2022-01-14 22:59:12:INFO:-------------Sending models-------------
2022-01-14 22:59:12:INFO:-------------Evaluating models-------------
2022-01-14 22:59:12:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:59:12:INFO:Accuracy = [0.8991085018482279, 0.9473798651880844, 0.8997608175690367, 0.9302022178734507, 0.9419439008480104, 0.8962818003913894, 0.9149815177212437, 0.9162861491628614, 0.9008480104370515, 0.8738856273102849]
2022-01-14 22:59:12:INFO:Loss = [0.28998158205468194, 0.12126871509634994, 0.3618820962368726, 0.20132894495444248, 0.18957287996436203, 0.28154248092078005, 0.30020866845988814, 0.2718042906003382, 0.3621876703025046, 0.36612580760824487]
2022-01-14 22:59:12:INFO:-------------Training local models-------------
2022-01-14 22:59:43:INFO:-------------Aggregating local models-------------
2022-01-14 22:59:44:INFO:-------------Round number: 67-------------
2022-01-14 22:59:44:INFO:-------------Sending models-------------
2022-01-14 22:59:44:INFO:-------------Evaluating models-------------
2022-01-14 22:59:44:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:59:44:INFO:Accuracy = [0.8991085018482279, 0.9473798651880844, 0.8997608175690367, 0.9304196564470537, 0.9421613394216134, 0.8969341161121983, 0.9149815177212437, 0.9162861491628614, 0.9004131332898456, 0.8741030658838878]
2022-01-14 22:59:44:INFO:Loss = [0.2893396158211393, 0.12086040626177644, 0.3614763300989164, 0.20125076875236556, 0.18927827229912475, 0.2812566041942007, 0.29990498603860377, 0.2714214813265985, 0.3623052609939218, 0.3654390320873757]
2022-01-14 22:59:44:INFO:-------------Training local models-------------
2022-01-14 23:00:16:INFO:-------------Aggregating local models-------------
2022-01-14 23:00:16:INFO:-------------Round number: 68-------------
2022-01-14 23:00:16:INFO:-------------Sending models-------------
2022-01-14 23:00:17:INFO:-------------Evaluating models-------------
2022-01-14 23:00:17:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:00:17:INFO:Accuracy = [0.8988910632746249, 0.9473798651880844, 0.8999782561426397, 0.9304196564470537, 0.9423787779952163, 0.8973689932594042, 0.9149815177212437, 0.9167210263100674, 0.9008480104370515, 0.8741030658838878]
2022-01-14 23:00:17:INFO:Loss = [0.2887167392523132, 0.12046340844868034, 0.3610792452297389, 0.2011810901999824, 0.18898977280529758, 0.2809808078016383, 0.2996026453665409, 0.2710536563302258, 0.36243501991421806, 0.3647761231128942]
2022-01-14 23:00:17:INFO:-------------Training local models-------------
2022-01-14 23:00:48:INFO:-------------Aggregating local models-------------
2022-01-14 23:00:49:INFO:-------------Round number: 69-------------
2022-01-14 23:00:49:INFO:-------------Sending models-------------
2022-01-14 23:00:49:INFO:-------------Evaluating models-------------
2022-01-14 23:00:49:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:00:49:INFO:Accuracy = [0.8988910632746249, 0.9473798651880844, 0.9001956947162426, 0.9302022178734507, 0.9423787779952163, 0.898021308980213, 0.9149815177212437, 0.9167210263100674, 0.9010654490106544, 0.8745379430310937]
2022-01-14 23:00:49:INFO:Loss = [0.2881113605924842, 0.12007441697709287, 0.36070440505475543, 0.2011176801800141, 0.18870828971589743, 0.28072410893792715, 0.29931432144177667, 0.27070019386853933, 0.3625707621476694, 0.3641310638292624]
2022-01-14 23:00:49:INFO:-------------Training local models-------------
2022-01-14 23:01:21:INFO:-------------Aggregating local models-------------
2022-01-14 23:01:21:INFO:-------------Round number: 70-------------
2022-01-14 23:01:21:INFO:-------------Sending models-------------
2022-01-14 23:01:21:INFO:-------------Evaluating models-------------
2022-01-14 23:01:22:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:01:22:INFO:Accuracy = [0.8995433789954338, 0.9473798651880844, 0.9006305718634485, 0.9302022178734507, 0.9423787779952163, 0.898021308980213, 0.9151989562948467, 0.9171559034572733, 0.9001956947162426, 0.8751902587519026]
2022-01-14 23:01:22:INFO:Loss = [0.2875228057097349, 0.1196943377053001, 0.36034584025169736, 0.20105757655391945, 0.1884289280035855, 0.28048095250194216, 0.2990388295866842, 0.2703574769135915, 0.3627074901253776, 0.3634977353824139]
2022-01-14 23:01:22:INFO:-------------Training local models-------------
2022-01-14 23:01:53:INFO:-------------Aggregating local models-------------
2022-01-14 23:01:54:INFO:-------------Round number: 71-------------
2022-01-14 23:01:54:INFO:-------------Sending models-------------
2022-01-14 23:01:54:INFO:-------------Evaluating models-------------
2022-01-14 23:01:54:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:01:54:INFO:Accuracy = [0.8995433789954338, 0.9473798651880844, 0.9008480104370515, 0.9308545335942596, 0.9425962165688193, 0.898021308980213, 0.9156338334420526, 0.9173733420308763, 0.9001956947162426, 0.8760600130463144]
2022-01-14 23:01:54:INFO:Loss = [0.28695463846273805, 0.1193206284220017, 0.35999802218883875, 0.2010065039587681, 0.18816202042179248, 0.2802595492089721, 0.2987676411053576, 0.2700214626518887, 0.3628429283074101, 0.36287654101454525]
2022-01-14 23:01:54:INFO:-------------Training local models-------------
2022-01-14 23:02:26:INFO:-------------Aggregating local models-------------
2022-01-14 23:02:26:INFO:-------------Round number: 72-------------
2022-01-14 23:02:26:INFO:-------------Sending models-------------
2022-01-14 23:02:26:INFO:-------------Evaluating models-------------
2022-01-14 23:02:26:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:02:26:INFO:Accuracy = [0.8995433789954338, 0.9473798651880844, 0.9010654490106544, 0.9306370950206566, 0.9425962165688193, 0.898021308980213, 0.9158512720156555, 0.9173733420308763, 0.9004131332898456, 0.8758425744727114]
2022-01-14 23:02:26:INFO:Loss = [0.28639869035374427, 0.11895558507632582, 0.3596618221155371, 0.2009612055051692, 0.18790056246734949, 0.280050787075456, 0.2985004380052572, 0.2697014547296819, 0.3629837859346459, 0.36227023178272805]
2022-01-14 23:02:26:INFO:-------------Training local models-------------
2022-01-14 23:02:58:INFO:-------------Aggregating local models-------------
2022-01-14 23:02:58:INFO:-------------Round number: 73-------------
2022-01-14 23:02:58:INFO:-------------Sending models-------------
2022-01-14 23:02:58:INFO:-------------Evaluating models-------------
2022-01-14 23:02:58:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:02:58:INFO:Accuracy = [0.8997608175690367, 0.9475973037616873, 0.9008480104370515, 0.9304196564470537, 0.9428136551424222, 0.898021308980213, 0.9158512720156555, 0.9173733420308763, 0.9006305718634485, 0.8760600130463144]
2022-01-14 23:02:58:INFO:Loss = [0.28585994655197705, 0.11859753157044971, 0.35934027975304533, 0.20092213736409328, 0.18764191258386945, 0.27985774698169014, 0.2982422544326387, 0.2693889425025277, 0.36312149038296243, 0.3616738813752017]
2022-01-14 23:02:58:INFO:-------------Training local models-------------
2022-01-14 23:03:30:INFO:-------------Aggregating local models-------------
2022-01-14 23:03:30:INFO:-------------Round number: 74-------------
2022-01-14 23:03:30:INFO:-------------Sending models-------------
2022-01-14 23:03:30:INFO:-------------Evaluating models-------------
2022-01-14 23:03:30:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:03:30:INFO:Accuracy = [0.8997608175690367, 0.9475973037616873, 0.9008480104370515, 0.9304196564470537, 0.9432485322896281, 0.898021308980213, 0.9160687105892585, 0.9175907806044792, 0.9006305718634485, 0.8758425744727114]
2022-01-14 23:03:30:INFO:Loss = [0.2853368466771396, 0.11824683924998663, 0.35902472500579774, 0.20088782756093518, 0.1873890559151077, 0.27967455785671014, 0.297986345601575, 0.2690873195359866, 0.3632625662469827, 0.36109526977876566]
2022-01-14 23:03:30:INFO:-------------Training local models-------------
2022-01-14 23:04:02:INFO:-------------Aggregating local models-------------
2022-01-14 23:04:02:INFO:-------------Round number: 75-------------
2022-01-14 23:04:02:INFO:-------------Sending models-------------
2022-01-14 23:04:02:INFO:-------------Evaluating models-------------
2022-01-14 23:04:02:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:04:02:INFO:Accuracy = [0.8999782561426397, 0.9480321809088932, 0.9008480104370515, 0.9302022178734507, 0.9432485322896281, 0.898021308980213, 0.9160687105892585, 0.9178082191780822, 0.9004131332898456, 0.8758425744727114]
2022-01-14 23:04:02:INFO:Loss = [0.28483160336160523, 0.11790204484364873, 0.35872509488784293, 0.20085539398613142, 0.18714242289388297, 0.279505862031768, 0.2977420232524728, 0.2687995666561697, 0.3634066537230817, 0.3605276400588239]
2022-01-14 23:04:02:INFO:-------------Training local models-------------
2022-01-14 23:04:34:INFO:-------------Aggregating local models-------------
2022-01-14 23:04:34:INFO:-------------Round number: 76-------------
2022-01-14 23:04:34:INFO:-------------Sending models-------------
2022-01-14 23:04:34:INFO:-------------Evaluating models-------------
2022-01-14 23:04:34:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:04:34:INFO:Accuracy = [0.8999782561426397, 0.9480321809088932, 0.9015003261578604, 0.9304196564470537, 0.9432485322896281, 0.8978038704066101, 0.9160687105892585, 0.9178082191780822, 0.9004131332898456, 0.8760600130463144]
2022-01-14 23:04:34:INFO:Loss = [0.2843460923042524, 0.11756671515468992, 0.35844331970993226, 0.20082429464016746, 0.18690460268187836, 0.279353107496622, 0.29750694157207136, 0.26852640895873164, 0.3635524008132621, 0.3599746834058576]
2022-01-14 23:04:34:INFO:-------------Training local models-------------
2022-01-14 23:05:06:INFO:-------------Aggregating local models-------------
2022-01-14 23:05:06:INFO:-------------Round number: 77-------------
2022-01-14 23:05:06:INFO:-------------Sending models-------------
2022-01-14 23:05:06:INFO:-------------Evaluating models-------------
2022-01-14 23:05:06:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:05:06:INFO:Accuracy = [0.9001956947162426, 0.9480321809088932, 0.9015003261578604, 0.9302022178734507, 0.9434659708632311, 0.8978038704066101, 0.9162861491628614, 0.9178082191780822, 0.9001956947162426, 0.8760600130463144]
2022-01-14 23:05:06:INFO:Loss = [0.28386999141257524, 0.11723803826445506, 0.3581603993107343, 0.2007933436847692, 0.18667113819128633, 0.27920766694429827, 0.29727048729984284, 0.26826352155360095, 0.3637001797479596, 0.3594351183415963]
2022-01-14 23:05:06:INFO:-------------Training local models-------------
2022-01-14 23:05:38:INFO:-------------Aggregating local models-------------
2022-01-14 23:05:38:INFO:-------------Round number: 78-------------
2022-01-14 23:05:38:INFO:-------------Sending models-------------
2022-01-14 23:05:38:INFO:-------------Evaluating models-------------
2022-01-14 23:05:38:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:05:38:INFO:Accuracy = [0.9001956947162426, 0.9482496194824962, 0.9019352033050663, 0.9297673407262448, 0.9434659708632311, 0.8978038704066101, 0.9162861491628614, 0.9178082191780822, 0.9004131332898456, 0.8760600130463144]
2022-01-14 23:05:38:INFO:Loss = [0.28340764358311354, 0.11691760145064795, 0.3578869834852665, 0.2007628358794181, 0.18644227041475817, 0.2790704369838616, 0.29704128197239343, 0.26801034712847155, 0.36384616983708873, 0.3589057457376084]
2022-01-14 23:05:38:INFO:-------------Training local models-------------
2022-01-14 23:06:10:INFO:-------------Aggregating local models-------------
2022-01-14 23:06:10:INFO:-------------Round number: 79-------------
2022-01-14 23:06:10:INFO:-------------Sending models-------------
2022-01-14 23:06:10:INFO:-------------Evaluating models-------------
2022-01-14 23:06:10:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:06:10:INFO:Accuracy = [0.9006305718634485, 0.9484670580560991, 0.9023700804522722, 0.9297673407262448, 0.9434659708632311, 0.8978038704066101, 0.9162861491628614, 0.9175907806044792, 0.8999782561426397, 0.8760600130463144]
2022-01-14 23:06:10:INFO:Loss = [0.282958163241388, 0.11660533141483806, 0.3576267205822224, 0.20073505851219806, 0.18622200866514604, 0.27894216235386865, 0.29681935899771833, 0.2677638330278015, 0.36399556350692575, 0.35839237018126774]
2022-01-14 23:06:10:INFO:-------------Training local models-------------
2022-01-14 23:06:42:INFO:-------------Aggregating local models-------------
2022-01-14 23:06:42:INFO:-------------Round number: 80-------------
2022-01-14 23:06:42:INFO:-------------Sending models-------------
2022-01-14 23:06:42:INFO:-------------Evaluating models-------------
2022-01-14 23:06:42:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:06:42:INFO:Accuracy = [0.9006305718634485, 0.948901935203305, 0.9028049575994781, 0.9295499021526419, 0.9434659708632311, 0.8975864318330071, 0.9165035877364645, 0.9175907806044792, 0.8999782561426397, 0.8762774516199173]
2022-01-14 23:06:42:INFO:Loss = [0.2825227475923671, 0.11630065378253396, 0.35737838579574804, 0.20070883305252893, 0.18600923401153432, 0.2788212363409017, 0.2966038958882415, 0.26752679182425004, 0.36415130551448804, 0.35789008597510935]
2022-01-14 23:06:42:INFO:-------------Training local models-------------
2022-01-14 23:07:14:INFO:-------------Aggregating local models-------------
2022-01-14 23:07:14:INFO:-------------Round number: 81-------------
2022-01-14 23:07:14:INFO:-------------Sending models-------------
2022-01-14 23:07:14:INFO:-------------Evaluating models-------------
2022-01-14 23:07:14:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:07:14:INFO:Accuracy = [0.9006305718634485, 0.948901935203305, 0.9028049575994781, 0.9297673407262448, 0.9434659708632311, 0.8978038704066101, 0.9167210263100674, 0.9175907806044792, 0.8999782561426397, 0.8762774516199173]
2022-01-14 23:07:14:INFO:Loss = [0.28210163958686646, 0.116001052123531, 0.35714205094898366, 0.20068357443334664, 0.18580226828893714, 0.2787157364869815, 0.2963933809705306, 0.26729958933258885, 0.36430689113601245, 0.3573966764642803]
2022-01-14 23:07:14:INFO:-------------Training local models-------------
2022-01-14 23:07:45:INFO:-------------Aggregating local models-------------
2022-01-14 23:07:46:INFO:-------------Round number: 82-------------
2022-01-14 23:07:46:INFO:-------------Sending models-------------
2022-01-14 23:07:46:INFO:-------------Evaluating models-------------
2022-01-14 23:07:46:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:07:46:INFO:Accuracy = [0.9008480104370515, 0.948901935203305, 0.903239834746684, 0.9299847792998478, 0.9434659708632311, 0.8988910632746249, 0.9167210263100674, 0.9178082191780822, 0.8999782561426397, 0.8762774516199173]
2022-01-14 23:07:46:INFO:Loss = [0.281693868434657, 0.11570650570614366, 0.35691628884711424, 0.2006661472275778, 0.1855975786390391, 0.2786098948015545, 0.2961868720595806, 0.2670790774904076, 0.3644674037698651, 0.3569148739924246]
2022-01-14 23:07:46:INFO:-------------Training local models-------------
2022-01-14 23:08:17:INFO:-------------Aggregating local models-------------
2022-01-14 23:08:18:INFO:-------------Round number: 83-------------
2022-01-14 23:08:18:INFO:-------------Sending models-------------
2022-01-14 23:08:18:INFO:-------------Evaluating models-------------
2022-01-14 23:08:18:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:08:18:INFO:Accuracy = [0.9008480104370515, 0.9486844966297021, 0.903239834746684, 0.9302022178734507, 0.9434659708632311, 0.8988910632746249, 0.9169384648836704, 0.9178082191780822, 0.8997608175690367, 0.8762774516199173]
2022-01-14 23:08:18:INFO:Loss = [0.2812997280597712, 0.11541549188122009, 0.3566916372687164, 0.20065355993394762, 0.18539956857589376, 0.2785159127116361, 0.2959817918778041, 0.2668693536365209, 0.36463213977509745, 0.3564471623094171]
2022-01-14 23:08:18:INFO:-------------Training local models-------------
2022-01-14 23:08:49:INFO:-------------Aggregating local models-------------
2022-01-14 23:08:50:INFO:-------------Round number: 84-------------
2022-01-14 23:08:50:INFO:-------------Sending models-------------
2022-01-14 23:08:50:INFO:-------------Evaluating models-------------
2022-01-14 23:08:50:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:08:50:INFO:Accuracy = [0.9010654490106544, 0.9486844966297021, 0.903457273320287, 0.9306370950206566, 0.9434659708632311, 0.8988910632746249, 0.9171559034572733, 0.9173733420308763, 0.9001956947162426, 0.8762774516199173]
2022-01-14 23:08:50:INFO:Loss = [0.2809179552220101, 0.11512993191506125, 0.35648057437207453, 0.20064225353085385, 0.1852041371825355, 0.27842898488276707, 0.29578354427343456, 0.2666655692910375, 0.3647964402403743, 0.3559886252107214]
2022-01-14 23:08:50:INFO:-------------Training local models-------------
2022-01-14 23:09:21:INFO:-------------Aggregating local models-------------
2022-01-14 23:09:22:INFO:-------------Round number: 85-------------
2022-01-14 23:09:22:INFO:-------------Sending models-------------
2022-01-14 23:09:22:INFO:-------------Evaluating models-------------
2022-01-14 23:09:22:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:09:22:INFO:Accuracy = [0.9008480104370515, 0.9486844966297021, 0.9036747118938899, 0.9306370950206566, 0.943683409436834, 0.8991085018482279, 0.9171559034572733, 0.9171559034572733, 0.9001956947162426, 0.8767123287671232]
2022-01-14 23:09:22:INFO:Loss = [0.28054380320898986, 0.11485271840020385, 0.3562747028419727, 0.20063719098846103, 0.18501373452129774, 0.27834710453068257, 0.29558728955955726, 0.26646803334607294, 0.3649669970846886, 0.35554212302742694]
2022-01-14 23:09:22:INFO:-------------Training local models-------------
2022-01-14 23:09:53:INFO:-------------Aggregating local models-------------
2022-01-14 23:09:54:INFO:-------------Round number: 86-------------
2022-01-14 23:09:54:INFO:-------------Sending models-------------
2022-01-14 23:09:54:INFO:-------------Evaluating models-------------
2022-01-14 23:09:54:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:09:54:INFO:Accuracy = [0.9008480104370515, 0.9486844966297021, 0.9038921504674929, 0.9304196564470537, 0.94411828658404, 0.8991085018482279, 0.9171559034572733, 0.9171559034572733, 0.8997608175690367, 0.8767123287671232]
2022-01-14 23:09:54:INFO:Loss = [0.28018175440880266, 0.11457878735001147, 0.35607755076611547, 0.20063360019858187, 0.18482885927051357, 0.2782646149994819, 0.29539992061841197, 0.2662759856015451, 0.3651338990854911, 0.35510280410469874]
2022-01-14 23:09:54:INFO:-------------Training local models-------------
2022-01-14 23:10:25:INFO:-------------Aggregating local models-------------
2022-01-14 23:10:26:INFO:-------------Round number: 87-------------
2022-01-14 23:10:26:INFO:-------------Sending models-------------
2022-01-14 23:10:26:INFO:-------------Evaluating models-------------
2022-01-14 23:10:26:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:10:26:INFO:Accuracy = [0.9008480104370515, 0.9486844966297021, 0.9036747118938899, 0.9308545335942596, 0.94411828658404, 0.8991085018482279, 0.9171559034572733, 0.9171559034572733, 0.8995433789954338, 0.8764948901935203]
2022-01-14 23:10:26:INFO:Loss = [0.27982948026032967, 0.11431222444434465, 0.35588905431321494, 0.20063253141428744, 0.18464687910968988, 0.27819409249713417, 0.2952117175451967, 0.266089266097372, 0.36530370856909417, 0.35467165483568436]
2022-01-14 23:10:26:INFO:-------------Training local models-------------
2022-01-14 23:10:57:INFO:-------------Aggregating local models-------------
2022-01-14 23:10:58:INFO:-------------Round number: 88-------------
2022-01-14 23:10:58:INFO:-------------Sending models-------------
2022-01-14 23:10:58:INFO:-------------Evaluating models-------------
2022-01-14 23:10:58:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:10:58:INFO:Accuracy = [0.9008480104370515, 0.9486844966297021, 0.903457273320287, 0.9306370950206566, 0.94411828658404, 0.8993259404218308, 0.9175907806044792, 0.9173733420308763, 0.8995433789954338, 0.8764948901935203]
2022-01-14 23:10:58:INFO:Loss = [0.27948826672206567, 0.11404914692155181, 0.3557031484165261, 0.20063432106261905, 0.18446950356894537, 0.2781328102188612, 0.29502933297580847, 0.26591277256615653, 0.365469537633576, 0.35424749888901935]
2022-01-14 23:10:58:INFO:-------------Training local models-------------
2022-01-14 23:11:29:INFO:-------------Aggregating local models-------------
2022-01-14 23:11:30:INFO:-------------Round number: 89-------------
2022-01-14 23:11:30:INFO:-------------Sending models-------------
2022-01-14 23:11:30:INFO:-------------Evaluating models-------------
2022-01-14 23:11:30:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:11:30:INFO:Accuracy = [0.9008480104370515, 0.9486844966297021, 0.9036747118938899, 0.9306370950206566, 0.943900848010437, 0.8993259404218308, 0.9175907806044792, 0.9171559034572733, 0.8995433789954338, 0.8760600130463144]
2022-01-14 23:11:30:INFO:Loss = [0.27915417165265993, 0.1137954282861559, 0.35552862123898854, 0.20063680816106705, 0.18430155957773087, 0.2780775284538856, 0.2948528028956939, 0.26574419443047276, 0.3656388485712465, 0.3538348544847178]
2022-01-14 23:11:30:INFO:-------------Training local models-------------
2022-01-14 23:12:01:INFO:-------------Aggregating local models-------------
2022-01-14 23:12:02:INFO:-------------Round number: 90-------------
2022-01-14 23:12:02:INFO:-------------Sending models-------------
2022-01-14 23:12:02:INFO:-------------Evaluating models-------------
2022-01-14 23:12:02:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:12:02:INFO:Accuracy = [0.9008480104370515, 0.948901935203305, 0.903239834746684, 0.9304196564470537, 0.943900848010437, 0.8993259404218308, 0.9175907806044792, 0.9169384648836704, 0.8993259404218308, 0.8764948901935203]
2022-01-14 23:12:02:INFO:Loss = [0.2788333129234957, 0.1135448641618741, 0.35535569891008456, 0.20063819226429755, 0.1841375656350469, 0.2780152465861466, 0.2946759220266235, 0.26557963546308166, 0.36580684650695183, 0.35342884882375575]
2022-01-14 23:12:02:INFO:-------------Training local models-------------
2022-01-14 23:12:33:INFO:-------------Aggregating local models-------------
2022-01-14 23:12:34:INFO:-------------Round number: 91-------------
2022-01-14 23:12:34:INFO:-------------Sending models-------------
2022-01-14 23:12:34:INFO:-------------Evaluating models-------------
2022-01-14 23:12:34:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:12:34:INFO:Accuracy = [0.9010654490106544, 0.9486844966297021, 0.9030223961730811, 0.9306370950206566, 0.943900848010437, 0.8995433789954338, 0.9175907806044792, 0.9173733420308763, 0.8993259404218308, 0.8769297673407263]
2022-01-14 23:12:34:INFO:Loss = [0.2785172146981211, 0.11330222870466686, 0.3551911377423895, 0.20063969592622813, 0.1839757082468741, 0.2779602062137072, 0.2945039987647089, 0.26542267340798653, 0.3659770847336048, 0.3530312529345883]
2022-01-14 23:12:34:INFO:-------------Training local models-------------
2022-01-14 23:13:05:INFO:-------------Aggregating local models-------------
2022-01-14 23:13:06:INFO:-------------Round number: 92-------------
2022-01-14 23:13:06:INFO:-------------Sending models-------------
2022-01-14 23:13:06:INFO:-------------Evaluating models-------------
2022-01-14 23:13:06:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:13:06:INFO:Accuracy = [0.9008480104370515, 0.9486844966297021, 0.903239834746684, 0.9308545335942596, 0.943900848010437, 0.8995433789954338, 0.9175907806044792, 0.9173733420308763, 0.8995433789954338, 0.8767123287671232]
2022-01-14 23:13:06:INFO:Loss = [0.27820769069520995, 0.11306529019980635, 0.35502786091170907, 0.20064249910620977, 0.18381992465806996, 0.27792752260247267, 0.29433277375078204, 0.2652718406513537, 0.3661472925235744, 0.3526406965550745]
2022-01-14 23:13:06:INFO:-------------Training local models-------------
2022-01-14 23:13:37:INFO:-------------Aggregating local models-------------
2022-01-14 23:13:38:INFO:-------------Round number: 93-------------
2022-01-14 23:13:38:INFO:-------------Sending models-------------
2022-01-14 23:13:38:INFO:-------------Evaluating models-------------
2022-01-14 23:13:38:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:13:38:INFO:Accuracy = [0.9006305718634485, 0.9486844966297021, 0.903239834746684, 0.9312894107414655, 0.943900848010437, 0.8995433789954338, 0.9175907806044792, 0.9175907806044792, 0.8995433789954338, 0.8769297673407263]
2022-01-14 23:13:38:INFO:Loss = [0.2779090467906665, 0.11283089719871904, 0.354864563512765, 0.20064817029418017, 0.18366682584986582, 0.2778932696923734, 0.2941622758507929, 0.2651207253214479, 0.3663156732745867, 0.352253775354692]
2022-01-14 23:13:38:INFO:-------------Training local models-------------
2022-01-14 23:14:09:INFO:-------------Aggregating local models-------------
2022-01-14 23:14:10:INFO:-------------Round number: 94-------------
2022-01-14 23:14:10:INFO:-------------Sending models-------------
2022-01-14 23:14:10:INFO:-------------Evaluating models-------------
2022-01-14 23:14:10:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:14:10:INFO:Accuracy = [0.9004131332898456, 0.9486844966297021, 0.903239834746684, 0.9312894107414655, 0.943900848010437, 0.8999782561426397, 0.9180256577516851, 0.9178082191780822, 0.8995433789954338, 0.8771472059143292]
2022-01-14 23:14:10:INFO:Loss = [0.277613713046788, 0.11260061774779871, 0.3547097505837005, 0.200655990634412, 0.18352002023332997, 0.2778626675819292, 0.2939985818793214, 0.26498053609433914, 0.36648396381844417, 0.35187559273949726]
2022-01-14 23:14:10:INFO:-------------Training local models-------------
2022-01-14 23:14:41:INFO:-------------Aggregating local models-------------
2022-01-14 23:14:42:INFO:-------------Round number: 95-------------
2022-01-14 23:14:42:INFO:-------------Sending models-------------
2022-01-14 23:14:42:INFO:-------------Evaluating models-------------
2022-01-14 23:14:42:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:14:42:INFO:Accuracy = [0.9006305718634485, 0.948901935203305, 0.903239834746684, 0.9312894107414655, 0.94411828658404, 0.9004131332898456, 0.9180256577516851, 0.9178082191780822, 0.8995433789954338, 0.8771472059143292]
2022-01-14 23:14:42:INFO:Loss = [0.27733145744730303, 0.11237834758420853, 0.3545616177086701, 0.20066677431715582, 0.1833756937089992, 0.2778401479444374, 0.29383838200311585, 0.2648418246352697, 0.36665378727188586, 0.3515062225141972]
2022-01-14 23:14:42:INFO:-------------Training local models-------------
2022-01-14 23:15:13:INFO:-------------Aggregating local models-------------
2022-01-14 23:15:14:INFO:-------------Round number: 96-------------
2022-01-14 23:15:14:INFO:-------------Sending models-------------
2022-01-14 23:15:14:INFO:-------------Evaluating models-------------
2022-01-14 23:15:14:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:15:14:INFO:Accuracy = [0.9008480104370515, 0.949119373776908, 0.903457273320287, 0.9310719721678625, 0.94411828658404, 0.9006305718634485, 0.9180256577516851, 0.9180256577516851, 0.8995433789954338, 0.8773646444879322]
2022-01-14 23:15:14:INFO:Loss = [0.27705425542778783, 0.11215557651672499, 0.3544147399817463, 0.20067714828569855, 0.1832340292522632, 0.27782097699690544, 0.29367925288295604, 0.26470951366971085, 0.3668221278310715, 0.3511410525279398]
2022-01-14 23:15:14:INFO:-------------Training local models-------------
2022-01-14 23:15:45:INFO:-------------Aggregating local models-------------
2022-01-14 23:15:46:INFO:-------------Round number: 97-------------
2022-01-14 23:15:46:INFO:-------------Sending models-------------
2022-01-14 23:15:46:INFO:-------------Evaluating models-------------
2022-01-14 23:15:46:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:15:46:INFO:Accuracy = [0.9008480104370515, 0.949119373776908, 0.903239834746684, 0.9315068493150684, 0.94411828658404, 0.9006305718634485, 0.9180256577516851, 0.918460534898891, 0.8993259404218308, 0.8773646444879322]
2022-01-14 23:15:46:INFO:Loss = [0.27678754636457664, 0.11193911206757809, 0.3542709240747866, 0.20068551140135715, 0.18309632474674525, 0.2778040974544691, 0.293525569236557, 0.2645820925481297, 0.36699280463065476, 0.35078606934016915]
2022-01-14 23:15:46:INFO:-------------Training local models-------------
2022-01-14 23:16:17:INFO:-------------Aggregating local models-------------
2022-01-14 23:16:18:INFO:-------------Round number: 98-------------
2022-01-14 23:16:18:INFO:-------------Sending models-------------
2022-01-14 23:16:18:INFO:-------------Evaluating models-------------
2022-01-14 23:16:18:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:16:18:INFO:Accuracy = [0.9010654490106544, 0.949119373776908, 0.903239834746684, 0.9315068493150684, 0.94411828658404, 0.9012828875842575, 0.9180256577516851, 0.918460534898891, 0.8993259404218308, 0.8775820830615351]
2022-01-14 23:16:18:INFO:Loss = [0.2765256266496456, 0.11172577171002428, 0.35413428645692235, 0.20069361259708407, 0.18296252950529268, 0.27779361432405875, 0.2933753714411485, 0.26446255818267067, 0.3671639052632901, 0.3504383636131094]
2022-01-14 23:16:18:INFO:-------------Training local models-------------
2022-01-14 23:16:49:INFO:-------------Aggregating local models-------------
2022-01-14 23:16:50:INFO:-------------Round number: 99-------------
2022-01-14 23:16:50:INFO:-------------Sending models-------------
2022-01-14 23:16:50:INFO:-------------Evaluating models-------------
2022-01-14 23:16:50:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:16:50:INFO:Accuracy = [0.9010654490106544, 0.9493368123505109, 0.9030223961730811, 0.9315068493150684, 0.94411828658404, 0.9012828875842575, 0.9180256577516851, 0.918460534898891, 0.8991085018482279, 0.8777995216351381]
2022-01-14 23:16:50:INFO:Loss = [0.27627090546550187, 0.11151601867696877, 0.35400037163949344, 0.20070226861547064, 0.18283355242212163, 0.2777872856603204, 0.29322942175232536, 0.26434501946675215, 0.3673349693301488, 0.35009727655627665]
2022-01-14 23:16:50:INFO:-------------Training local models-------------
2022-01-14 23:17:21:INFO:-------------Aggregating local models-------------
2022-01-14 23:17:22:INFO:-------------Round number: 100-------------
2022-01-14 23:17:22:INFO:-------------Sending models-------------
2022-01-14 23:17:22:INFO:-------------Evaluating models-------------
2022-01-14 23:17:22:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:17:22:INFO:Accuracy = [0.9010654490106544, 0.9493368123505109, 0.9028049575994781, 0.9315068493150684, 0.944335725157643, 0.9012828875842575, 0.9182430963252881, 0.918460534898891, 0.8991085018482279, 0.8775820830615351]
2022-01-14 23:17:22:INFO:Loss = [0.2760253367997077, 0.11130851320197152, 0.35386968251812306, 0.20071341451747657, 0.18270646287131115, 0.27778408256995823, 0.2930880790692096, 0.2642333875863681, 0.3675023211055024, 0.3497622566613736]
2022-01-14 23:17:22:INFO:-------------Training local models-------------
2022-01-14 23:17:53:INFO:-------------Aggregating local models-------------
2022-01-14 23:17:54:INFO:-------------Round number: 101-------------
2022-01-14 23:17:54:INFO:-------------Sending models-------------
2022-01-14 23:17:54:INFO:-------------Evaluating models-------------
2022-01-14 23:17:54:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:17:54:INFO:Accuracy = [0.9010654490106544, 0.9497716894977168, 0.9023700804522722, 0.9312894107414655, 0.944335725157643, 0.9012828875842575, 0.9182430963252881, 0.9182430963252881, 0.8995433789954338, 0.8777995216351381]
2022-01-14 23:17:54:INFO:Loss = [0.27578706795883295, 0.11110754904066275, 0.35373802920782166, 0.2007249652992013, 0.18258250073158208, 0.27778654870709846, 0.29294720584234596, 0.2641226327994971, 0.36766827355910653, 0.34943752781089116]
2022-01-14 23:17:54:INFO:-------------Training local models-------------
2022-01-14 23:18:25:INFO:-------------Aggregating local models-------------
2022-01-14 23:18:26:INFO:-------------Round number: 102-------------
2022-01-14 23:18:26:INFO:-------------Sending models-------------
2022-01-14 23:18:26:INFO:-------------Evaluating models-------------
2022-01-14 23:18:26:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:18:26:INFO:Accuracy = [0.9012828875842575, 0.9499891280713199, 0.9023700804522722, 0.9315068493150684, 0.944335725157643, 0.9012828875842575, 0.9182430963252881, 0.9182430963252881, 0.8995433789954338, 0.8775820830615351]
2022-01-14 23:18:26:INFO:Loss = [0.2755576725499129, 0.1109108977138455, 0.35361191370138895, 0.20073788067795814, 0.18246102279006854, 0.2777849230823421, 0.292809285141849, 0.2640161534764514, 0.36783875304147795, 0.3491180160676192]
2022-01-14 23:18:26:INFO:-------------Training local models-------------
2022-01-14 23:18:57:INFO:-------------Aggregating local models-------------
2022-01-14 23:18:58:INFO:-------------Round number: 103-------------
2022-01-14 23:18:58:INFO:-------------Sending models-------------
2022-01-14 23:18:58:INFO:-------------Evaluating models-------------
2022-01-14 23:18:58:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:18:58:INFO:Accuracy = [0.9015003261578604, 0.9497716894977168, 0.9021526418786693, 0.9315068493150684, 0.944335725157643, 0.9012828875842575, 0.9182430963252881, 0.9182430963252881, 0.8993259404218308, 0.8775820830615351]
2022-01-14 23:18:58:INFO:Loss = [0.27533444712633803, 0.11071867771495256, 0.35348931422871377, 0.20075027744413745, 0.18234550952937323, 0.277787445918022, 0.29267572329252445, 0.2639145761162841, 0.3680038535167763, 0.348807435181311]
2022-01-14 23:18:58:INFO:-------------Training local models-------------
2022-01-14 23:19:29:INFO:-------------Aggregating local models-------------
2022-01-14 23:19:29:INFO:-------------Round number: 104-------------
2022-01-14 23:19:29:INFO:-------------Sending models-------------
2022-01-14 23:19:30:INFO:-------------Evaluating models-------------
2022-01-14 23:19:30:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:19:30:INFO:Accuracy = [0.9012828875842575, 0.9499891280713199, 0.9023700804522722, 0.9315068493150684, 0.944335725157643, 0.9012828875842575, 0.9182430963252881, 0.9182430963252881, 0.8993259404218308, 0.8777995216351381]
2022-01-14 23:19:30:INFO:Loss = [0.2751162146913613, 0.11053439591950825, 0.35336718039665765, 0.200762337806532, 0.18223137914642773, 0.27777926429324895, 0.29254477987550204, 0.26381418304648985, 0.36816755783070115, 0.3485002884356061]
2022-01-14 23:19:30:INFO:-------------Training local models-------------
2022-01-14 23:20:01:INFO:-------------Aggregating local models-------------
2022-01-14 23:20:01:INFO:-------------Round number: 105-------------
2022-01-14 23:20:01:INFO:-------------Sending models-------------
2022-01-14 23:20:02:INFO:-------------Evaluating models-------------
2022-01-14 23:20:02:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:20:02:INFO:Accuracy = [0.9012828875842575, 0.9499891280713199, 0.9023700804522722, 0.9315068493150684, 0.944335725157643, 0.9012828875842575, 0.9182430963252881, 0.918460534898891, 0.8993259404218308, 0.878016960208741]
2022-01-14 23:20:02:INFO:Loss = [0.27490413778706774, 0.11035144238830819, 0.35324441489688785, 0.20077585505155973, 0.1821189640403386, 0.2777773865749355, 0.2924149380848488, 0.2637147414957655, 0.36832975187553113, 0.3482006283258344]
2022-01-14 23:20:02:INFO:-------------Training local models-------------
2022-01-14 23:20:33:INFO:-------------Aggregating local models-------------
2022-01-14 23:20:33:INFO:-------------Round number: 106-------------
2022-01-14 23:20:33:INFO:-------------Sending models-------------
2022-01-14 23:20:33:INFO:-------------Evaluating models-------------
2022-01-14 23:20:34:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:20:34:INFO:Accuracy = [0.9012828875842575, 0.9499891280713199, 0.9023700804522722, 0.9317242878886715, 0.9445531637312459, 0.9012828875842575, 0.9182430963252881, 0.918460534898891, 0.8993259404218308, 0.878016960208741]
2022-01-14 23:20:34:INFO:Loss = [0.2746981193135991, 0.11017104614286369, 0.35312698320603103, 0.2007915979657618, 0.18200725595541897, 0.27778051053664665, 0.29228590906966084, 0.2636214398623514, 0.36849226145939534, 0.34790858146516335]
2022-01-14 23:20:34:INFO:-------------Training local models-------------
2022-01-14 23:21:05:INFO:-------------Aggregating local models-------------
2022-01-14 23:21:05:INFO:-------------Round number: 107-------------
2022-01-14 23:21:05:INFO:-------------Sending models-------------
2022-01-14 23:21:05:INFO:-------------Evaluating models-------------
2022-01-14 23:21:06:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:21:06:INFO:Accuracy = [0.9010654490106544, 0.9502065666449228, 0.9023700804522722, 0.9315068493150684, 0.9445531637312459, 0.9015003261578604, 0.9182430963252881, 0.918460534898891, 0.8993259404218308, 0.8786692759295499]
2022-01-14 23:21:06:INFO:Loss = [0.2744962119235215, 0.10999561933885428, 0.3530137089620305, 0.20080993920707543, 0.18189748244362342, 0.27778148078000975, 0.2921587373610974, 0.2635331285947039, 0.3686589681226223, 0.34762182303800865]
2022-01-14 23:21:06:INFO:-------------Training local models-------------
2022-01-14 23:21:37:INFO:-------------Aggregating local models-------------
2022-01-14 23:21:37:INFO:-------------Round number: 108-------------
2022-01-14 23:21:37:INFO:-------------Sending models-------------
2022-01-14 23:21:37:INFO:-------------Evaluating models-------------
2022-01-14 23:21:38:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:21:38:INFO:Accuracy = [0.9012828875842575, 0.9504240052185258, 0.9023700804522722, 0.9317242878886715, 0.9445531637312459, 0.9015003261578604, 0.918460534898891, 0.9182430963252881, 0.8997608175690367, 0.8786692759295499]
2022-01-14 23:21:38:INFO:Loss = [0.2742997382756272, 0.1098235130915069, 0.35290309505038076, 0.20082868979832716, 0.18179059431942307, 0.2777890656822833, 0.29203476480322854, 0.2634488483866717, 0.36882655448382284, 0.34734207495339414]
2022-01-14 23:21:38:INFO:-------------Training local models-------------
2022-01-14 23:22:09:INFO:-------------Aggregating local models-------------
2022-01-14 23:22:09:INFO:-------------Round number: 109-------------
2022-01-14 23:22:09:INFO:-------------Sending models-------------
2022-01-14 23:22:09:INFO:-------------Evaluating models-------------
2022-01-14 23:22:10:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:22:10:INFO:Accuracy = [0.9015003261578604, 0.9504240052185258, 0.9025875190258752, 0.9317242878886715, 0.9445531637312459, 0.9015003261578604, 0.918677973472494, 0.9182430963252881, 0.8997608175690367, 0.8786692759295499]
2022-01-14 23:22:10:INFO:Loss = [0.2741061984434375, 0.10965383715899656, 0.3527968714602126, 0.20084969426600977, 0.18168713024111272, 0.2777933997540911, 0.29191314756992176, 0.26336866431576134, 0.3689986011856381, 0.3470714473870341]
2022-01-14 23:22:10:INFO:-------------Training local models-------------
2022-01-14 23:22:41:INFO:-------------Aggregating local models-------------
2022-01-14 23:22:41:INFO:-------------Round number: 110-------------
2022-01-14 23:22:41:INFO:-------------Sending models-------------
2022-01-14 23:22:41:INFO:-------------Evaluating models-------------
2022-01-14 23:22:41:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:22:41:INFO:Accuracy = [0.9015003261578604, 0.9504240052185258, 0.9025875190258752, 0.9317242878886715, 0.9445531637312459, 0.9017177647314634, 0.918677973472494, 0.9182430963252881, 0.8997608175690367, 0.8786692759295499]
2022-01-14 23:22:41:INFO:Loss = [0.27391815214923454, 0.10948729647167459, 0.35269788642729366, 0.20086932198781401, 0.18158684246279433, 0.27780110686863285, 0.2917930260299624, 0.26329238940765737, 0.3691694499586228, 0.34680596912522427]
2022-01-14 23:22:41:INFO:-------------Training local models-------------
2022-01-14 23:23:13:INFO:-------------Aggregating local models-------------
2022-01-14 23:23:13:INFO:-------------Round number: 111-------------
2022-01-14 23:23:13:INFO:-------------Sending models-------------
2022-01-14 23:23:13:INFO:-------------Evaluating models-------------
2022-01-14 23:23:13:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:23:13:INFO:Accuracy = [0.9015003261578604, 0.9504240052185258, 0.9025875190258752, 0.9317242878886715, 0.9447706023048489, 0.9023700804522722, 0.9188954120460969, 0.9182430963252881, 0.8997608175690367, 0.8788867145031528]
2022-01-14 23:23:13:INFO:Loss = [0.27373719248170475, 0.10932202518110991, 0.3525989277993138, 0.20088832799547784, 0.18148763272326957, 0.27780606813450515, 0.29167388031541625, 0.2632185924874076, 0.3693400888098804, 0.34654673841870715]
2022-01-14 23:23:13:INFO:-------------Training local models-------------
2022-01-14 23:23:45:INFO:-------------Aggregating local models-------------
2022-01-14 23:23:45:INFO:-------------Round number: 112-------------
2022-01-14 23:23:45:INFO:-------------Sending models-------------
2022-01-14 23:23:45:INFO:-------------Evaluating models-------------
2022-01-14 23:23:45:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:23:45:INFO:Accuracy = [0.9012828875842575, 0.9502065666449228, 0.9028049575994781, 0.9317242878886715, 0.9447706023048489, 0.9023700804522722, 0.9188954120460969, 0.9182430963252881, 0.8997608175690367, 0.8788867145031528]
2022-01-14 23:23:45:INFO:Loss = [0.27355983809991324, 0.10916129052462069, 0.3525024730383028, 0.20090930796387999, 0.18139005793316212, 0.27781798831734156, 0.29155847567069715, 0.26314878363302413, 0.3695083922595116, 0.34629223774889506]
2022-01-14 23:23:45:INFO:-------------Training local models-------------
2022-01-14 23:24:17:INFO:-------------Aggregating local models-------------
2022-01-14 23:24:17:INFO:-------------Round number: 113-------------
2022-01-14 23:24:17:INFO:-------------Sending models-------------
2022-01-14 23:24:17:INFO:-------------Evaluating models-------------
2022-01-14 23:24:17:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:24:17:INFO:Accuracy = [0.9012828875842575, 0.9504240052185258, 0.9028049575994781, 0.9317242878886715, 0.9447706023048489, 0.9028049575994781, 0.9193302891933028, 0.9182430963252881, 0.8997608175690367, 0.8788867145031528]
2022-01-14 23:24:17:INFO:Loss = [0.27338847234888647, 0.1090043871977774, 0.35241095687509616, 0.2009290136700466, 0.1812945483236712, 0.2778316954814305, 0.29144537150263455, 0.2630813005728452, 0.36967754615040066, 0.34604151491148405]
2022-01-14 23:24:17:INFO:-------------Training local models-------------
2022-01-14 23:24:49:INFO:-------------Aggregating local models-------------
2022-01-14 23:24:49:INFO:-------------Round number: 114-------------
2022-01-14 23:24:49:INFO:-------------Sending models-------------
2022-01-14 23:24:49:INFO:-------------Evaluating models-------------
2022-01-14 23:24:49:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:24:49:INFO:Accuracy = [0.9012828875842575, 0.9502065666449228, 0.903239834746684, 0.9317242878886715, 0.9447706023048489, 0.9028049575994781, 0.9193302891933028, 0.9182430963252881, 0.8997608175690367, 0.8795390302239617]
2022-01-14 23:24:49:INFO:Loss = [0.2732196220679038, 0.10885045983759803, 0.35232018629146405, 0.2009499075220686, 0.18120193425497486, 0.27784502675879735, 0.29133315011679217, 0.2630160531850847, 0.36984498614160327, 0.3457952584065708]
2022-01-14 23:24:49:INFO:-------------Training local models-------------
2022-01-14 23:25:21:INFO:-------------Aggregating local models-------------
2022-01-14 23:25:21:INFO:-------------Round number: 115-------------
2022-01-14 23:25:21:INFO:-------------Sending models-------------
2022-01-14 23:25:21:INFO:-------------Evaluating models-------------
2022-01-14 23:25:21:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:25:21:INFO:Accuracy = [0.9017177647314634, 0.9502065666449228, 0.903239834746684, 0.9317242878886715, 0.9447706023048489, 0.9028049575994781, 0.9193302891933028, 0.9180256577516851, 0.8999782561426397, 0.8799739073711677]
2022-01-14 23:25:21:INFO:Loss = [0.2730554851883158, 0.10869929052983866, 0.35223284939997423, 0.20097009450423065, 0.18111128682653962, 0.27786330683819294, 0.291223799648809, 0.262954396276617, 0.370010627813368, 0.3455534423474659]
2022-01-14 23:25:21:INFO:-------------Training local models-------------
2022-01-14 23:25:53:INFO:-------------Aggregating local models-------------
2022-01-14 23:25:53:INFO:-------------Round number: 116-------------
2022-01-14 23:25:53:INFO:-------------Sending models-------------
2022-01-14 23:25:53:INFO:-------------Evaluating models-------------
2022-01-14 23:25:53:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:25:53:INFO:Accuracy = [0.9017177647314634, 0.9502065666449228, 0.903239834746684, 0.9319417264622744, 0.9447706023048489, 0.9028049575994781, 0.9193302891933028, 0.9178082191780822, 0.9001956947162426, 0.8801913459447706]
2022-01-14 23:25:53:INFO:Loss = [0.27289527498466765, 0.10855136127929288, 0.35214815707502645, 0.2009910615542784, 0.18102362355228527, 0.27787982576105896, 0.29111535277120903, 0.26289396006435767, 0.37017459258781216, 0.34531745480110854]
2022-01-14 23:25:53:INFO:-------------Training local models-------------
2022-01-14 23:26:25:INFO:-------------Aggregating local models-------------
2022-01-14 23:26:25:INFO:-------------Round number: 117-------------
2022-01-14 23:26:25:INFO:-------------Sending models-------------
2022-01-14 23:26:25:INFO:-------------Evaluating models-------------
2022-01-14 23:26:25:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:26:25:INFO:Accuracy = [0.9017177647314634, 0.9502065666449228, 0.903239834746684, 0.9319417264622744, 0.9447706023048489, 0.9028049575994781, 0.9193302891933028, 0.9173733420308763, 0.9001956947162426, 0.8801913459447706]
2022-01-14 23:26:25:INFO:Loss = [0.2727383147857565, 0.10840646593937188, 0.352063871221427, 0.2010119853755126, 0.1809376077050305, 0.27789682803265864, 0.29100856510372386, 0.2628369019465839, 0.37033779762382957, 0.3450846335482273]
2022-01-14 23:26:25:INFO:-------------Training local models-------------
2022-01-14 23:26:57:INFO:-------------Aggregating local models-------------
2022-01-14 23:26:57:INFO:-------------Round number: 118-------------
2022-01-14 23:26:57:INFO:-------------Sending models-------------
2022-01-14 23:26:57:INFO:-------------Evaluating models-------------
2022-01-14 23:26:57:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:26:57:INFO:Accuracy = [0.9017177647314634, 0.9502065666449228, 0.9030223961730811, 0.9319417264622744, 0.9447706023048489, 0.9028049575994781, 0.9193302891933028, 0.9175907806044792, 0.9001956947162426, 0.8806262230919765]
2022-01-14 23:26:57:INFO:Loss = [0.2725863691712452, 0.10826411532689409, 0.3519853076867287, 0.20103413134353343, 0.180853599093691, 0.27791480583627914, 0.290904567565845, 0.26278221265261975, 0.3705018521348691, 0.34485976012780245]
2022-01-14 23:26:57:INFO:-------------Training local models-------------
2022-01-14 23:27:28:INFO:-------------Aggregating local models-------------
2022-01-14 23:27:29:INFO:-------------Round number: 119-------------
2022-01-14 23:27:29:INFO:-------------Sending models-------------
2022-01-14 23:27:29:INFO:-------------Evaluating models-------------
2022-01-14 23:27:29:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:27:29:INFO:Accuracy = [0.9017177647314634, 0.9502065666449228, 0.9030223961730811, 0.9319417264622744, 0.9447706023048489, 0.9030223961730811, 0.9193302891933028, 0.9175907806044792, 0.9006305718634485, 0.8810611002391824]
2022-01-14 23:27:29:INFO:Loss = [0.27243774794171716, 0.10812391868869325, 0.35190767260125516, 0.20105627478893118, 0.18077186845539978, 0.27793248445501595, 0.2908022608531878, 0.2627309089150937, 0.37066456315462765, 0.3446389489765827]
2022-01-14 23:27:29:INFO:-------------Training local models-------------
2022-01-14 23:28:00:INFO:-------------Aggregating local models-------------
2022-01-14 23:28:01:INFO:-------------Round number: 120-------------
2022-01-14 23:28:01:INFO:-------------Sending models-------------
2022-01-14 23:28:01:INFO:-------------Evaluating models-------------
2022-01-14 23:28:01:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:28:01:INFO:Accuracy = [0.9017177647314634, 0.9506414437921287, 0.903239834746684, 0.9319417264622744, 0.9447706023048489, 0.9030223961730811, 0.9193302891933028, 0.9175907806044792, 0.9008480104370515, 0.8812785388127854]
2022-01-14 23:28:01:INFO:Loss = [0.2722956680371483, 0.10798704704288448, 0.35183465177207, 0.20107899486130118, 0.18069295331094679, 0.2779516059442363, 0.2907033312471439, 0.26267968930599606, 0.37082640232766284, 0.34442446420232103]
2022-01-14 23:28:01:INFO:-------------Training local models-------------
2022-01-14 23:28:32:INFO:-------------Aggregating local models-------------
2022-01-14 23:28:33:INFO:-------------Round number: 121-------------
2022-01-14 23:28:33:INFO:-------------Sending models-------------
2022-01-14 23:28:33:INFO:-------------Evaluating models-------------
2022-01-14 23:28:33:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:28:33:INFO:Accuracy = [0.9017177647314634, 0.9512937595129376, 0.903239834746684, 0.9319417264622744, 0.9452054794520548, 0.903239834746684, 0.9193302891933028, 0.9175907806044792, 0.9008480104370515, 0.8814959773863883]
2022-01-14 23:28:33:INFO:Loss = [0.272155524358977, 0.10785415360355907, 0.3517595919630124, 0.20110270752807366, 0.18061486774843707, 0.2779739293594885, 0.29060497414452335, 0.26263306353623284, 0.37098556177906394, 0.34421262016767873]
2022-01-14 23:28:33:INFO:-------------Training local models-------------
2022-01-14 23:29:04:INFO:-------------Aggregating local models-------------
2022-01-14 23:29:05:INFO:-------------Round number: 122-------------
2022-01-14 23:29:05:INFO:-------------Sending models-------------
2022-01-14 23:29:05:INFO:-------------Evaluating models-------------
2022-01-14 23:29:05:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:29:05:INFO:Accuracy = [0.9017177647314634, 0.9517286366601435, 0.903239834746684, 0.9319417264622744, 0.9452054794520548, 0.903239834746684, 0.9193302891933028, 0.9173733420308763, 0.9008480104370515, 0.8812785388127854]
2022-01-14 23:29:05:INFO:Loss = [0.2720244783634253, 0.10772397364605163, 0.35169104846196614, 0.20112715546226717, 0.18053938213782877, 0.2779982572683524, 0.29051222465347004, 0.26258752610812675, 0.3711458760224891, 0.3440076639919131]
2022-01-14 23:29:05:INFO:-------------Training local models-------------
2022-01-14 23:29:36:INFO:-------------Aggregating local models-------------
2022-01-14 23:29:37:INFO:-------------Round number: 123-------------
2022-01-14 23:29:37:INFO:-------------Sending models-------------
2022-01-14 23:29:37:INFO:-------------Evaluating models-------------
2022-01-14 23:29:37:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:29:37:INFO:Accuracy = [0.9017177647314634, 0.9517286366601435, 0.903239834746684, 0.9319417264622744, 0.9452054794520548, 0.903239834746684, 0.9193302891933028, 0.9175907806044792, 0.9008480104370515, 0.8814959773863883]
2022-01-14 23:29:37:INFO:Loss = [0.2718955731920793, 0.10759811754376211, 0.35162582800519687, 0.20114920557216792, 0.18046583073835337, 0.27802527887361883, 0.2904212988256777, 0.26254278998716546, 0.37130699035783654, 0.34380934927252843]
2022-01-14 23:29:37:INFO:-------------Training local models-------------
2022-01-14 23:30:08:INFO:-------------Aggregating local models-------------
2022-01-14 23:30:09:INFO:-------------Round number: 124-------------
2022-01-14 23:30:09:INFO:-------------Sending models-------------
2022-01-14 23:30:09:INFO:-------------Evaluating models-------------
2022-01-14 23:30:09:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:30:09:INFO:Accuracy = [0.9017177647314634, 0.9517286366601435, 0.903457273320287, 0.9319417264622744, 0.9452054794520548, 0.903457273320287, 0.9193302891933028, 0.9175907806044792, 0.9010654490106544, 0.8821482931071972]
2022-01-14 23:30:09:INFO:Loss = [0.2717697535583891, 0.10747299632367127, 0.35156312496177095, 0.2011718623396629, 0.18039665087561835, 0.2780508962803868, 0.29033271330006144, 0.26250138993237276, 0.37146629166803424, 0.34361311513974857]
2022-01-14 23:30:09:INFO:-------------Training local models-------------
2022-01-14 23:30:40:INFO:-------------Aggregating local models-------------
2022-01-14 23:30:41:INFO:-------------Round number: 125-------------
2022-01-14 23:30:41:INFO:-------------Sending models-------------
2022-01-14 23:30:41:INFO:-------------Evaluating models-------------
2022-01-14 23:30:41:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:30:41:INFO:Accuracy = [0.9017177647314634, 0.9517286366601435, 0.903457273320287, 0.9321591650358774, 0.9452054794520548, 0.9038921504674929, 0.9193302891933028, 0.9175907806044792, 0.9010654490106544, 0.8825831702544031]
2022-01-14 23:30:41:INFO:Loss = [0.27164743233368555, 0.10735249961323888, 0.3515042378093423, 0.2011944879990993, 0.18032920098662986, 0.27807924496483555, 0.29024636406929577, 0.26246221024355426, 0.3716271936852937, 0.3434228544472742]
2022-01-14 23:30:41:INFO:-------------Training local models-------------
2022-01-14 23:31:12:INFO:-------------Aggregating local models-------------
2022-01-14 23:31:13:INFO:-------------Round number: 126-------------
2022-01-14 23:31:13:INFO:-------------Sending models-------------
2022-01-14 23:31:13:INFO:-------------Evaluating models-------------
2022-01-14 23:31:13:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:31:13:INFO:Accuracy = [0.9017177647314634, 0.9517286366601435, 0.903457273320287, 0.9321591650358774, 0.9452054794520548, 0.9038921504674929, 0.9193302891933028, 0.9178082191780822, 0.9010654490106544, 0.882800608828006]
2022-01-14 23:31:13:INFO:Loss = [0.2715293348296266, 0.10723391710685637, 0.3514462730263425, 0.20121939602680028, 0.18026492735433516, 0.2781087118908841, 0.2901605971137465, 0.26242425560537463, 0.3717864963486012, 0.34323492566113784]
2022-01-14 23:31:13:INFO:-------------Training local models-------------
2022-01-14 23:31:44:INFO:-------------Aggregating local models-------------
2022-01-14 23:31:45:INFO:-------------Round number: 127-------------
2022-01-14 23:31:45:INFO:-------------Sending models-------------
2022-01-14 23:31:45:INFO:-------------Evaluating models-------------
2022-01-14 23:31:45:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:31:45:INFO:Accuracy = [0.9017177647314634, 0.9519460752337464, 0.9036747118938899, 0.9321591650358774, 0.9452054794520548, 0.9038921504674929, 0.9193302891933028, 0.9178082191780822, 0.9010654490106544, 0.883018047401609]
2022-01-14 23:31:45:INFO:Loss = [0.27141589071605376, 0.10711696235290438, 0.35139119185814194, 0.20124300882447782, 0.18020301593841367, 0.2781402574324253, 0.29007755238775706, 0.2623914115893182, 0.37194570818725153, 0.3430524212906252]
2022-01-14 23:31:45:INFO:-------------Training local models-------------
2022-01-14 23:32:16:INFO:-------------Aggregating local models-------------
2022-01-14 23:32:17:INFO:-------------Round number: 128-------------
2022-01-14 23:32:17:INFO:-------------Sending models-------------
2022-01-14 23:32:17:INFO:-------------Evaluating models-------------
2022-01-14 23:32:17:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:32:17:INFO:Accuracy = [0.9017177647314634, 0.9521635138073494, 0.9036747118938899, 0.9319417264622744, 0.9452054794520548, 0.9038921504674929, 0.9193302891933028, 0.9178082191780822, 0.9010654490106544, 0.883018047401609]
2022-01-14 23:32:17:INFO:Loss = [0.27130690566345095, 0.10700127024710157, 0.3513392826863508, 0.201267180658327, 0.18014019327625747, 0.2781741944177808, 0.2899974159670504, 0.26235925107629615, 0.37210359380402, 0.3428738596487545]
2022-01-14 23:32:17:INFO:-------------Training local models-------------
2022-01-14 23:32:48:INFO:-------------Aggregating local models-------------
2022-01-14 23:32:49:INFO:-------------Round number: 129-------------
2022-01-14 23:32:49:INFO:-------------Sending models-------------
2022-01-14 23:32:49:INFO:-------------Evaluating models-------------
2022-01-14 23:32:49:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:32:49:INFO:Accuracy = [0.9019352033050663, 0.9521635138073494, 0.9036747118938899, 0.9319417264622744, 0.9452054794520548, 0.9041095890410958, 0.9195477277669059, 0.9178082191780822, 0.9012828875842575, 0.883235485975212]
2022-01-14 23:32:49:INFO:Loss = [0.2712030494342563, 0.10688769377406669, 0.351287911470306, 0.20129177661960154, 0.1800795779926098, 0.2782071365330218, 0.28991822293568037, 0.2623292952184323, 0.37225968997670894, 0.34269758807493717]
2022-01-14 23:32:49:INFO:-------------Training local models-------------
2022-01-14 23:33:20:INFO:-------------Aggregating local models-------------
2022-01-14 23:33:21:INFO:-------------Round number: 130-------------
2022-01-14 23:33:21:INFO:-------------Sending models-------------
2022-01-14 23:33:21:INFO:-------------Evaluating models-------------
2022-01-14 23:33:21:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:33:21:INFO:Accuracy = [0.9019352033050663, 0.9523809523809523, 0.903457273320287, 0.9319417264622744, 0.9454229180256577, 0.9043270276146989, 0.9197651663405088, 0.9178082191780822, 0.9012828875842575, 0.8838878016960209]
2022-01-14 23:33:21:INFO:Loss = [0.27109865287983703, 0.10677912155362243, 0.3512393256620037, 0.2013170333877258, 0.18002193546488943, 0.2782424590749704, 0.28984191721604274, 0.26230107670053937, 0.37241422109203515, 0.34252529435754725]
2022-01-14 23:33:21:INFO:-------------Training local models-------------
2022-01-14 23:33:52:INFO:-------------Aggregating local models-------------
2022-01-14 23:33:53:INFO:-------------Round number: 131-------------
2022-01-14 23:33:53:INFO:-------------Sending models-------------
2022-01-14 23:33:53:INFO:-------------Evaluating models-------------
2022-01-14 23:33:53:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:33:53:INFO:Accuracy = [0.9019352033050663, 0.9523809523809523, 0.903457273320287, 0.9321591650358774, 0.9454229180256577, 0.9045444661883018, 0.9197651663405088, 0.9180256577516851, 0.9012828875842575, 0.8836703631224179]
2022-01-14 23:33:53:INFO:Loss = [0.27099872803034086, 0.10667120702413344, 0.35119190149291574, 0.2013405943040887, 0.17996336348313757, 0.27827642356509735, 0.289765018349519, 0.26227236256891695, 0.3725687445217226, 0.34235513055519184]
2022-01-14 23:33:53:INFO:-------------Training local models-------------
2022-01-14 23:34:24:INFO:-------------Aggregating local models-------------
2022-01-14 23:34:25:INFO:-------------Round number: 132-------------
2022-01-14 23:34:25:INFO:-------------Sending models-------------
2022-01-14 23:34:25:INFO:-------------Evaluating models-------------
2022-01-14 23:34:25:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:34:25:INFO:Accuracy = [0.9019352033050663, 0.9523809523809523, 0.903239834746684, 0.9323766036094803, 0.9454229180256577, 0.9045444661883018, 0.9197651663405088, 0.9180256577516851, 0.9012828875842575, 0.8836703631224179]
2022-01-14 23:34:25:INFO:Loss = [0.27090127802059355, 0.10656586971187257, 0.3511469359028317, 0.2013634216616134, 0.17990833064379977, 0.27831012880680783, 0.2896912426785967, 0.2622440013344903, 0.3727216536591562, 0.342188391040752]
2022-01-14 23:34:25:INFO:-------------Training local models-------------
2022-01-14 23:34:56:INFO:-------------Aggregating local models-------------
2022-01-14 23:34:57:INFO:-------------Round number: 133-------------
2022-01-14 23:34:57:INFO:-------------Sending models-------------
2022-01-14 23:34:57:INFO:-------------Evaluating models-------------
2022-01-14 23:34:57:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:34:57:INFO:Accuracy = [0.9019352033050663, 0.9528158295281582, 0.903239834746684, 0.9323766036094803, 0.9454229180256577, 0.9045444661883018, 0.9197651663405088, 0.9180256577516851, 0.9012828875842575, 0.8841052402696238]
2022-01-14 23:34:57:INFO:Loss = [0.27080639049832766, 0.1064629926729408, 0.3511017312739576, 0.20138616034012738, 0.17985442128795334, 0.2783455105451249, 0.2896168387398753, 0.26221682485947095, 0.3728728228517089, 0.34202370691153117]
2022-01-14 23:34:57:INFO:-------------Training local models-------------
2022-01-14 23:35:28:INFO:-------------Aggregating local models-------------
2022-01-14 23:35:28:INFO:-------------Round number: 134-------------
2022-01-14 23:35:28:INFO:-------------Sending models-------------
2022-01-14 23:35:29:INFO:-------------Evaluating models-------------
2022-01-14 23:35:29:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:35:29:INFO:Accuracy = [0.9019352033050663, 0.9536855838225701, 0.903239834746684, 0.9323766036094803, 0.9454229180256577, 0.9045444661883018, 0.9197651663405088, 0.9180256577516851, 0.9012828875842575, 0.8841052402696238]
2022-01-14 23:35:29:INFO:Loss = [0.270712201700855, 0.10636185342489002, 0.3510586744372108, 0.20140978663404657, 0.17980200451796383, 0.27838124793411073, 0.2895450002323559, 0.26219050425614, 0.3730207149083947, 0.3418613351527069]
2022-01-14 23:35:29:INFO:-------------Training local models-------------
2022-01-14 23:36:00:INFO:-------------Aggregating local models-------------
2022-01-14 23:36:00:INFO:-------------Round number: 135-------------
2022-01-14 23:36:00:INFO:-------------Sending models-------------
2022-01-14 23:36:01:INFO:-------------Evaluating models-------------
2022-01-14 23:36:01:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:36:01:INFO:Accuracy = [0.9019352033050663, 0.9536855838225701, 0.903239834746684, 0.9323766036094803, 0.9454229180256577, 0.9045444661883018, 0.9197651663405088, 0.9180256577516851, 0.9012828875842575, 0.8841052402696238]
2022-01-14 23:36:01:INFO:Loss = [0.2706228125569309, 0.10626214883324607, 0.35101714792323085, 0.20143306905811503, 0.17975123888963268, 0.27841675621051626, 0.2894745190828999, 0.2621663138535787, 0.3731704113948926, 0.3417022634884571]
2022-01-14 23:36:01:INFO:-------------Training local models-------------
2022-01-14 23:36:32:INFO:-------------Aggregating local models-------------
2022-01-14 23:36:32:INFO:-------------Round number: 136-------------
2022-01-14 23:36:32:INFO:-------------Sending models-------------
2022-01-14 23:36:33:INFO:-------------Evaluating models-------------
2022-01-14 23:36:33:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:36:33:INFO:Accuracy = [0.9019352033050663, 0.9536855838225701, 0.903457273320287, 0.9323766036094803, 0.9454229180256577, 0.9047619047619048, 0.9197651663405088, 0.9182430963252881, 0.9012828875842575, 0.8841052402696238]
2022-01-14 23:36:33:INFO:Loss = [0.2705346586036378, 0.10616269104428663, 0.35097704788320977, 0.2014570895105955, 0.1797021100008734, 0.278451409861009, 0.2894058886791955, 0.2621430759020553, 0.3733182063308748, 0.34154458516297115]
2022-01-14 23:36:33:INFO:-------------Training local models-------------
2022-01-14 23:37:04:INFO:-------------Aggregating local models-------------
2022-01-14 23:37:04:INFO:-------------Round number: 137-------------
2022-01-14 23:37:04:INFO:-------------Sending models-------------
2022-01-14 23:37:05:INFO:-------------Evaluating models-------------
2022-01-14 23:37:05:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:37:05:INFO:Accuracy = [0.9021526418786693, 0.9539030223961731, 0.903457273320287, 0.9323766036094803, 0.9454229180256577, 0.9047619047619048, 0.9197651663405088, 0.9182430963252881, 0.9012828875842575, 0.8841052402696238]
2022-01-14 23:37:05:INFO:Loss = [0.27044876391842, 0.10606506844128134, 0.35093811488796967, 0.2014810745793489, 0.17965487932853577, 0.27848981124531497, 0.28933700925435935, 0.2621189790216188, 0.37346439657424124, 0.3413884189266738]
2022-01-14 23:37:05:INFO:-------------Training local models-------------
2022-01-14 23:37:36:INFO:-------------Aggregating local models-------------
2022-01-14 23:37:36:INFO:-------------Round number: 138-------------
2022-01-14 23:37:36:INFO:-------------Sending models-------------
2022-01-14 23:37:36:INFO:-------------Evaluating models-------------
2022-01-14 23:37:37:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:37:37:INFO:Accuracy = [0.9021526418786693, 0.9539030223961731, 0.903239834746684, 0.9325940421830833, 0.9454229180256577, 0.9047619047619048, 0.9197651663405088, 0.9182430963252881, 0.9012828875842575, 0.8836703631224179]
2022-01-14 23:37:37:INFO:Loss = [0.27036406342423774, 0.1059702092166464, 0.35090177547634704, 0.20150414288623295, 0.17960884709360211, 0.27852814123641234, 0.28927104853130303, 0.2620991004678031, 0.3736100613471704, 0.3412357213571215]
2022-01-14 23:37:37:INFO:-------------Training local models-------------
2022-01-14 23:38:08:INFO:-------------Aggregating local models-------------
2022-01-14 23:38:08:INFO:-------------Round number: 139-------------
2022-01-14 23:38:08:INFO:-------------Sending models-------------
2022-01-14 23:38:08:INFO:-------------Evaluating models-------------
2022-01-14 23:38:09:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:38:09:INFO:Accuracy = [0.9021526418786693, 0.9539030223961731, 0.9030223961730811, 0.9325940421830833, 0.9454229180256577, 0.9051967819091107, 0.9197651663405088, 0.918460534898891, 0.9012828875842575, 0.8836703631224179]
2022-01-14 23:38:09:INFO:Loss = [0.27028319471743967, 0.10587645712347239, 0.3508657881954687, 0.2015266416504752, 0.17956301434285954, 0.278565719166571, 0.28920566594414404, 0.26207890184238125, 0.3737544447402277, 0.3410850769822487]
2022-01-14 23:38:09:INFO:-------------Training local models-------------
2022-01-14 23:38:40:INFO:-------------Aggregating local models-------------
2022-01-14 23:38:40:INFO:-------------Round number: 140-------------
2022-01-14 23:38:40:INFO:-------------Sending models-------------
2022-01-14 23:38:40:INFO:-------------Evaluating models-------------
2022-01-14 23:38:41:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:38:41:INFO:Accuracy = [0.9021526418786693, 0.954120460969776, 0.9030223961730811, 0.9325940421830833, 0.9454229180256577, 0.9056316590563166, 0.9197651663405088, 0.918460534898891, 0.9012828875842575, 0.8838878016960209]
2022-01-14 23:38:41:INFO:Loss = [0.2702048015455979, 0.10578373225861981, 0.35082989297954287, 0.20154852890335867, 0.17951918501524058, 0.2786022940874781, 0.28914163952822086, 0.26205914168792194, 0.3738990477011884, 0.34093603075877443]
2022-01-14 23:38:41:INFO:-------------Training local models-------------
2022-01-14 23:39:12:INFO:-------------Aggregating local models-------------
2022-01-14 23:39:12:INFO:-------------Round number: 141-------------
2022-01-14 23:39:12:INFO:-------------Sending models-------------
2022-01-14 23:39:12:INFO:-------------Evaluating models-------------
2022-01-14 23:39:12:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:39:12:INFO:Accuracy = [0.9021526418786693, 0.9539030223961731, 0.9028049575994781, 0.9325940421830833, 0.9454229180256577, 0.9058490976299195, 0.9197651663405088, 0.918460534898891, 0.9012828875842575, 0.8838878016960209]
2022-01-14 23:39:12:INFO:Loss = [0.27012786175151987, 0.10569339011262141, 0.3507948734260746, 0.20157030150725513, 0.17947652866318609, 0.27864310248271135, 0.2890787493991963, 0.2620422261643232, 0.374041951303892, 0.34079163806390134]
2022-01-14 23:39:12:INFO:-------------Training local models-------------
2022-01-14 23:39:44:INFO:-------------Aggregating local models-------------
2022-01-14 23:39:44:INFO:-------------Round number: 142-------------
2022-01-14 23:39:44:INFO:-------------Sending models-------------
2022-01-14 23:39:44:INFO:-------------Evaluating models-------------
2022-01-14 23:39:44:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:39:44:INFO:Accuracy = [0.9021526418786693, 0.9539030223961731, 0.9030223961730811, 0.9325940421830833, 0.9454229180256577, 0.9060665362035225, 0.9199826049141118, 0.9182430963252881, 0.9012828875842575, 0.8838878016960209]
2022-01-14 23:39:44:INFO:Loss = [0.2700542957600585, 0.1056048450106436, 0.3507626123782715, 0.2015914859809394, 0.17943393115551395, 0.2786837139231415, 0.28901739411527144, 0.26202490780944954, 0.3741824135714814, 0.3406492900263563]
2022-01-14 23:39:44:INFO:-------------Training local models-------------
2022-01-14 23:40:16:INFO:-------------Aggregating local models-------------
2022-01-14 23:40:16:INFO:-------------Round number: 143-------------
2022-01-14 23:40:16:INFO:-------------Sending models-------------
2022-01-14 23:40:16:INFO:-------------Evaluating models-------------
2022-01-14 23:40:16:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:40:16:INFO:Accuracy = [0.9021526418786693, 0.9539030223961731, 0.903239834746684, 0.9325940421830833, 0.9454229180256577, 0.9060665362035225, 0.9199826049141118, 0.9180256577516851, 0.9012828875842575, 0.8841052402696238]
2022-01-14 23:40:16:INFO:Loss = [0.26998333488973497, 0.10551689756586721, 0.3507299443570078, 0.20161339989117863, 0.1793924720427526, 0.27872192130546497, 0.2889564358990758, 0.2620088013506568, 0.3743251203814243, 0.34050848268994466]
2022-01-14 23:40:16:INFO:-------------Training local models-------------
2022-01-14 23:40:48:INFO:-------------Aggregating local models-------------
2022-01-14 23:40:48:INFO:-------------Round number: 144-------------
2022-01-14 23:40:48:INFO:-------------Sending models-------------
2022-01-14 23:40:48:INFO:-------------Evaluating models-------------
2022-01-14 23:40:48:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:40:48:INFO:Accuracy = [0.9021526418786693, 0.9539030223961731, 0.903457273320287, 0.9325940421830833, 0.9454229180256577, 0.9060665362035225, 0.9199826049141118, 0.9180256577516851, 0.9012828875842575, 0.8841052402696238]
2022-01-14 23:40:48:INFO:Loss = [0.2699133998242461, 0.10543056605705611, 0.350698328890663, 0.20163478835145895, 0.17935383110210334, 0.2787632025139718, 0.28889583548732733, 0.261992906934513, 0.37446386223823913, 0.340369881843321]
2022-01-14 23:40:48:INFO:-------------Training local models-------------
2022-01-14 23:41:20:INFO:-------------Aggregating local models-------------
2022-01-14 23:41:20:INFO:-------------Round number: 145-------------
2022-01-14 23:41:20:INFO:-------------Sending models-------------
2022-01-14 23:41:20:INFO:-------------Evaluating models-------------
2022-01-14 23:41:20:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:41:20:INFO:Accuracy = [0.9021526418786693, 0.9539030223961731, 0.903457273320287, 0.9325940421830833, 0.9454229180256577, 0.9060665362035225, 0.9199826049141118, 0.9180256577516851, 0.9012828875842575, 0.8841052402696238]
2022-01-14 23:41:20:INFO:Loss = [0.2698465195107179, 0.10534629426732746, 0.350670272593357, 0.20165598362583478, 0.17931499199227643, 0.27880474288907026, 0.2888376880395179, 0.2619781203359123, 0.37460223424783545, 0.34023525501808916]
2022-01-14 23:41:20:INFO:-------------Training local models-------------
2022-01-14 23:41:52:INFO:-------------Aggregating local models-------------
2022-01-14 23:41:52:INFO:-------------Round number: 146-------------
2022-01-14 23:41:52:INFO:-------------Sending models-------------
2022-01-14 23:41:52:INFO:-------------Evaluating models-------------
2022-01-14 23:41:52:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:41:52:INFO:Accuracy = [0.9021526418786693, 0.9539030223961731, 0.903457273320287, 0.9325940421830833, 0.9454229180256577, 0.9060665362035225, 0.9199826049141118, 0.9180256577516851, 0.9012828875842575, 0.8841052402696238]
2022-01-14 23:41:52:INFO:Loss = [0.2697812417410138, 0.10526292298529845, 0.35064127654046595, 0.2016772563186019, 0.17927632880782712, 0.2788438008641636, 0.28877910806288876, 0.26196302499705615, 0.37474224504060005, 0.3401017879534792]
2022-01-14 23:41:52:INFO:-------------Training local models-------------
2022-01-14 23:42:24:INFO:-------------Aggregating local models-------------
2022-01-14 23:42:24:INFO:-------------Round number: 147-------------
2022-01-14 23:42:24:INFO:-------------Sending models-------------
2022-01-14 23:42:24:INFO:-------------Evaluating models-------------
2022-01-14 23:42:24:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:42:24:INFO:Accuracy = [0.9025875190258752, 0.954120460969776, 0.903457273320287, 0.9325940421830833, 0.9454229180256577, 0.9060665362035225, 0.9199826049141118, 0.9180256577516851, 0.9012828875842575, 0.8841052402696238]
2022-01-14 23:42:24:INFO:Loss = [0.2697176265538616, 0.10518259046829163, 0.3506114256441206, 0.20169711522359832, 0.1792404052552437, 0.2788837122144645, 0.2887212439454062, 0.2619498290187268, 0.3748778589473652, 0.3399708296728477]
2022-01-14 23:42:24:INFO:-------------Training local models-------------
2022-01-14 23:42:56:INFO:-------------Aggregating local models-------------
2022-01-14 23:42:56:INFO:-------------Round number: 148-------------
2022-01-14 23:42:56:INFO:-------------Sending models-------------
2022-01-14 23:42:56:INFO:-------------Evaluating models-------------
2022-01-14 23:42:56:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:42:56:INFO:Accuracy = [0.9028049575994781, 0.954120460969776, 0.903457273320287, 0.9325940421830833, 0.9454229180256577, 0.9060665362035225, 0.9199826049141118, 0.9180256577516851, 0.9012828875842575, 0.8843226788432268]
2022-01-14 23:42:56:INFO:Loss = [0.2696556413145206, 0.10510403040141059, 0.35058541069634275, 0.20171844867378513, 0.17920506184362742, 0.27892620485616904, 0.28866644463760877, 0.26193778830904346, 0.37501317203693235, 0.33984388766958534]
2022-01-14 23:42:56:INFO:-------------Training local models-------------
2022-01-14 23:43:28:INFO:-------------Aggregating local models-------------
2022-01-14 23:43:28:INFO:-------------Round number: 149-------------
2022-01-14 23:43:28:INFO:-------------Sending models-------------
2022-01-14 23:43:28:INFO:-------------Evaluating models-------------
2022-01-14 23:43:28:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:43:28:INFO:Accuracy = [0.9030223961730811, 0.954120460969776, 0.903457273320287, 0.9325940421830833, 0.9454229180256577, 0.9060665362035225, 0.9199826049141118, 0.9180256577516851, 0.9012828875842575, 0.8845401174168297]
2022-01-14 23:43:28:INFO:Loss = [0.2695945605781852, 0.10502692384844659, 0.35055922508672804, 0.20173962441119433, 0.17917106893899856, 0.2789608321624807, 0.28861080409040746, 0.2619250189377808, 0.3751484253755446, 0.33971711340422156]
2022-01-14 23:43:28:INFO:-------------Training local models-------------
2022-01-14 23:44:00:INFO:-------------Aggregating local models-------------
2022-01-14 23:44:00:INFO:-------------Round number: 150-------------
2022-01-14 23:44:00:INFO:-------------Sending models-------------
2022-01-14 23:44:00:INFO:-------------Evaluating models-------------
2022-01-14 23:44:00:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:44:00:INFO:Accuracy = [0.9030223961730811, 0.954337899543379, 0.903457273320287, 0.9325940421830833, 0.9454229180256577, 0.9060665362035225, 0.9199826049141118, 0.9178082191780822, 0.9012828875842575, 0.8845401174168297]
2022-01-14 23:44:00:INFO:Loss = [0.2695356969528273, 0.10495167523067142, 0.35053384856691605, 0.2017592865915731, 0.17913889290030743, 0.2789921818437482, 0.2885573956844295, 0.2619124447084798, 0.37528182835267826, 0.339593234676406]
2022-01-14 23:44:00:INFO:-------------Training local models-------------
2022-01-14 23:44:32:INFO:-------------Aggregating local models-------------
2022-01-14 23:44:32:INFO:-------------Round number: 151-------------
2022-01-14 23:44:32:INFO:-------------Sending models-------------
2022-01-14 23:44:32:INFO:-------------Evaluating models-------------
2022-01-14 23:44:32:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:44:32:INFO:Accuracy = [0.9030223961730811, 0.954337899543379, 0.903457273320287, 0.9325940421830833, 0.9456403565992607, 0.9062839747771254, 0.9199826049141118, 0.9178082191780822, 0.9012828875842575, 0.8847575559904327]
2022-01-14 23:44:32:INFO:Loss = [0.26947868192964397, 0.10487793113664572, 0.35051068963130516, 0.20178019291168495, 0.17910683647229064, 0.2790280886506242, 0.28850533473418805, 0.2619012562542816, 0.37541661421971834, 0.339471364449899]
2022-01-14 23:44:32:INFO:-------------Training local models-------------
2022-01-14 23:45:04:INFO:-------------Aggregating local models-------------
2022-01-14 23:45:04:INFO:-------------Round number: 152-------------
2022-01-14 23:45:04:INFO:-------------Sending models-------------
2022-01-14 23:45:04:INFO:-------------Evaluating models-------------
2022-01-14 23:45:04:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:45:04:INFO:Accuracy = [0.9028049575994781, 0.9545553381169819, 0.903457273320287, 0.9325940421830833, 0.9456403565992607, 0.9062839747771254, 0.9199826049141118, 0.9178082191780822, 0.9012828875842575, 0.8851924331376386]
2022-01-14 23:45:04:INFO:Loss = [0.2694226888830626, 0.10480610627836719, 0.35048675966237414, 0.2017999217944803, 0.17907662294543894, 0.2790611551597246, 0.28845563372205124, 0.2618916265729616, 0.37554644438121754, 0.3393519665101419]
2022-01-14 23:45:04:INFO:-------------Training local models-------------
2022-01-14 23:45:36:INFO:-------------Aggregating local models-------------
2022-01-14 23:45:36:INFO:-------------Round number: 153-------------
2022-01-14 23:45:36:INFO:-------------Sending models-------------
2022-01-14 23:45:36:INFO:-------------Evaluating models-------------
2022-01-14 23:45:36:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:45:36:INFO:Accuracy = [0.9028049575994781, 0.9547727766905849, 0.903457273320287, 0.9325940421830833, 0.9456403565992607, 0.9062839747771254, 0.9199826049141118, 0.9178082191780822, 0.9012828875842575, 0.8854098717112415]
2022-01-14 23:45:36:INFO:Loss = [0.26936912551890635, 0.10473569469742534, 0.3504643147729355, 0.20181995878684048, 0.1790467378973528, 0.2790994611516604, 0.2884059650637549, 0.2618831865412328, 0.375676888080921, 0.3392358204210982]
2022-01-14 23:45:36:INFO:-------------Training local models-------------
2022-01-14 23:46:08:INFO:-------------Aggregating local models-------------
2022-01-14 23:46:08:INFO:-------------Round number: 154-------------
2022-01-14 23:46:08:INFO:-------------Sending models-------------
2022-01-14 23:46:08:INFO:-------------Evaluating models-------------
2022-01-14 23:46:08:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:46:08:INFO:Accuracy = [0.9028049575994781, 0.9547727766905849, 0.903457273320287, 0.9325940421830833, 0.9456403565992607, 0.9062839747771254, 0.9199826049141118, 0.9175907806044792, 0.9015003261578604, 0.8856273102848445]
2022-01-14 23:46:08:INFO:Loss = [0.2693171125610649, 0.10466714927017891, 0.3504443237116343, 0.20184012483977928, 0.17901670340811532, 0.279137134483707, 0.28835836315735913, 0.261875870011588, 0.37580572146716607, 0.33912067566109305]
2022-01-14 23:46:08:INFO:-------------Training local models-------------
2022-01-14 23:46:39:INFO:-------------Aggregating local models-------------
2022-01-14 23:46:40:INFO:-------------Round number: 155-------------
2022-01-14 23:46:40:INFO:-------------Sending models-------------
2022-01-14 23:46:40:INFO:-------------Evaluating models-------------
2022-01-14 23:46:40:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:46:40:INFO:Accuracy = [0.9028049575994781, 0.9547727766905849, 0.903457273320287, 0.9325940421830833, 0.9456403565992607, 0.9062839747771254, 0.9199826049141118, 0.9173733420308763, 0.9012828875842575, 0.8860621874320505]
2022-01-14 23:46:40:INFO:Loss = [0.26926629206347646, 0.10459993141787981, 0.3504255163583005, 0.20186016161055417, 0.17898721543308055, 0.27917816621060365, 0.2883124231609314, 0.2618689777378773, 0.3759341730483659, 0.33900820668026355]
2022-01-14 23:46:40:INFO:-------------Training local models-------------
2022-01-14 23:47:11:INFO:-------------Aggregating local models-------------
2022-01-14 23:47:12:INFO:-------------Round number: 156-------------
2022-01-14 23:47:12:INFO:-------------Sending models-------------
2022-01-14 23:47:12:INFO:-------------Evaluating models-------------
2022-01-14 23:47:12:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:47:12:INFO:Accuracy = [0.9028049575994781, 0.9547727766905849, 0.903457273320287, 0.9325940421830833, 0.9456403565992607, 0.9062839747771254, 0.9197651663405088, 0.9178082191780822, 0.9012828875842575, 0.8860621874320505]
2022-01-14 23:47:12:INFO:Loss = [0.2692173083000407, 0.10453290303786425, 0.3504039971267135, 0.20188072637083296, 0.17895855884660347, 0.27922167715328433, 0.2882650563139986, 0.26186324351920526, 0.37606201064190703, 0.33889739609769814]
2022-01-14 23:47:12:INFO:-------------Training local models-------------
2022-01-14 23:47:43:INFO:-------------Aggregating local models-------------
2022-01-14 23:47:44:INFO:-------------Round number: 157-------------
2022-01-14 23:47:44:INFO:-------------Sending models-------------
2022-01-14 23:47:44:INFO:-------------Evaluating models-------------
2022-01-14 23:47:44:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:47:44:INFO:Accuracy = [0.9028049575994781, 0.9547727766905849, 0.903457273320287, 0.9328114807566862, 0.9456403565992607, 0.9062839747771254, 0.9197651663405088, 0.9180256577516851, 0.9012828875842575, 0.8860621874320505]
2022-01-14 23:47:44:INFO:Loss = [0.26916848539064075, 0.1044674475196766, 0.35038516451733004, 0.20190235379944405, 0.1789309749594144, 0.27926418688608834, 0.2882184294050093, 0.2618589963062132, 0.37618728151269165, 0.3387878171636207]
2022-01-14 23:47:44:INFO:-------------Training local models-------------
2022-01-14 23:48:15:INFO:-------------Aggregating local models-------------
2022-01-14 23:48:16:INFO:-------------Round number: 158-------------
2022-01-14 23:48:16:INFO:-------------Sending models-------------
2022-01-14 23:48:16:INFO:-------------Evaluating models-------------
2022-01-14 23:48:16:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:48:16:INFO:Accuracy = [0.9028049575994781, 0.9549902152641878, 0.903457273320287, 0.9328114807566862, 0.9456403565992607, 0.9062839747771254, 0.9197651663405088, 0.9180256577516851, 0.9012828875842575, 0.8860621874320505]
2022-01-14 23:48:16:INFO:Loss = [0.2691211129127591, 0.10440274479779456, 0.3503657732758366, 0.2019244724380188, 0.17890238166269404, 0.279304621144063, 0.28817240985923814, 0.26185408318863834, 0.3763108063402514, 0.33868040322517945]
2022-01-14 23:48:16:INFO:-------------Training local models-------------
2022-01-14 23:48:47:INFO:-------------Aggregating local models-------------
2022-01-14 23:48:48:INFO:-------------Round number: 159-------------
2022-01-14 23:48:48:INFO:-------------Sending models-------------
2022-01-14 23:48:48:INFO:-------------Evaluating models-------------
2022-01-14 23:48:48:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:48:48:INFO:Accuracy = [0.9030223961730811, 0.9549902152641878, 0.9036747118938899, 0.9328114807566862, 0.9456403565992607, 0.9062839747771254, 0.9197651663405088, 0.9180256577516851, 0.9012828875842575, 0.8862796260056534]
2022-01-14 23:48:48:INFO:Loss = [0.26907553959718733, 0.10433865499867738, 0.35034785275300956, 0.20194593981608505, 0.17887506026070532, 0.27934644072057935, 0.28812744950190133, 0.2618495028008425, 0.3764338952396146, 0.3385754842488589]
2022-01-14 23:48:48:INFO:-------------Training local models-------------
2022-01-14 23:49:19:INFO:-------------Aggregating local models-------------
2022-01-14 23:49:20:INFO:-------------Round number: 160-------------
2022-01-14 23:49:20:INFO:-------------Sending models-------------
2022-01-14 23:49:20:INFO:-------------Evaluating models-------------
2022-01-14 23:49:20:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:49:20:INFO:Accuracy = [0.9030223961730811, 0.9549902152641878, 0.903457273320287, 0.9328114807566862, 0.9456403565992607, 0.9065014133507284, 0.9199826049141118, 0.9182430963252881, 0.9012828875842575, 0.8862796260056534]
2022-01-14 23:49:20:INFO:Loss = [0.26903031927113474, 0.1042752189696049, 0.3503307450507178, 0.20196774248893398, 0.1788477112057175, 0.279388360000364, 0.28808316662344763, 0.2618463506200156, 0.3765583852871302, 0.33847208953158325]
2022-01-14 23:49:20:INFO:-------------Training local models-------------
2022-01-14 23:49:51:INFO:-------------Aggregating local models-------------
2022-01-14 23:49:52:INFO:-------------Round number: 161-------------
2022-01-14 23:49:52:INFO:-------------Sending models-------------
2022-01-14 23:49:52:INFO:-------------Evaluating models-------------
2022-01-14 23:49:52:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:49:52:INFO:Accuracy = [0.9030223961730811, 0.9552076538377908, 0.903457273320287, 0.9328114807566862, 0.9456403565992607, 0.9065014133507284, 0.9199826049141118, 0.9182430963252881, 0.9012828875842575, 0.8862796260056534]
2022-01-14 23:49:52:INFO:Loss = [0.2689868415836336, 0.10421309349636465, 0.3503124567014299, 0.20198895909258893, 0.1788226037369591, 0.2794307053070056, 0.2880388338035866, 0.26184325365304695, 0.37667848632567813, 0.33836923831517224]
2022-01-14 23:49:52:INFO:-------------Training local models-------------
2022-01-14 23:50:23:INFO:-------------Aggregating local models-------------
2022-01-14 23:50:24:INFO:-------------Round number: 162-------------
2022-01-14 23:50:24:INFO:-------------Sending models-------------
2022-01-14 23:50:24:INFO:-------------Evaluating models-------------
2022-01-14 23:50:24:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:50:24:INFO:Accuracy = [0.9030223961730811, 0.9552076538377908, 0.903457273320287, 0.9328114807566862, 0.9456403565992607, 0.9065014133507284, 0.9199826049141118, 0.9182430963252881, 0.9012828875842575, 0.8862796260056534]
2022-01-14 23:50:24:INFO:Loss = [0.2689453859399742, 0.10415115270167358, 0.3502975026687583, 0.20200922971837498, 0.17879663792379422, 0.2794716362025963, 0.2879956490530305, 0.2618416109739016, 0.3767994233840834, 0.3382685816968848]
2022-01-14 23:50:24:INFO:-------------Training local models-------------
2022-01-14 23:50:55:INFO:-------------Aggregating local models-------------
2022-01-14 23:50:56:INFO:-------------Round number: 163-------------
2022-01-14 23:50:56:INFO:-------------Sending models-------------
2022-01-14 23:50:56:INFO:-------------Evaluating models-------------
2022-01-14 23:50:56:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:50:56:INFO:Accuracy = [0.9030223961730811, 0.9552076538377908, 0.9036747118938899, 0.9328114807566862, 0.9456403565992607, 0.9067188519243313, 0.9199826049141118, 0.9182430963252881, 0.9012828875842575, 0.8862796260056534]
2022-01-14 23:50:56:INFO:Loss = [0.268904251489105, 0.10409012825796833, 0.35028145077883766, 0.2020287855372581, 0.17877252614244962, 0.2795138273889766, 0.28795320400574576, 0.2618393376149084, 0.37692163429416975, 0.33816998083751487]
2022-01-14 23:50:56:INFO:-------------Training local models-------------
2022-01-14 23:51:27:INFO:-------------Aggregating local models-------------
2022-01-14 23:51:28:INFO:-------------Round number: 164-------------
2022-01-14 23:51:28:INFO:-------------Sending models-------------
2022-01-14 23:51:28:INFO:-------------Evaluating models-------------
2022-01-14 23:51:28:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:51:28:INFO:Accuracy = [0.9030223961730811, 0.9549902152641878, 0.9036747118938899, 0.9325940421830833, 0.9456403565992607, 0.9067188519243313, 0.9199826049141118, 0.9178082191780822, 0.9012828875842575, 0.8862796260056534]
2022-01-14 23:51:28:INFO:Loss = [0.26886507324090403, 0.10403032654818262, 0.35026493706698114, 0.20204820271220092, 0.1787482761224604, 0.27955189984784057, 0.28791164916214534, 0.2618383686509241, 0.37704061488748514, 0.3380723136422774]
2022-01-14 23:51:28:INFO:-------------Training local models-------------
2022-01-14 23:51:59:INFO:-------------Aggregating local models-------------
2022-01-14 23:52:00:INFO:-------------Round number: 165-------------
2022-01-14 23:52:00:INFO:-------------Sending models-------------
2022-01-14 23:52:00:INFO:-------------Evaluating models-------------
2022-01-14 23:52:00:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:52:00:INFO:Accuracy = [0.9030223961730811, 0.9549902152641878, 0.9036747118938899, 0.9325940421830833, 0.9456403565992607, 0.9067188519243313, 0.9199826049141118, 0.9178082191780822, 0.9012828875842575, 0.8864970645792564]
2022-01-14 23:52:00:INFO:Loss = [0.2688258942560704, 0.1039718256233727, 0.3502497941053925, 0.2020678844278187, 0.1787255707142063, 0.27959319510622, 0.2878706735603182, 0.2618373749233264, 0.3771587105291204, 0.33797631545652645]
2022-01-14 23:52:00:INFO:-------------Training local models-------------
2022-01-14 23:52:31:INFO:-------------Aggregating local models-------------
2022-01-14 23:52:32:INFO:-------------Round number: 166-------------
2022-01-14 23:52:32:INFO:-------------Sending models-------------
2022-01-14 23:52:32:INFO:-------------Evaluating models-------------
2022-01-14 23:52:32:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:52:32:INFO:Accuracy = [0.9030223961730811, 0.9549902152641878, 0.9038921504674929, 0.9325940421830833, 0.9456403565992607, 0.9069362904979343, 0.9199826049141118, 0.9178082191780822, 0.9012828875842575, 0.8864970645792564]
2022-01-14 23:52:32:INFO:Loss = [0.26878812460695045, 0.1039143544049751, 0.3502349165960634, 0.2020870741198755, 0.1787020068383338, 0.2796342692663432, 0.2878307323121883, 0.26183676256286226, 0.37727722168739614, 0.33788269639118373]
2022-01-14 23:52:32:INFO:-------------Training local models-------------
2022-01-14 23:53:03:INFO:-------------Aggregating local models-------------
2022-01-14 23:53:04:INFO:-------------Round number: 167-------------
2022-01-14 23:53:04:INFO:-------------Sending models-------------
2022-01-14 23:53:04:INFO:-------------Evaluating models-------------
2022-01-14 23:53:04:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:53:04:INFO:Accuracy = [0.9030223961730811, 0.9549902152641878, 0.9038921504674929, 0.9325940421830833, 0.9456403565992607, 0.9069362904979343, 0.9202000434877147, 0.9178082191780822, 0.9012828875842575, 0.8862796260056534]
2022-01-14 23:53:04:INFO:Loss = [0.2687525220284957, 0.10385764673568214, 0.35022087527572804, 0.20210586460679597, 0.1786789834144734, 0.2796750486521831, 0.28779155523640526, 0.2618367926405414, 0.3773936424346922, 0.3377901698322126]
2022-01-14 23:53:04:INFO:-------------Training local models-------------
2022-01-14 23:53:35:INFO:-------------Aggregating local models-------------
2022-01-14 23:53:36:INFO:-------------Round number: 168-------------
2022-01-14 23:53:36:INFO:-------------Sending models-------------
2022-01-14 23:53:36:INFO:-------------Evaluating models-------------
2022-01-14 23:53:36:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:53:36:INFO:Accuracy = [0.9030223961730811, 0.9549902152641878, 0.9041095890410958, 0.9325940421830833, 0.9458577951728636, 0.9069362904979343, 0.9202000434877147, 0.9180256577516851, 0.9012828875842575, 0.8864970645792564]
2022-01-14 23:53:36:INFO:Loss = [0.2687170641285109, 0.10380222459928715, 0.35020532662498094, 0.202124173151535, 0.17865768622584946, 0.27971593232240133, 0.28775157389647377, 0.2618372663706901, 0.3775081982752834, 0.33769863739846495]
2022-01-14 23:53:36:INFO:-------------Training local models-------------
2022-01-14 23:54:07:INFO:-------------Aggregating local models-------------
2022-01-14 23:54:08:INFO:-------------Round number: 169-------------
2022-01-14 23:54:08:INFO:-------------Sending models-------------
2022-01-14 23:54:08:INFO:-------------Evaluating models-------------
2022-01-14 23:54:08:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:54:08:INFO:Accuracy = [0.9030223961730811, 0.9552076538377908, 0.9041095890410958, 0.9325940421830833, 0.9458577951728636, 0.9069362904979343, 0.9204174820613177, 0.9180256577516851, 0.9012828875842575, 0.8864970645792564]
2022-01-14 23:54:08:INFO:Loss = [0.2686823596552058, 0.10374817386000035, 0.3501925822362464, 0.20214240080699628, 0.17863677505115036, 0.27975756479915004, 0.28771428588027775, 0.26183851016615123, 0.37762495464514256, 0.33760903691887634]
2022-01-14 23:54:08:INFO:-------------Training local models-------------
2022-01-14 23:54:39:INFO:-------------Aggregating local models-------------
2022-01-14 23:54:40:INFO:-------------Round number: 170-------------
2022-01-14 23:54:40:INFO:-------------Sending models-------------
2022-01-14 23:54:40:INFO:-------------Evaluating models-------------
2022-01-14 23:54:40:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:54:40:INFO:Accuracy = [0.9030223961730811, 0.9552076538377908, 0.9041095890410958, 0.9325940421830833, 0.9458577951728636, 0.9069362904979343, 0.9204174820613177, 0.9180256577516851, 0.9012828875842575, 0.8864970645792564]
2022-01-14 23:54:40:INFO:Loss = [0.2686492479496539, 0.10369486040791762, 0.35017873310292574, 0.20216136271027627, 0.178616079058827, 0.2797941444279672, 0.2876757087617784, 0.2618398507944671, 0.3777400125859091, 0.3375200093528416]
2022-01-14 23:54:40:INFO:-------------Training local models-------------
2022-01-14 23:55:11:INFO:-------------Aggregating local models-------------
2022-01-14 23:55:12:INFO:-------------Round number: 171-------------
2022-01-14 23:55:12:INFO:-------------Sending models-------------
2022-01-14 23:55:12:INFO:-------------Evaluating models-------------
2022-01-14 23:55:12:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:55:12:INFO:Accuracy = [0.9028049575994781, 0.9549902152641878, 0.9041095890410958, 0.9325940421830833, 0.9458577951728636, 0.9069362904979343, 0.9204174820613177, 0.9180256577516851, 0.9012828875842575, 0.8864970645792564]
2022-01-14 23:55:12:INFO:Loss = [0.2686160592180713, 0.10364270443720727, 0.3501665406976548, 0.20217902989023945, 0.17859619395384604, 0.279836786579118, 0.2876393192025726, 0.2618425272833105, 0.377854120665094, 0.33743304314151945]
2022-01-14 23:55:12:INFO:-------------Training local models-------------
2022-01-14 23:55:43:INFO:-------------Aggregating local models-------------
2022-01-14 23:55:44:INFO:-------------Round number: 172-------------
2022-01-14 23:55:44:INFO:-------------Sending models-------------
2022-01-14 23:55:44:INFO:-------------Evaluating models-------------
2022-01-14 23:55:44:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:55:44:INFO:Accuracy = [0.9028049575994781, 0.9549902152641878, 0.9041095890410958, 0.9325940421830833, 0.9458577951728636, 0.9071537290715372, 0.9204174820613177, 0.9180256577516851, 0.9012828875842575, 0.8867145031528593]
2022-01-14 23:55:44:INFO:Loss = [0.26858475248803304, 0.10359113828845233, 0.35015433447142474, 0.20219754441350044, 0.1785767870331908, 0.27987919851495774, 0.287602673857224, 0.2618446656342855, 0.3779653900482898, 0.3373470367515288]
2022-01-14 23:55:44:INFO:-------------Training local models-------------
2022-01-14 23:56:15:INFO:-------------Aggregating local models-------------
2022-01-14 23:56:15:INFO:-------------Round number: 173-------------
2022-01-14 23:56:15:INFO:-------------Sending models-------------
2022-01-14 23:56:16:INFO:-------------Evaluating models-------------
2022-01-14 23:56:16:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:56:16:INFO:Accuracy = [0.9028049575994781, 0.9549902152641878, 0.9041095890410958, 0.9325940421830833, 0.9458577951728636, 0.9071537290715372, 0.9204174820613177, 0.9180256577516851, 0.9012828875842575, 0.8867145031528593]
2022-01-14 23:56:16:INFO:Loss = [0.26855450818491533, 0.10354082135049603, 0.35014314549537634, 0.20221652334233772, 0.17855832062143462, 0.27992253144854307, 0.28756701816927804, 0.2618470184112214, 0.3780759995639258, 0.33726216293541067]
2022-01-14 23:56:16:INFO:-------------Training local models-------------
2022-01-14 23:56:47:INFO:-------------Aggregating local models-------------
2022-01-14 23:56:47:INFO:-------------Round number: 174-------------
2022-01-14 23:56:47:INFO:-------------Sending models-------------
2022-01-14 23:56:47:INFO:-------------Evaluating models-------------
2022-01-14 23:56:48:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:56:48:INFO:Accuracy = [0.9028049575994781, 0.9549902152641878, 0.9041095890410958, 0.9325940421830833, 0.9458577951728636, 0.9071537290715372, 0.9204174820613177, 0.9180256577516851, 0.9012828875842575, 0.8867145031528593]
2022-01-14 23:56:48:INFO:Loss = [0.2685253457674606, 0.10349207785707075, 0.3501311185422111, 0.20223443744580524, 0.17854040915037978, 0.27995818999237276, 0.2875321609557674, 0.2618498271357137, 0.37818659947411437, 0.33718004084974545]
2022-01-14 23:56:48:INFO:-------------Training local models-------------
2022-01-14 23:57:19:INFO:-------------Aggregating local models-------------
2022-01-14 23:57:19:INFO:-------------Round number: 175-------------
2022-01-14 23:57:19:INFO:-------------Sending models-------------
2022-01-14 23:57:19:INFO:-------------Evaluating models-------------
2022-01-14 23:57:20:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:57:20:INFO:Accuracy = [0.9028049575994781, 0.9549902152641878, 0.9041095890410958, 0.9325940421830833, 0.9458577951728636, 0.9073711676451403, 0.9204174820613177, 0.9180256577516851, 0.9012828875842575, 0.8867145031528593]
2022-01-14 23:57:20:INFO:Loss = [0.268496088813253, 0.10344412713650177, 0.3501201982625723, 0.20225195692564507, 0.17852208791897792, 0.2800004343204553, 0.28749773601125556, 0.26185256284263164, 0.3782930530153683, 0.3370985926294877]
2022-01-14 23:57:20:INFO:-------------Training local models-------------
2022-01-14 23:57:51:INFO:-------------Aggregating local models-------------
2022-01-14 23:57:51:INFO:-------------Round number: 176-------------
2022-01-14 23:57:51:INFO:-------------Sending models-------------
2022-01-14 23:57:51:INFO:-------------Evaluating models-------------
2022-01-14 23:57:52:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:57:52:INFO:Accuracy = [0.9028049575994781, 0.9549902152641878, 0.9041095890410958, 0.9325940421830833, 0.9456403565992607, 0.9073711676451403, 0.9204174820613177, 0.9180256577516851, 0.9012828875842575, 0.8871493803000652]
2022-01-14 23:57:52:INFO:Loss = [0.26846857350101677, 0.10339686080358682, 0.35010947971015727, 0.20226994714751376, 0.1785057096506972, 0.28004300134397553, 0.28746345716272653, 0.261855486594948, 0.37840105390721196, 0.33701750670778563]
2022-01-14 23:57:52:INFO:-------------Training local models-------------
2022-01-14 23:58:23:INFO:-------------Aggregating local models-------------
2022-01-14 23:58:23:INFO:-------------Round number: 177-------------
2022-01-14 23:58:23:INFO:-------------Sending models-------------
2022-01-14 23:58:23:INFO:-------------Evaluating models-------------
2022-01-14 23:58:24:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:58:24:INFO:Accuracy = [0.9028049575994781, 0.9549902152641878, 0.9041095890410958, 0.9325940421830833, 0.9456403565992607, 0.9073711676451403, 0.9204174820613177, 0.9180256577516851, 0.9012828875842575, 0.8871493803000652]
2022-01-14 23:58:24:INFO:Loss = [0.26844201955612723, 0.10335034396817, 0.3500998816895901, 0.2022865410437392, 0.1784892376745626, 0.28008004217344173, 0.2874298265195759, 0.2618581088352766, 0.3785080570157989, 0.33693862262935864]
2022-01-14 23:58:24:INFO:-------------Training local models-------------
2022-01-14 23:58:55:INFO:-------------Aggregating local models-------------
2022-01-14 23:58:55:INFO:-------------Round number: 178-------------
2022-01-14 23:58:55:INFO:-------------Sending models-------------
2022-01-14 23:58:55:INFO:-------------Evaluating models-------------
2022-01-14 23:58:56:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:58:56:INFO:Accuracy = [0.9028049575994781, 0.9549902152641878, 0.9041095890410958, 0.9325940421830833, 0.9456403565992607, 0.9073711676451403, 0.9204174820613177, 0.9180256577516851, 0.9010654490106544, 0.8871493803000652]
2022-01-14 23:58:56:INFO:Loss = [0.26841572748923176, 0.10330499295686925, 0.3500900004262797, 0.2023045095129848, 0.17847378750500767, 0.28012271661529564, 0.2873967125582651, 0.26186144203735995, 0.37861227386248186, 0.3368618685319197]
2022-01-14 23:58:56:INFO:-------------Training local models-------------
2022-01-14 23:59:27:INFO:-------------Aggregating local models-------------
2022-01-14 23:59:27:INFO:-------------Round number: 179-------------
2022-01-14 23:59:27:INFO:-------------Sending models-------------
2022-01-14 23:59:27:INFO:-------------Evaluating models-------------
2022-01-14 23:59:28:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:59:28:INFO:Accuracy = [0.9028049575994781, 0.9549902152641878, 0.9038921504674929, 0.9325940421830833, 0.9456403565992607, 0.9073711676451403, 0.9204174820613177, 0.9182430963252881, 0.9010654490106544, 0.8871493803000652]
2022-01-14 23:59:28:INFO:Loss = [0.26839079345037625, 0.10326006406327283, 0.3500822561726937, 0.20232154153839416, 0.17845966815315784, 0.28016115908975503, 0.2873655061777786, 0.26186630039955516, 0.3787182963651157, 0.33678564747941925]
2022-01-14 23:59:28:INFO:-------------Training local models-------------
2022-01-14 23:59:59:INFO:-------------Aggregating local models-------------
2022-01-14 23:59:59:INFO:-------------Round number: 180-------------
2022-01-14 23:59:59:INFO:-------------Sending models-------------
2022-01-14 23:59:59:INFO:-------------Evaluating models-------------
2022-01-14 23:59:59:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 23:59:59:INFO:Accuracy = [0.9025875190258752, 0.9549902152641878, 0.9038921504674929, 0.9325940421830833, 0.9456403565992607, 0.9073711676451403, 0.9204174820613177, 0.9182430963252881, 0.9008480104370515, 0.8875842574472711]
2022-01-14 23:59:59:INFO:Loss = [0.26836550079579885, 0.10321512596214584, 0.3500729689670882, 0.20233918828896183, 0.17844356629871255, 0.280202155392778, 0.287333330411046, 0.261869204663038, 0.3788201872756061, 0.3367098429233123]
2022-01-14 23:59:59:INFO:-------------Training local models-------------
2022-01-15 00:00:31:INFO:-------------Aggregating local models-------------
2022-01-15 00:00:31:INFO:-------------Round number: 181-------------
2022-01-15 00:00:31:INFO:-------------Sending models-------------
2022-01-15 00:00:31:INFO:-------------Evaluating models-------------
2022-01-15 00:00:31:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-15 00:00:31:INFO:Accuracy = [0.9025875190258752, 0.9552076538377908, 0.9038921504674929, 0.9325940421830833, 0.9456403565992607, 0.9073711676451403, 0.9204174820613177, 0.9182430963252881, 0.9008480104370515, 0.8878016960208741]
2022-01-15 00:00:31:INFO:Loss = [0.26834187952133165, 0.10317165161358625, 0.3500653548615667, 0.2023558648051399, 0.17842976039992625, 0.2802449811196016, 0.28730229995370316, 0.2618739571324617, 0.37892521992750156, 0.33663577052066357]
2022-01-15 00:00:31:INFO:-------------Training local models-------------
2022-01-15 00:01:03:INFO:-------------Aggregating local models-------------
2022-01-15 00:01:03:INFO:-------------Round number: 182-------------
2022-01-15 00:01:03:INFO:-------------Sending models-------------
2022-01-15 00:01:03:INFO:-------------Evaluating models-------------
2022-01-15 00:01:03:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-15 00:01:03:INFO:Accuracy = [0.9025875190258752, 0.9552076538377908, 0.9038921504674929, 0.9325940421830833, 0.9456403565992607, 0.9078060447923462, 0.9204174820613177, 0.9182430963252881, 0.9008480104370515, 0.888019134594477]
2022-01-15 00:01:03:INFO:Loss = [0.2683184271837979, 0.10312797757946923, 0.35005829872112754, 0.20237276061002332, 0.17841591232735446, 0.2802824540178015, 0.28727246947850754, 0.26187874122578864, 0.37902883023087924, 0.3365629725319839]
2022-01-15 00:01:03:INFO:-------------Training local models-------------
2022-01-15 00:01:35:INFO:-------------Aggregating local models-------------
2022-01-15 00:01:35:INFO:-------------Round number: 183-------------
2022-01-15 00:01:35:INFO:-------------Sending models-------------
2022-01-15 00:01:35:INFO:-------------Evaluating models-------------
2022-01-15 00:01:35:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-15 00:01:35:INFO:Accuracy = [0.9025875190258752, 0.9552076538377908, 0.9038921504674929, 0.9325940421830833, 0.9456403565992607, 0.9078060447923462, 0.9204174820613177, 0.9182430963252881, 0.9008480104370515, 0.88823657316808]
2022-01-15 00:01:35:INFO:Loss = [0.26829534626717777, 0.10308414914331093, 0.3500512383228973, 0.20238910549838746, 0.17840262969556892, 0.2803248991528787, 0.2872430445968815, 0.2618839493212091, 0.3791276182797647, 0.3364911098517051]
2022-01-15 00:01:35:INFO:-------------Training local models-------------
2022-01-15 00:02:07:INFO:-------------Aggregating local models-------------
2022-01-15 00:02:07:INFO:-------------Round number: 184-------------
2022-01-15 00:02:07:INFO:-------------Sending models-------------
2022-01-15 00:02:07:INFO:-------------Evaluating models-------------
2022-01-15 00:02:07:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-15 00:02:07:INFO:Accuracy = [0.9025875190258752, 0.9552076538377908, 0.9038921504674929, 0.9325940421830833, 0.9456403565992607, 0.9078060447923462, 0.9204174820613177, 0.9182430963252881, 0.9008480104370515, 0.8884540117416829]
2022-01-15 00:02:07:INFO:Loss = [0.26827289199798404, 0.10304114528531273, 0.3500454959438188, 0.20240613675805408, 0.17839025153050891, 0.2803623433271104, 0.2872148715379314, 0.26188986260418184, 0.37922967085648973, 0.33642073514775916]
2022-01-15 00:02:07:INFO:-------------Training local models-------------
2022-01-15 00:02:39:INFO:-------------Aggregating local models-------------
2022-01-15 00:02:39:INFO:-------------Round number: 185-------------
2022-01-15 00:02:39:INFO:-------------Sending models-------------
2022-01-15 00:02:39:INFO:-------------Evaluating models-------------
2022-01-15 00:02:39:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-15 00:02:39:INFO:Accuracy = [0.9025875190258752, 0.9552076538377908, 0.9038921504674929, 0.9325940421830833, 0.9456403565992607, 0.9080234833659491, 0.9206349206349206, 0.9182430963252881, 0.9010654490106544, 0.8886714503152859]
2022-01-15 00:02:39:INFO:Loss = [0.26825051544635803, 0.10299875451271026, 0.3500391690670392, 0.20242087166367656, 0.17837859176265963, 0.28040564553642294, 0.2871863493035637, 0.2618962998007805, 0.379327876335621, 0.33635116511807317]
2022-01-15 00:02:39:INFO:-------------Training local models-------------
2022-01-15 00:03:11:INFO:-------------Aggregating local models-------------
2022-01-15 00:03:11:INFO:-------------Round number: 186-------------
2022-01-15 00:03:11:INFO:-------------Sending models-------------
2022-01-15 00:03:11:INFO:-------------Evaluating models-------------
2022-01-15 00:03:11:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-15 00:03:11:INFO:Accuracy = [0.9025875190258752, 0.9552076538377908, 0.9038921504674929, 0.9325940421830833, 0.9456403565992607, 0.9082409219395521, 0.9206349206349206, 0.9182430963252881, 0.9010654490106544, 0.8888888888888888]
2022-01-15 00:03:11:INFO:Loss = [0.2682279893184273, 0.10295666392265997, 0.350033647643229, 0.20243717794446484, 0.17836613792764677, 0.28044474249566376, 0.2871580623309429, 0.2619028576305479, 0.3794266149183351, 0.33628291929713067]
2022-01-15 00:03:11:INFO:-------------Training local models-------------
2022-01-15 00:03:43:INFO:-------------Aggregating local models-------------
2022-01-15 00:03:43:INFO:-------------Round number: 187-------------
2022-01-15 00:03:43:INFO:-------------Sending models-------------
2022-01-15 00:03:43:INFO:-------------Evaluating models-------------
2022-01-15 00:03:43:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-15 00:03:43:INFO:Accuracy = [0.9025875190258752, 0.9554250924113937, 0.9041095890410958, 0.9328114807566862, 0.9456403565992607, 0.908458360513155, 0.9206349206349206, 0.9182430963252881, 0.9010654490106544, 0.8888888888888888]
2022-01-15 00:03:43:INFO:Loss = [0.2682062955717803, 0.10291540422511128, 0.3500281832832782, 0.20245043446666552, 0.17835612951273233, 0.2804849116056496, 0.2871307097055751, 0.2619095833892651, 0.3795233632735669, 0.3362159532847506]
2022-01-15 00:03:43:INFO:-------------Training local models-------------
2022-01-15 00:04:14:INFO:-------------Aggregating local models-------------
2022-01-15 00:04:15:INFO:-------------Round number: 188-------------
2022-01-15 00:04:15:INFO:-------------Sending models-------------
2022-01-15 00:04:15:INFO:-------------Evaluating models-------------
2022-01-15 00:04:15:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-15 00:04:15:INFO:Accuracy = [0.9025875190258752, 0.9554250924113937, 0.9041095890410958, 0.9328114807566862, 0.9456403565992607, 0.908458360513155, 0.9206349206349206, 0.9182430963252881, 0.9010654490106544, 0.8888888888888888]
2022-01-15 00:04:15:INFO:Loss = [0.26818498771957994, 0.10287401566714796, 0.3500220426039843, 0.20246436251001362, 0.17834569197954436, 0.280521732578351, 0.2871032416387658, 0.26191598717645104, 0.37961942287948097, 0.3361498615062155]
2022-01-15 00:04:15:INFO:-------------Training local models-------------
2022-01-15 00:04:46:INFO:-------------Aggregating local models-------------
2022-01-15 00:04:47:INFO:-------------Round number: 189-------------
2022-01-15 00:04:47:INFO:-------------Sending models-------------
2022-01-15 00:04:47:INFO:-------------Evaluating models-------------
2022-01-15 00:04:47:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-15 00:04:47:INFO:Accuracy = [0.9025875190258752, 0.9554250924113937, 0.9038921504674929, 0.9328114807566862, 0.9456403565992607, 0.908458360513155, 0.9206349206349206, 0.9180256577516851, 0.9010654490106544, 0.8888888888888888]
2022-01-15 00:04:47:INFO:Loss = [0.2681646831440902, 0.10283431721977086, 0.35001714156198044, 0.20247828489234077, 0.17833524010747692, 0.2805633786164975, 0.28707701407688757, 0.26192293330321503, 0.3797142684236386, 0.33608552696926064]
2022-01-15 00:04:47:INFO:-------------Training local models-------------
2022-01-15 00:05:18:INFO:-------------Aggregating local models-------------
2022-01-15 00:05:19:INFO:-------------Round number: 190-------------
2022-01-15 00:05:19:INFO:-------------Sending models-------------
2022-01-15 00:05:19:INFO:-------------Evaluating models-------------
2022-01-15 00:05:19:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-15 00:05:19:INFO:Accuracy = [0.9025875190258752, 0.9554250924113937, 0.9038921504674929, 0.9328114807566862, 0.9456403565992607, 0.908458360513155, 0.9206349206349206, 0.9180256577516851, 0.9008480104370515, 0.8888888888888888]
2022-01-15 00:05:19:INFO:Loss = [0.26814529577415297, 0.10279549146670366, 0.35001274758616147, 0.20249249157250893, 0.17832526394296694, 0.2806003764248258, 0.2870516858464055, 0.2619312446317493, 0.3798102148637662, 0.33602173134661173]
2022-01-15 00:05:19:INFO:-------------Training local models-------------
2022-01-15 00:05:50:INFO:-------------Aggregating local models-------------
2022-01-15 00:05:51:INFO:-------------Round number: 191-------------
2022-01-15 00:05:51:INFO:-------------Sending models-------------
2022-01-15 00:05:51:INFO:-------------Evaluating models-------------
2022-01-15 00:05:51:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-15 00:05:51:INFO:Accuracy = [0.9025875190258752, 0.9554250924113937, 0.9038921504674929, 0.9328114807566862, 0.9456403565992607, 0.908458360513155, 0.9206349206349206, 0.9182430963252881, 0.9008480104370515, 0.8888888888888888]
2022-01-15 00:05:51:INFO:Loss = [0.2681252984234311, 0.10275662987611368, 0.3500079861205976, 0.20250677793483246, 0.17831482129310536, 0.2806397770591101, 0.2870259492874038, 0.2619382496649826, 0.3799030642297935, 0.33595802594425517]
2022-01-15 00:05:51:INFO:-------------Training local models-------------
2022-01-15 00:06:22:INFO:-------------Aggregating local models-------------
2022-01-15 00:06:23:INFO:-------------Round number: 192-------------
2022-01-15 00:06:23:INFO:-------------Sending models-------------
2022-01-15 00:06:23:INFO:-------------Evaluating models-------------
2022-01-15 00:06:23:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-15 00:06:23:INFO:Accuracy = [0.9025875190258752, 0.9554250924113937, 0.9038921504674929, 0.9328114807566862, 0.9456403565992607, 0.908458360513155, 0.9206349206349206, 0.9182430963252881, 0.9008480104370515, 0.8888888888888888]
2022-01-15 00:06:23:INFO:Loss = [0.26810723511203527, 0.10271860281562442, 0.3500039509263208, 0.2025207841691681, 0.17830607739655388, 0.2806764150483658, 0.2870012252530558, 0.26194636496181595, 0.3799975895930363, 0.3358958063738633]
2022-01-15 00:06:23:INFO:-------------Training local models-------------
2022-01-15 00:06:54:INFO:-------------Aggregating local models-------------
2022-01-15 00:06:55:INFO:-------------Round number: 193-------------
2022-01-15 00:06:55:INFO:-------------Sending models-------------
2022-01-15 00:06:55:INFO:-------------Evaluating models-------------
2022-01-15 00:06:55:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-15 00:06:55:INFO:Accuracy = [0.9025875190258752, 0.9554250924113937, 0.9038921504674929, 0.9328114807566862, 0.9456403565992607, 0.908458360513155, 0.9206349206349206, 0.9182430963252881, 0.9008480104370515, 0.8888888888888888]
2022-01-15 00:06:55:INFO:Loss = [0.2680896295256621, 0.10268043858313106, 0.3500007944706101, 0.20253470253281886, 0.1782961802153973, 0.28071185798462794, 0.28697688172233277, 0.2619543371520331, 0.38008881055432503, 0.33583461754262983]
2022-01-15 00:06:55:INFO:-------------Training local models-------------
2022-01-15 00:07:26:INFO:-------------Aggregating local models-------------
2022-01-15 00:07:27:INFO:-------------Round number: 194-------------
2022-01-15 00:07:27:INFO:-------------Sending models-------------
2022-01-15 00:07:27:INFO:-------------Evaluating models-------------
2022-01-15 00:07:27:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-15 00:07:27:INFO:Accuracy = [0.9025875190258752, 0.9556425309849967, 0.9038921504674929, 0.9328114807566862, 0.9456403565992607, 0.908458360513155, 0.9206349206349206, 0.9182430963252881, 0.9008480104370515, 0.8888888888888888]
2022-01-15 00:07:27:INFO:Loss = [0.26807194591332445, 0.10264337219862851, 0.3499973674705137, 0.2025488257978714, 0.17828617133532784, 0.28075361379967645, 0.2869526564309425, 0.26196257580564486, 0.380180318153614, 0.33577360378261234]
2022-01-15 00:07:27:INFO:-------------Training local models-------------
2022-01-15 00:07:58:INFO:-------------Aggregating local models-------------
2022-01-15 00:07:59:INFO:-------------Round number: 195-------------
2022-01-15 00:07:59:INFO:-------------Sending models-------------
2022-01-15 00:07:59:INFO:-------------Evaluating models-------------
2022-01-15 00:07:59:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-15 00:07:59:INFO:Accuracy = [0.9025875190258752, 0.9556425309849967, 0.9038921504674929, 0.9328114807566862, 0.9456403565992607, 0.908675799086758, 0.9206349206349206, 0.9182430963252881, 0.9008480104370515, 0.8888888888888888]
2022-01-15 00:07:59:INFO:Loss = [0.2680541988730833, 0.10260679168414744, 0.3499925860865514, 0.2025620329463508, 0.17827768827943627, 0.2807886234572918, 0.2869285932808076, 0.26197083439846236, 0.38027004498018285, 0.33571309835704605]
2022-01-15 00:07:59:INFO:-------------Training local models-------------
2022-01-15 00:08:30:INFO:-------------Aggregating local models-------------
2022-01-15 00:08:31:INFO:-------------Round number: 196-------------
2022-01-15 00:08:31:INFO:-------------Sending models-------------
2022-01-15 00:08:31:INFO:-------------Evaluating models-------------
2022-01-15 00:08:31:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-15 00:08:31:INFO:Accuracy = [0.9025875190258752, 0.9556425309849967, 0.9038921504674929, 0.9328114807566862, 0.9456403565992607, 0.908675799086758, 0.9206349206349206, 0.9182430963252881, 0.9008480104370515, 0.8888888888888888]
2022-01-15 00:08:31:INFO:Loss = [0.26803767580234245, 0.10257088402960894, 0.3499889138894362, 0.20257594791335232, 0.17826781168464856, 0.2808284416676463, 0.28690506256728493, 0.2619792232680746, 0.38036093394099696, 0.3356541521346376]
2022-01-15 00:08:31:INFO:-------------Training local models-------------
2022-01-15 00:09:02:INFO:-------------Aggregating local models-------------
2022-01-15 00:09:03:INFO:-------------Round number: 197-------------
2022-01-15 00:09:03:INFO:-------------Sending models-------------
2022-01-15 00:09:03:INFO:-------------Evaluating models-------------
2022-01-15 00:09:03:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-15 00:09:03:INFO:Accuracy = [0.9025875190258752, 0.9556425309849967, 0.9038921504674929, 0.9328114807566862, 0.9456403565992607, 0.908675799086758, 0.9206349206349206, 0.9182430963252881, 0.9008480104370515, 0.8888888888888888]
2022-01-15 00:09:03:INFO:Loss = [0.2680216391252262, 0.10253533864742696, 0.34998504562663074, 0.20258954387026856, 0.17825911989154122, 0.2808633886580067, 0.28688226134695544, 0.2619882233174619, 0.380448706447844, 0.3355962741832925]
2022-01-15 00:09:03:INFO:-------------Training local models-------------
2022-01-15 00:09:34:INFO:-------------Aggregating local models-------------
2022-01-15 00:09:35:INFO:-------------Round number: 198-------------
2022-01-15 00:09:35:INFO:-------------Sending models-------------
2022-01-15 00:09:35:INFO:-------------Evaluating models-------------
2022-01-15 00:09:35:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-15 00:09:35:INFO:Accuracy = [0.9025875190258752, 0.9556425309849967, 0.9038921504674929, 0.9328114807566862, 0.9456403565992607, 0.9088932376603609, 0.9204174820613177, 0.9182430963252881, 0.9008480104370515, 0.8888888888888888]
2022-01-15 00:09:35:INFO:Loss = [0.2680058973291643, 0.10250104352627487, 0.34998189932322715, 0.20260319015613695, 0.17825149362671908, 0.28089951321303414, 0.2868604825460694, 0.2619971220907654, 0.3805373365130157, 0.33553940577963176]
2022-01-15 00:09:35:INFO:-------------Training local models-------------
2022-01-15 00:10:06:INFO:-------------Aggregating local models-------------
2022-01-15 00:10:07:INFO:-------------Round number: 199-------------
2022-01-15 00:10:07:INFO:-------------Sending models-------------
2022-01-15 00:10:07:INFO:-------------Evaluating models-------------
2022-01-15 00:10:07:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-15 00:10:07:INFO:Accuracy = [0.9025875190258752, 0.9556425309849967, 0.9038921504674929, 0.9328114807566862, 0.9456403565992607, 0.9091106762339639, 0.9204174820613177, 0.9182430963252881, 0.9008480104370515, 0.8888888888888888]
2022-01-15 00:10:07:INFO:Loss = [0.26799027210382814, 0.10246608169161303, 0.34997782429040714, 0.20261693658444468, 0.17824245280324497, 0.28093832536334185, 0.2868384058928171, 0.2620055369122804, 0.38062357894552573, 0.33548253306078235]
2022-01-15 00:10:07:INFO:-------------Training local models-------------
2022-01-15 00:10:38:INFO:-------------Aggregating local models-------------
