
Number of users: 20
Number of classes: 10
Min # of samples per uesr: 10
Alpha for Dirichlet Distribution: 0.1
Ratio for Sampling Training Data: 0.5
Reading source dataset.
Downloading and extracting zip archive
Downloading http://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip to ./data/EMNIST/raw/emnist.zip
Extracting ./data/EMNIST/raw/emnist.zip to ./data/EMNIST/raw
Processing byclass
Processing bymerge
Processing balanced
Processing letters
Processing digits
Processing mnist
Done!
Loading data from storage ...
Rearrange data by class...
TRAIN SET:
  Total #samples: 124800. sample shape: torch.Size([1, 28, 28])
  #samples per class:
 [0, 4800, 4800, 4800, 4800, 4800, 4800, 4800, 4800, 4800]
Loading data from storage ...
Rearrange data by class...
TEST SET:
  Total #samples: 20800. sample shape: torch.Size([1, 28, 28])
  #samples per class:
 [0, 800, 800, 800, 800, 800, 800, 800, 800, 800]
10 labels in total.
Try to find valid data separation
7 4800 2400
3 4800 2400
2 4800 2400
8 4800 2400
5 4800 2400
6 4800 2400
9 4800 2400
4 4800 2400
0 0 0
1 4800 2400
processing users...
TRAIN #sample by user: [2487, 71, 857, 505, 772, 818, 1421, 933, 1768, 462, 2994, 2054, 2629, 151, 914, 300, 305, 160, 264, 1735]
Dumping train data => ./u20c10-mtl-alpha0.1-ratio0.5/train/train.pt
2487 samples in total
c=4,n=41| c=6,n=572| c=7,n=1| c=8,n=1873| 
4 Labels/ 2487 Number of training samples for user [0]:
71 samples in total
c=3,n=1| c=5,n=36| c=9,n=34| 
3 Labels/ 71 Number of training samples for user [1]:
857 samples in total
c=4,n=1| c=5,n=275| c=7,n=1| c=8,n=230| c=9,n=350| 
5 Labels/ 857 Number of training samples for user [2]:
505 samples in total
c=3,n=196| c=7,n=5| c=9,n=304| 
3 Labels/ 505 Number of training samples for user [3]:
772 samples in total
c=1,n=1| c=2,n=330| c=5,n=1| c=7,n=1| c=9,n=439| 
5 Labels/ 772 Number of training samples for user [4]:
818 samples in total
c=1,n=9| c=2,n=700| c=4,n=83| c=6,n=2| c=8,n=18| c=9,n=6| 
6 Labels/ 818 Number of training samples for user [5]:
1421 samples in total
c=4,n=695| c=5,n=726| 
2 Labels/ 1421 Number of training samples for user [6]:
933 samples in total
c=1,n=3| c=2,n=366| c=3,n=19| c=4,n=28| c=6,n=492| c=7,n=24| c=9,n=1| 
7 Labels/ 933 Number of training samples for user [7]:
1768 samples in total
c=2,n=77| c=3,n=1374| c=4,n=220| c=7,n=11| c=8,n=86| 
5 Labels/ 1768 Number of training samples for user [8]:
462 samples in total
c=4,n=13| c=7,n=136| c=8,n=1| c=9,n=312| 
4 Labels/ 462 Number of training samples for user [9]:
2994 samples in total
c=2,n=382| c=3,n=27| c=5,n=1084| c=6,n=1253| c=7,n=1| c=9,n=247| 
6 Labels/ 2994 Number of training samples for user [10]:
2054 samples in total
c=1,n=2| c=3,n=105| c=6,n=1| c=7,n=1944| c=8,n=1| c=9,n=1| 
6 Labels/ 2054 Number of training samples for user [11]:
2629 samples in total
c=1,n=2349| c=2,n=3| c=4,n=110| c=5,n=157| c=6,n=10| 
5 Labels/ 2629 Number of training samples for user [12]:
151 samples in total
c=1,n=19| c=3,n=33| c=6,n=13| c=9,n=86| 
4 Labels/ 151 Number of training samples for user [13]:
914 samples in total
c=1,n=5| c=2,n=24| c=3,n=87| c=4,n=781| c=5,n=6| c=6,n=2| c=7,n=1| c=9,n=8| 
8 Labels/ 914 Number of training samples for user [14]:
300 samples in total
c=2,n=1| c=3,n=101| c=4,n=1| c=5,n=2| c=7,n=102| c=8,n=93| 
6 Labels/ 300 Number of training samples for user [15]:
305 samples in total
c=1,n=1| c=2,n=6| c=4,n=128| c=7,n=133| c=9,n=37| 
5 Labels/ 305 Number of training samples for user [16]:
160 samples in total
c=5,n=48| c=6,n=6| c=8,n=97| c=9,n=9| 
4 Labels/ 160 Number of training samples for user [17]:
264 samples in total
c=2,n=135| c=4,n=25| c=5,n=64| c=7,n=39| c=9,n=1| 
5 Labels/ 264 Number of training samples for user [18]:
1735 samples in total
c=1,n=11| c=2,n=376| c=3,n=457| c=4,n=274| c=5,n=1| c=6,n=49| c=7,n=1| c=8,n=1| c=9,n=565| 
9 Labels/ 1735 Number of training samples for user [19]:
TEST #sample by user: [160, 120, 200, 120, 200, 240, 80, 280, 200, 160, 240, 240, 200, 160, 320, 240, 200, 160, 200, 360]
Dumping train data => ./u20c10-mtl-alpha0.1-ratio0.5/test/test.pt
Finish Generating User samples
