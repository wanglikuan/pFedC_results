2022-01-16 17:22:34:INFO:-------------Round number: 0-------------
2022-01-16 17:22:34:INFO:-------------Sending models-------------
2022-01-16 17:22:35:INFO:-------------Evaluating models-------------
2022-01-16 17:22:35:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-16 17:22:35:INFO:Accuracy = [0.8984360278876955, 0.8839268890145091, 0.8846806105144149, 0.9057848125117769, 0.9261352930092331, 0.0746184284906727, 0.11513095911060862, 0.10570944036178632, 0.09044657998869418, 0.8869417750141323]
2022-01-16 17:22:35:INFO:Loss = [0.6698315352150921, 0.6535867544269076, 0.6625111897674145, 0.6538707435928497, 0.6621472520726716, 0.7392828428455501, 0.7384982380980216, 0.7415181731063587, 0.7481898140251378, 0.6703967377585567]
2022-01-16 17:22:35:INFO:-------------Training local models-------------
2022-01-16 17:23:47:INFO:-------------Aggregating local models-------------
2022-01-16 17:23:48:INFO:-------------Round number: 1-------------
2022-01-16 17:23:48:INFO:-------------Sending models-------------
2022-01-16 17:23:49:INFO:-------------Evaluating models-------------
2022-01-16 17:23:49:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-16 17:23:49:INFO:Accuracy = [0.863576408517053, 0.8471829658941021, 0.8569813453928773, 0.8701714716412285, 0.8392688901450914, 0.8807235726399095, 0.8432259280195967, 0.833615978895798, 0.875824382890522, 0.7806670435274167]
2022-01-16 17:23:49:INFO:Loss = [0.43153205287923735, 0.41478683828110013, 0.44005179434343655, 0.40496212162606704, 0.38739611648426053, 0.421548983519846, 0.4737519216482442, 0.4656331501764268, 0.4534104642082186, 0.5386359720063205]
2022-01-16 17:23:49:INFO:-------------Training local models-------------
2022-01-16 17:25:01:INFO:-------------Aggregating local models-------------
2022-01-16 17:25:02:INFO:-------------Round number: 2-------------
2022-01-16 17:25:02:INFO:-------------Sending models-------------
2022-01-16 17:25:02:INFO:-------------Evaluating models-------------
2022-01-16 17:25:02:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-16 17:25:02:INFO:Accuracy = [0.8620689655172413, 0.8405879027699266, 0.8488788392688902, 0.8831731675146034, 0.8545317505181835, 0.8814772941398153, 0.8417184850197852, 0.8392688901450914, 0.8797814207650273, 0.837384586395327]
2022-01-16 17:25:02:INFO:Loss = [0.44118327125928003, 0.3450819038037882, 0.42901016809751735, 0.3640109244337443, 0.334670221248955, 0.34928190099387457, 0.45841251965278745, 0.4062404246723189, 0.41615870225906443, 0.4953462086359626]
2022-01-16 17:25:02:INFO:-------------Training local models-------------
2022-01-16 17:26:14:INFO:-------------Aggregating local models-------------
2022-01-16 17:26:15:INFO:-------------Round number: 3-------------
2022-01-16 17:26:15:INFO:-------------Sending models-------------
2022-01-16 17:26:16:INFO:-------------Evaluating models-------------
2022-01-16 17:26:16:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-16 17:26:16:INFO:Accuracy = [0.8257019031467873, 0.8569813453928773, 0.8505747126436781, 0.8950442811381195, 0.8662144337667232, 0.8752590917655926, 0.8452986621443377, 0.8432259280195967, 0.8797814207650273, 0.8515168645185603]
2022-01-16 17:26:16:INFO:Loss = [0.4480045001276188, 0.31123261198298613, 0.42503093448793083, 0.3481268546685635, 0.3053358736354454, 0.33573299419908414, 0.45329928917335444, 0.3729301349508055, 0.40094598210082427, 0.4845747750958655]
2022-01-16 17:26:16:INFO:-------------Training local models-------------
2022-01-16 17:27:28:INFO:-------------Aggregating local models-------------
2022-01-16 17:27:29:INFO:-------------Round number: 4-------------
2022-01-16 17:27:29:INFO:-------------Sending models-------------
2022-01-16 17:27:29:INFO:-------------Evaluating models-------------
2022-01-16 17:27:29:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-16 17:27:29:INFO:Accuracy = [0.8162803843979649, 0.8598078010175241, 0.8550970416431128, 0.9044657998869418, 0.8788392688901451, 0.8707367627661579, 0.8524590163934426, 0.8485019785189373, 0.8797814207650273, 0.8535895986433013]
2022-01-16 17:27:29:INFO:Loss = [0.45192790632874974, 0.2979108781940057, 0.42239874311420444, 0.3397114926039055, 0.2907117967474441, 0.33702294696401436, 0.4515166559602503, 0.3533217649566775, 0.39509638452515305, 0.479587544700605]
2022-01-16 17:27:29:INFO:-------------Training local models-------------
2022-01-16 17:28:41:INFO:-------------Aggregating local models-------------
2022-01-16 17:28:42:INFO:-------------Round number: 5-------------
2022-01-16 17:28:42:INFO:-------------Sending models-------------
2022-01-16 17:28:42:INFO:-------------Evaluating models-------------
2022-01-16 17:28:42:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-16 17:28:42:INFO:Accuracy = [0.8228754475221406, 0.8594309402675712, 0.8631995477671001, 0.9082344073864707, 0.8884492180139438, 0.8701714716412285, 0.8618805351422649, 0.8613152440173356, 0.8799698511400038, 0.8549086112681364]
2022-01-16 17:28:42:INFO:Loss = [0.4514260162427054, 0.293177065972045, 0.42115028687933187, 0.3338782036769486, 0.2831416160885377, 0.3408874403892409, 0.4510125569847069, 0.3401509284884873, 0.39222808017617256, 0.47639976090091574]
2022-01-16 17:28:42:INFO:-------------Training local models-------------
2022-01-16 17:29:54:INFO:-------------Aggregating local models-------------
2022-01-16 17:29:55:INFO:-------------Round number: 6-------------
2022-01-16 17:29:55:INFO:-------------Sending models-------------
2022-01-16 17:29:55:INFO:-------------Evaluating models-------------
2022-01-16 17:29:56:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-16 17:29:56:INFO:Accuracy = [0.8283399283964575, 0.8609383832673827, 0.8762012436404748, 0.9082344073864707, 0.8990013190126248, 0.8697946108912756, 0.8688524590163934, 0.8797814207650273, 0.8807235726399095, 0.8560391935179951]
2022-01-16 17:29:56:INFO:Loss = [0.4476352013418411, 0.29060829182224573, 0.4200909695927098, 0.32949050768744115, 0.278575922448935, 0.34394335866598114, 0.4507686578948033, 0.32984072033081, 0.38985571823141124, 0.4737875698298737]
2022-01-16 17:29:56:INFO:-------------Training local models-------------
2022-01-16 17:31:08:INFO:-------------Aggregating local models-------------
2022-01-16 17:31:09:INFO:-------------Round number: 7-------------
2022-01-16 17:31:09:INFO:-------------Sending models-------------
2022-01-16 17:31:09:INFO:-------------Evaluating models-------------
2022-01-16 17:31:09:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-16 17:31:09:INFO:Accuracy = [0.8321085358959864, 0.8641416996419823, 0.8867533446391558, 0.9082344073864707, 0.9072922555115884, 0.8696061805162992, 0.8780855473902393, 0.8952327115130959, 0.8816657245147917, 0.8560391935179951]
2022-01-16 17:31:09:INFO:Loss = [0.44199435074818666, 0.2882287892951174, 0.4186177109600669, 0.32614249016454155, 0.2751916748838024, 0.3453031086461787, 0.45030042787865354, 0.3209377755227144, 0.3874366608831683, 0.47127226827322555]
2022-01-16 17:31:09:INFO:-------------Training local models-------------
2022-01-16 17:32:21:INFO:-------------Aggregating local models-------------
2022-01-16 17:32:22:INFO:-------------Round number: 8-------------
2022-01-16 17:32:22:INFO:-------------Sending models-------------
2022-01-16 17:32:22:INFO:-------------Evaluating models-------------
2022-01-16 17:32:22:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-16 17:32:22:INFO:Accuracy = [0.8381383078952327, 0.8699830412662521, 0.889391369888826, 0.9093649896363294, 0.9138873186357641, 0.8713020538910873, 0.8831731675146034, 0.9035236480120595, 0.8829847371396269, 0.856416054267948]
2022-01-16 17:32:22:INFO:Loss = [0.4353972263887129, 0.28557993085188094, 0.4166805569512404, 0.3234817490832951, 0.27217415250612387, 0.345133316150656, 0.44962458780677844, 0.3128102543328471, 0.38479559804127833, 0.46875232144558826]
2022-01-16 17:32:22:INFO:-------------Training local models-------------
2022-01-16 17:33:34:INFO:-------------Aggregating local models-------------
2022-01-16 17:33:35:INFO:-------------Round number: 9-------------
2022-01-16 17:33:35:INFO:-------------Sending models-------------
2022-01-16 17:33:35:INFO:-------------Evaluating models-------------
2022-01-16 17:33:35:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-16 17:33:35:INFO:Accuracy = [0.8462408140192199, 0.8745053702656869, 0.8908988128886377, 0.910495571886188, 0.9191633691351045, 0.872055775390993, 0.8875070661390616, 0.9087996985114001, 0.8831731675146034, 0.8569813453928773]
2022-01-16 17:33:35:INFO:Loss = [0.4282903446459138, 0.28280699593139175, 0.4144440142141721, 0.32132826641427303, 0.26921453729642786, 0.3437478597661463, 0.44888848138631615, 0.30540686503590325, 0.38191665032022043, 0.46621284295333787]
2022-01-16 17:33:35:INFO:-------------Training local models-------------
2022-01-16 17:34:47:INFO:-------------Aggregating local models-------------
2022-01-16 17:34:48:INFO:-------------Round number: 10-------------
2022-01-16 17:34:48:INFO:-------------Sending models-------------
2022-01-16 17:34:48:INFO:-------------Evaluating models-------------
2022-01-16 17:34:48:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-16 17:34:48:INFO:Accuracy = [0.8532127378933484, 0.8797814207650273, 0.8918409647635199, 0.9116261541360468, 0.9221782551347277, 0.8743169398907104, 0.8899566610137554, 0.9129451667608819, 0.8835500282645562, 0.8575466365178067]
2022-01-16 17:34:48:INFO:Loss = [0.4209140917510333, 0.2800973109440818, 0.4120574822485365, 0.31951224474203993, 0.2662553235045518, 0.3414398618728633, 0.44816721406603305, 0.2986706112906878, 0.3788176239799613, 0.46360639381496715]
2022-01-16 17:34:48:INFO:-------------Training local models-------------
2022-01-16 17:36:00:INFO:-------------Aggregating local models-------------
2022-01-16 17:36:01:INFO:-------------Round number: 11-------------
2022-01-16 17:36:01:INFO:-------------Sending models-------------
2022-01-16 17:36:01:INFO:-------------Evaluating models-------------
2022-01-16 17:36:02:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-16 17:36:02:INFO:Accuracy = [0.8571697757678538, 0.8852459016393442, 0.8925946862634256, 0.9118145845110232, 0.9246278500094215, 0.8762012436404748, 0.8910872432636141, 0.915583192010552, 0.8837384586395327, 0.8577350668927831]
2022-01-16 17:36:02:INFO:Loss = [0.4134919703933351, 0.27752364299217785, 0.4097111407230737, 0.31794806138057957, 0.2633846081969653, 0.3384297735631008, 0.44741594177773963, 0.2926521150977724, 0.37558544378605097, 0.4608805120966673]
2022-01-16 17:36:02:INFO:-------------Training local models-------------
2022-01-16 17:37:14:INFO:-------------Aggregating local models-------------
2022-01-16 17:37:15:INFO:-------------Round number: 12-------------
2022-01-16 17:37:15:INFO:-------------Sending models-------------
2022-01-16 17:37:15:INFO:-------------Evaluating models-------------
2022-01-16 17:37:15:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-16 17:37:15:INFO:Accuracy = [0.8641416996419823, 0.8895798002638026, 0.8924062558884492, 0.9129451667608819, 0.9268890145091389, 0.8788392688901451, 0.891464104013567, 0.9167137742604108, 0.8839268890145091, 0.8579234972677595]
2022-01-16 17:37:15:INFO:Loss = [0.4061220603305154, 0.27514773987206265, 0.4075092360824941, 0.31659467052547685, 0.2606312662428488, 0.33491056594813906, 0.4465992673950746, 0.28732024394580513, 0.37235994084705465, 0.45808463329021104]
2022-01-16 17:37:15:INFO:-------------Training local models-------------
2022-01-16 17:38:27:INFO:-------------Aggregating local models-------------
2022-01-16 17:38:28:INFO:-------------Round number: 13-------------
2022-01-16 17:38:28:INFO:-------------Sending models-------------
2022-01-16 17:38:28:INFO:-------------Evaluating models-------------
2022-01-16 17:38:28:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-16 17:38:28:INFO:Accuracy = [0.8696061805162992, 0.8925946862634256, 0.891464104013567, 0.9161484831354815, 0.9285848878839269, 0.8816657245147917, 0.8925946862634256, 0.9180327868852459, 0.884303749764462, 0.858111927642736]
2022-01-16 17:38:28:INFO:Loss = [0.3989268013479333, 0.27296310945941177, 0.4055126894989351, 0.3154130668349928, 0.25804049688323955, 0.33112464093050226, 0.4457297552204041, 0.28260539076023405, 0.36922101636482096, 0.4552640707427904]
2022-01-16 17:38:28:INFO:-------------Training local models-------------
2022-01-16 17:39:40:INFO:-------------Aggregating local models-------------
2022-01-16 17:39:41:INFO:-------------Round number: 14-------------
2022-01-16 17:39:41:INFO:-------------Sending models-------------
2022-01-16 17:39:41:INFO:-------------Evaluating models-------------
2022-01-16 17:39:41:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-16 17:39:41:INFO:Accuracy = [0.873751648765781, 0.8959864330130017, 0.8927831166384022, 0.9174674957603166, 0.9308460523836443, 0.884303749764462, 0.8929715470133786, 0.9193517995100811, 0.8848690408893913, 0.858111927642736]
2022-01-16 17:39:41:INFO:Loss = [0.39200282208988496, 0.2709834491438096, 0.40380453463276667, 0.3143989417934878, 0.2556579496239382, 0.32729119088282077, 0.44486748821878885, 0.2784733156225037, 0.3663512916921214, 0.45244997811558285]
2022-01-16 17:39:41:INFO:-------------Training local models-------------
2022-01-16 17:40:53:INFO:-------------Aggregating local models-------------
2022-01-16 17:40:54:INFO:-------------Round number: 15-------------
2022-01-16 17:40:54:INFO:-------------Sending models-------------
2022-01-16 17:40:54:INFO:-------------Evaluating models-------------
2022-01-16 17:40:54:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-16 17:40:54:INFO:Accuracy = [0.8778971170152629, 0.8997550405125306, 0.8929715470133786, 0.9185980780101752, 0.9325419257584323, 0.8858111927642736, 0.8935368381383079, 0.92312040700961, 0.8859996231392501, 0.8575466365178067]
2022-01-16 17:40:54:INFO:Loss = [0.38534305947904496, 0.26915087236059204, 0.40240434590364793, 0.3135405730011292, 0.2535009993109191, 0.3235188422596322, 0.44407282898004496, 0.27485051272081257, 0.3638308177054595, 0.44968105547818205]
2022-01-16 17:40:54:INFO:-------------Training local models-------------
2022-01-16 17:42:05:INFO:-------------Aggregating local models-------------
2022-01-16 17:42:06:INFO:-------------Round number: 16-------------
2022-01-16 17:42:06:INFO:-------------Sending models-------------
2022-01-16 17:42:06:INFO:-------------Evaluating models-------------
2022-01-16 17:42:07:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-16 17:42:07:INFO:Accuracy = [0.8801582815149802, 0.9025814961371773, 0.8937252685132844, 0.9189749387601281, 0.9327303561334087, 0.8875070661390616, 0.8944789900131901, 0.9253815715093273, 0.8890145091388731, 0.8573582061428302]
2022-01-16 17:42:07:INFO:Loss = [0.3789406640468771, 0.2674261182895182, 0.401190600967644, 0.3127964228180709, 0.2515015497255876, 0.3198988379596506, 0.443262124618531, 0.2716715229558342, 0.36175076689009183, 0.4469200408495773]
2022-01-16 17:42:07:INFO:-------------Training local models-------------
2022-01-16 17:43:17:INFO:-------------Aggregating local models-------------
2022-01-16 17:43:18:INFO:-------------Round number: 17-------------
2022-01-16 17:43:18:INFO:-------------Sending models-------------
2022-01-16 17:43:19:INFO:-------------Evaluating models-------------
2022-01-16 17:43:19:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-16 17:43:19:INFO:Accuracy = [0.8829847371396269, 0.9048426606368947, 0.8950442811381195, 0.919728660260034, 0.9338609383832673, 0.8888260787638967, 0.8954211418880723, 0.9272658752590918, 0.8903335217637083, 0.8569813453928773]
2022-01-16 17:43:19:INFO:Loss = [0.37281512366710007, 0.26579019773414075, 0.4001646979191799, 0.3121549006274253, 0.24966229870739923, 0.31648498158951505, 0.44243783878886134, 0.26887925599399815, 0.3601069830775518, 0.44419389660503095]
2022-01-16 17:43:19:INFO:-------------Training local models-------------
2022-01-16 17:44:30:INFO:-------------Aggregating local models-------------
2022-01-16 17:44:31:INFO:-------------Round number: 18-------------
2022-01-16 17:44:31:INFO:-------------Sending models-------------
2022-01-16 17:44:31:INFO:-------------Evaluating models-------------
2022-01-16 17:44:31:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-16 17:44:31:INFO:Accuracy = [0.884303749764462, 0.9065385340116827, 0.8961748633879781, 0.9195402298850575, 0.9342377991332202, 0.8907103825136612, 0.8957980026380252, 0.9285848878839269, 0.891464104013567, 0.856416054267948]
2022-01-16 17:44:31:INFO:Loss = [0.3669520560910316, 0.26426382932439674, 0.3992315411898661, 0.3115400214519317, 0.24793411611269137, 0.3132107797550767, 0.44157918112799377, 0.2664053059767803, 0.35889662990556875, 0.4415073965856488]
2022-01-16 17:44:31:INFO:-------------Training local models-------------
2022-01-16 17:45:42:INFO:-------------Aggregating local models-------------
2022-01-16 17:45:43:INFO:-------------Round number: 19-------------
2022-01-16 17:45:43:INFO:-------------Sending models-------------
2022-01-16 17:45:43:INFO:-------------Evaluating models-------------
2022-01-16 17:45:43:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-16 17:45:43:INFO:Accuracy = [0.8859996231392501, 0.9082344073864707, 0.896928584887884, 0.921047672884869, 0.9349915206331261, 0.8925946862634256, 0.8963632937629545, 0.9291501790088562, 0.8927831166384022, 0.8562276238929716]
2022-01-16 17:45:43:INFO:Loss = [0.3613597616294328, 0.2628604883470731, 0.3983955184207109, 0.3110120296888149, 0.2463544152059073, 0.31012605997126447, 0.4407185475839137, 0.26421714157881454, 0.35807309692626127, 0.4388907551322331]
2022-01-16 17:45:43:INFO:-------------Training local models-------------
2022-01-16 17:46:54:INFO:-------------Aggregating local models-------------
