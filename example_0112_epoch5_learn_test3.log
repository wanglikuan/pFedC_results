2022-01-12 19:48:58:INFO:-------------Round number: 0-------------
2022-01-12 19:48:58:INFO:-------------Sending models-------------
2022-01-12 19:48:58:INFO:-------------Evaluating models-------------
2022-01-12 19:48:58:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 19:48:58:INFO:Accuracy = [0.901010101010101, 0.8868686868686869, 0.896969696969697, 0.898989898989899, 0.901010101010101, 0.08888888888888889, 0.09494949494949495, 0.10303030303030303, 0.09696969696969697, 0.898989898989899]
2022-01-12 19:48:58:INFO:Loss = [0.6694116484637213, 0.653408883798002, 0.6615643211988488, 0.6542965058425461, 0.6641762230733428, 0.7379018910304465, 0.7407228308795678, 0.7419946313205391, 0.7473327146335081, 0.669854687109138]
2022-01-12 19:48:58:INFO:-------------Training local models-------------
2022-01-12 19:53:47:INFO:-------------updating local masks-------------
2022-01-12 19:53:47:INFO:-------------Aggregating local models-------------
2022-01-12 19:53:49:INFO:-------------Round number: 1-------------
2022-01-12 19:53:49:INFO:-------------Sending models-------------
2022-01-12 19:53:49:INFO:-------------Evaluating models-------------
2022-01-12 19:53:49:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 19:53:49:INFO:Accuracy = [0.9707070707070707, 0.9535353535353536, 0.897979797979798, 0.897979797979798, 0.9616161616161616, 0.9570707070707071, 0.9252525252525252, 0.9262626262626262, 0.9217171717171717, 0.9065656565656566]
2022-01-12 19:53:49:INFO:Loss = [0.07262695824464012, 0.09477750254874917, 0.19510986560513502, 0.19190025067196764, 0.14834378197521084, 0.15541896510403602, 0.1550199327047331, 0.14759908254902734, 0.18349695494151533, 0.21461993210168198]
2022-01-12 19:53:49:INFO:-------------Training local models-------------
2022-01-12 19:58:40:INFO:-------------updating local masks-------------
2022-01-12 19:58:41:INFO:-------------Aggregating local models-------------
2022-01-12 19:58:43:INFO:-------------Round number: 2-------------
2022-01-12 19:58:43:INFO:-------------Sending models-------------
2022-01-12 19:58:43:INFO:-------------Evaluating models-------------
2022-01-12 19:58:43:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 19:58:43:INFO:Accuracy = [0.9974747474747475, 0.9954545454545455, 0.9171717171717172, 0.9207070707070707, 0.9747474747474747, 0.9767676767676767, 0.9611111111111111, 0.9671717171717171, 0.943939393939394, 0.9424242424242424]
2022-01-12 19:58:43:INFO:Loss = [0.02593558860208952, 0.0355451870758458, 0.1393804342614139, 0.13828235265750066, 0.07841663930248799, 0.08415818352692037, 0.0746424583096123, 0.06796365159444953, 0.12763772457655792, 0.14840143336667538]
2022-01-12 19:58:43:INFO:-------------Training local models-------------
2022-01-12 20:03:33:INFO:-------------updating local masks-------------
2022-01-12 20:03:35:INFO:-------------Aggregating local models-------------
2022-01-12 20:03:37:INFO:-------------Round number: 3-------------
2022-01-12 20:03:37:INFO:-------------Sending models-------------
2022-01-12 20:03:37:INFO:-------------Evaluating models-------------
2022-01-12 20:03:37:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 20:03:37:INFO:Accuracy = [1.0, 0.9984848484848485, 0.9368686868686869, 0.9388888888888889, 0.9883838383838384, 0.9868686868686869, 0.9843434343434343, 0.9888888888888889, 0.953030303030303, 0.95]
2022-01-12 20:03:37:INFO:Loss = [0.013332403043221513, 0.018157278935629594, 0.1080667490175469, 0.10755068439075423, 0.04536115455084287, 0.048541122031365194, 0.044577423967814986, 0.0404355700777766, 0.09878008957855836, 0.11356976624675838]
2022-01-12 20:03:37:INFO:-------------Training local models-------------
2022-01-12 20:08:28:INFO:-------------updating local masks-------------
2022-01-12 20:08:29:INFO:-------------Aggregating local models-------------
2022-01-12 20:08:31:INFO:-------------Round number: 4-------------
2022-01-12 20:08:31:INFO:-------------Sending models-------------
2022-01-12 20:08:31:INFO:-------------Evaluating models-------------
2022-01-12 20:08:31:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 20:08:31:INFO:Accuracy = [1.0, 1.0, 0.9505050505050505, 0.951010101010101, 0.9944444444444445, 0.9944444444444445, 0.9939393939393939, 0.9934343434343434, 0.9585858585858585, 0.9575757575757575]
2022-01-12 20:08:31:INFO:Loss = [0.00855790339101628, 0.011524360391959275, 0.08748018688321198, 0.08734936848602662, 0.030647824217319593, 0.032292591706400434, 0.029960420559721323, 0.027190629263364973, 0.08179994586429198, 0.09434181209506627]
2022-01-12 20:08:31:INFO:-------------Training local models-------------
2022-01-12 20:13:24:INFO:-------------updating local masks-------------
2022-01-12 20:13:26:INFO:-------------Aggregating local models-------------
2022-01-12 20:13:27:INFO:-------------Round number: 5-------------
2022-01-12 20:13:27:INFO:-------------Sending models-------------
2022-01-12 20:13:28:INFO:-------------Evaluating models-------------
2022-01-12 20:13:28:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 20:13:28:INFO:Accuracy = [1.0, 1.0, 0.9656565656565657, 0.9656565656565657, 0.9959595959595959, 0.9949494949494949, 0.9954545454545455, 0.9964646464646465, 0.9651515151515152, 0.9611111111111111]
2022-01-12 20:13:28:INFO:Loss = [0.006176199027715778, 0.008251969930874608, 0.07310543926891334, 0.07348246008799779, 0.022926773910141418, 0.02381573180965562, 0.021879090910225947, 0.020090908710794837, 0.06973835142698866, 0.08076101942181897]
2022-01-12 20:13:28:INFO:-------------Training local models-------------
2022-01-12 20:18:20:INFO:-------------updating local masks-------------
2022-01-12 20:18:22:INFO:-------------Aggregating local models-------------
2022-01-12 20:18:23:INFO:-------------Round number: 6-------------
2022-01-12 20:18:23:INFO:-------------Sending models-------------
2022-01-12 20:18:23:INFO:-------------Evaluating models-------------
2022-01-12 20:18:23:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 20:18:23:INFO:Accuracy = [1.0, 1.0, 0.9702020202020202, 0.9696969696969697, 0.9959595959595959, 0.9959595959595959, 0.9974747474747475, 0.997979797979798, 0.9707070707070707, 0.9636363636363636]
2022-01-12 20:18:23:INFO:Loss = [0.00477419137524622, 0.006341994281169121, 0.06303172412299318, 0.06383579457645402, 0.018276258101648617, 0.01877379235069237, 0.01722856368938628, 0.01601858790198075, 0.06068794438441994, 0.07033422654574017]
2022-01-12 20:18:23:INFO:-------------Training local models-------------
2022-01-12 20:23:14:INFO:-------------updating local masks-------------
2022-01-12 20:23:16:INFO:-------------Aggregating local models-------------
2022-01-12 20:23:18:INFO:-------------Round number: 7-------------
2022-01-12 20:23:18:INFO:-------------Sending models-------------
2022-01-12 20:23:18:INFO:-------------Evaluating models-------------
2022-01-12 20:23:18:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 20:23:18:INFO:Accuracy = [1.0, 1.0, 0.9737373737373738, 0.9722222222222222, 0.996969696969697, 0.9974747474747475, 0.996969696969697, 0.9974747474747475, 0.9752525252525253, 0.9707070707070707]
2022-01-12 20:23:18:INFO:Loss = [0.0038581914550065055, 0.005099860745622668, 0.055999502040812686, 0.05707384469791614, 0.015218352308176985, 0.015500255598321515, 0.014311303011088213, 0.01344014284273873, 0.05370518021818957, 0.06177268555535432]
2022-01-12 20:23:18:INFO:-------------Training local models-------------
2022-01-12 20:28:08:INFO:-------------updating local masks-------------
2022-01-12 20:28:09:INFO:-------------Aggregating local models-------------
2022-01-12 20:28:11:INFO:-------------Round number: 8-------------
2022-01-12 20:28:11:INFO:-------------Sending models-------------
2022-01-12 20:28:11:INFO:-------------Evaluating models-------------
2022-01-12 20:28:11:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 20:28:11:INFO:Accuracy = [1.0, 1.0, 0.9767676767676767, 0.9767676767676767, 0.997979797979798, 0.997979797979798, 0.9974747474747475, 0.9974747474747475, 0.9813131313131314, 0.9752525252525253]
2022-01-12 20:28:11:INFO:Loss = [0.0032184164534996714, 0.004234231280346961, 0.051007175262555285, 0.05223202897992598, 0.013080815563061877, 0.0132364027274007, 0.01232214440420244, 0.011662955951620884, 0.04847315910069162, 0.05483970331388815]
2022-01-12 20:28:11:INFO:-------------Training local models-------------
2022-01-12 20:32:56:INFO:-------------updating local masks-------------
2022-01-12 20:32:58:INFO:-------------Aggregating local models-------------
2022-01-12 20:32:59:INFO:-------------Round number: 9-------------
2022-01-12 20:32:59:INFO:-------------Sending models-------------
2022-01-12 20:32:59:INFO:-------------Evaluating models-------------
2022-01-12 20:33:00:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 20:33:00:INFO:Accuracy = [1.0, 1.0, 0.9777777777777777, 0.9782828282828283, 0.9984848484848485, 0.997979797979798, 0.9974747474747475, 0.9974747474747475, 0.9818181818181818, 0.9777777777777777]
2022-01-12 20:33:00:INFO:Loss = [0.0027510521374584053, 0.003602280329431953, 0.047287716988413574, 0.04857783188069306, 0.011518361420982701, 0.011595029731732652, 0.01088626753083769, 0.010369132232807889, 0.04459068196881686, 0.04942501709276735]
2022-01-12 20:33:00:INFO:-------------Training local models-------------
2022-01-12 20:37:44:INFO:-------------updating local masks-------------
2022-01-12 20:37:46:INFO:-------------Aggregating local models-------------
2022-01-12 20:37:47:INFO:-------------Round number: 10-------------
2022-01-12 20:37:47:INFO:-------------Sending models-------------
2022-01-12 20:37:47:INFO:-------------Evaluating models-------------
2022-01-12 20:37:48:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 20:37:48:INFO:Accuracy = [1.0, 1.0, 0.9823232323232324, 0.9803030303030303, 0.998989898989899, 0.9984848484848485, 0.9974747474747475, 0.9974747474747475, 0.9838383838383838, 0.9808080808080808]
2022-01-12 20:37:48:INFO:Loss = [0.002396546574744556, 0.0031232755131004705, 0.044382120017969165, 0.045701097012080034, 0.010334243868029913, 0.010363207303570827, 0.00980085812360895, 0.009384337036831909, 0.04167337093504929, 0.04529359930137883]
2022-01-12 20:37:48:INFO:-------------Training local models-------------
2022-01-12 20:42:34:INFO:-------------updating local masks-------------
2022-01-12 20:42:35:INFO:-------------Aggregating local models-------------
2022-01-12 20:42:37:INFO:-------------Round number: 11-------------
2022-01-12 20:42:37:INFO:-------------Sending models-------------
2022-01-12 20:42:37:INFO:-------------Evaluating models-------------
2022-01-12 20:42:37:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 20:42:37:INFO:Accuracy = [1.0, 1.0, 0.9828282828282828, 0.9803030303030303, 0.9994949494949495, 0.9984848484848485, 0.9974747474747475, 0.9974747474747475, 0.9843434343434343, 0.9833333333333333]
2022-01-12 20:42:37:INFO:Loss = [0.0021197424369577243, 0.0027491978658780673, 0.04202454879584797, 0.04333622702313622, 0.009405648152761672, 0.009404122875305187, 0.008953692418634257, 0.00861171153041821, 0.03935934423700221, 0.0420833035736069]
2022-01-12 20:42:37:INFO:-------------Training local models-------------
2022-01-12 20:47:22:INFO:-------------updating local masks-------------
2022-01-12 20:47:23:INFO:-------------Aggregating local models-------------
2022-01-12 20:47:25:INFO:-------------Round number: 12-------------
2022-01-12 20:47:25:INFO:-------------Sending models-------------
2022-01-12 20:47:26:INFO:-------------Evaluating models-------------
2022-01-12 20:47:26:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 20:47:26:INFO:Accuracy = [1.0, 1.0, 0.9833333333333333, 0.9818181818181818, 0.9994949494949495, 0.9984848484848485, 0.9974747474747475, 0.9974747474747475, 0.9853535353535353, 0.9838383838383838]
2022-01-12 20:47:26:INFO:Loss = [0.001898721449752985, 0.0024504754261050203, 0.04005239216104853, 0.04134079495890565, 0.008653181069758379, 0.008631518934330094, 0.008272497589878369, 0.007987564352787548, 0.03749014636739204, 0.03956477077274508]
2022-01-12 20:47:26:INFO:-------------Training local models-------------
2022-01-12 20:52:12:INFO:-------------updating local masks-------------
2022-01-12 20:52:13:INFO:-------------Aggregating local models-------------
2022-01-12 20:52:15:INFO:-------------Round number: 13-------------
2022-01-12 20:52:15:INFO:-------------Sending models-------------
2022-01-12 20:52:15:INFO:-------------Evaluating models-------------
2022-01-12 20:52:15:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 20:52:15:INFO:Accuracy = [1.0, 1.0, 0.9838383838383838, 0.9823232323232324, 0.9994949494949495, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9858585858585859, 0.9863636363636363]
2022-01-12 20:52:15:INFO:Loss = [0.0017207283012564834, 0.002210145859509904, 0.03837355181379032, 0.03963100293585005, 0.008037126816899135, 0.008001527774416385, 0.007716764902094535, 0.007476753047211042, 0.03594199133165768, 0.03754914938938902]
2022-01-12 20:52:15:INFO:-------------Training local models-------------
2022-01-12 20:57:02:INFO:-------------updating local masks-------------
2022-01-12 20:57:04:INFO:-------------Aggregating local models-------------
2022-01-12 20:57:06:INFO:-------------Round number: 14-------------
2022-01-12 20:57:06:INFO:-------------Sending models-------------
2022-01-12 20:57:06:INFO:-------------Evaluating models-------------
2022-01-12 20:57:06:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 20:57:06:INFO:Accuracy = [1.0, 1.0, 0.9848484848484849, 0.9833333333333333, 0.9994949494949495, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9863636363636363, 0.9868686868686869]
2022-01-12 20:57:06:INFO:Loss = [0.001573881501135842, 0.0020120208205583485, 0.0369034639998228, 0.03810631123933582, 0.007525488381500995, 0.00747938635994973, 0.007252369112209616, 0.007048652031156999, 0.034626939507841306, 0.03589582231858242]
2022-01-12 20:57:06:INFO:-------------Training local models-------------
2022-01-12 21:01:53:INFO:-------------updating local masks-------------
2022-01-12 21:01:55:INFO:-------------Aggregating local models-------------
2022-01-12 21:01:56:INFO:-------------Round number: 15-------------
2022-01-12 21:01:56:INFO:-------------Sending models-------------
2022-01-12 21:01:56:INFO:-------------Evaluating models-------------
2022-01-12 21:01:56:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 21:01:56:INFO:Accuracy = [1.0, 1.0, 0.9848484848484849, 0.9843434343434343, 0.9994949494949495, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9868686868686869, 0.9863636363636363]
2022-01-12 21:01:56:INFO:Loss = [0.0014513653131246547, 0.0018468370310570621, 0.03561858311311678, 0.036769156639642496, 0.007088404370465515, 0.007036259005940107, 0.006858607300345091, 0.006684580903524278, 0.033501138571903934, 0.03452604881724733]
2022-01-12 21:01:56:INFO:-------------Training local models-------------
2022-01-12 21:06:43:INFO:-------------updating local masks-------------
2022-01-12 21:06:45:INFO:-------------Aggregating local models-------------
2022-01-12 21:06:46:INFO:-------------Round number: 16-------------
2022-01-12 21:06:46:INFO:-------------Sending models-------------
2022-01-12 21:06:46:INFO:-------------Evaluating models-------------
2022-01-12 21:06:46:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 21:06:46:INFO:Accuracy = [1.0, 1.0, 0.9848484848484849, 0.9848484848484849, 0.9994949494949495, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9873737373737373, 0.9863636363636363]
2022-01-12 21:06:46:INFO:Loss = [0.0013474477182869738, 0.0017067919544287078, 0.03449006404790829, 0.035589927701335226, 0.006717624134339852, 0.006661900387395019, 0.006520606434659008, 0.00637099895344602, 0.032563885977328434, 0.03340944271807199]
2022-01-12 21:06:46:INFO:-------------Training local models-------------
2022-01-12 21:11:34:INFO:-------------updating local masks-------------
2022-01-12 21:11:36:INFO:-------------Aggregating local models-------------
2022-01-12 21:11:37:INFO:-------------Round number: 17-------------
2022-01-12 21:11:37:INFO:-------------Sending models-------------
2022-01-12 21:11:37:INFO:-------------Evaluating models-------------
2022-01-12 21:11:37:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 21:11:37:INFO:Accuracy = [1.0, 1.0, 0.9863636363636363, 0.9858585858585859, 0.998989898989899, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9873737373737373, 0.9863636363636363]
2022-01-12 21:11:37:INFO:Loss = [0.0012582156093993383, 0.0015867051152974564, 0.03348015899961562, 0.03453248388449896, 0.006396798195966785, 0.006339534591476115, 0.00622677318650757, 0.0060973696626546135, 0.031781906638409255, 0.03248888012051178]
2022-01-12 21:11:37:INFO:-------------Training local models-------------
2022-01-12 21:16:23:INFO:-------------updating local masks-------------
2022-01-12 21:16:25:INFO:-------------Aggregating local models-------------
2022-01-12 21:16:27:INFO:-------------Round number: 18-------------
2022-01-12 21:16:27:INFO:-------------Sending models-------------
2022-01-12 21:16:27:INFO:-------------Evaluating models-------------
2022-01-12 21:16:27:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 21:16:27:INFO:Accuracy = [1.0, 1.0, 0.9868686868686869, 0.9863636363636363, 0.998989898989899, 0.998989898989899, 0.997979797979798, 0.9974747474747475, 0.9873737373737373, 0.9873737373737373]
2022-01-12 21:16:27:INFO:Loss = [0.001181073086994766, 0.0014831044440859731, 0.032593262616313894, 0.03360466416154234, 0.006119457811820956, 0.006061910259619125, 0.005969467753190353, 0.005857057971286739, 0.031135318267299244, 0.031729470290104866]
2022-01-12 21:16:27:INFO:-------------Training local models-------------
2022-01-12 21:21:13:INFO:-------------updating local masks-------------
2022-01-12 21:21:14:INFO:-------------Aggregating local models-------------
2022-01-12 21:21:16:INFO:-------------Round number: 19-------------
2022-01-12 21:21:16:INFO:-------------Sending models-------------
2022-01-12 21:21:16:INFO:-------------Evaluating models-------------
2022-01-12 21:21:16:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 21:21:16:INFO:Accuracy = [1.0, 1.0, 0.9873737373737373, 0.9868686868686869, 0.998989898989899, 0.998989898989899, 0.997979797979798, 0.9974747474747475, 0.9878787878787879, 0.9873737373737373]
2022-01-12 21:21:16:INFO:Loss = [0.0011136505780215352, 0.0013927559180533858, 0.03180067591923521, 0.032767490766664104, 0.0058761189949210445, 0.005819037918667567, 0.0057415515021685595, 0.005643505822232015, 0.030551988719680317, 0.03106213761775415]
2022-01-12 21:21:16:INFO:-------------Training local models-------------
2022-01-12 21:26:03:INFO:-------------updating local masks-------------
2022-01-12 21:26:05:INFO:-------------Aggregating local models-------------
2022-01-12 21:26:07:INFO:-------------Round number: 20-------------
2022-01-12 21:26:07:INFO:-------------Sending models-------------
2022-01-12 21:26:07:INFO:-------------Evaluating models-------------
2022-01-12 21:26:07:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 21:26:07:INFO:Accuracy = [1.0, 1.0, 0.9873737373737373, 0.9868686868686869, 0.998989898989899, 0.998989898989899, 0.997979797979798, 0.9974747474747475, 0.9873737373737373, 0.9878787878787879]
2022-01-12 21:26:07:INFO:Loss = [0.0010544208834501044, 0.001313530525989005, 0.031102687029208872, 0.032029141510444024, 0.005661721264399915, 0.005605098650042724, 0.005538633319850884, 0.00545276440089866, 0.03005990422195714, 0.030502430834846994]
2022-01-12 21:26:07:INFO:-------------Training local models-------------
2022-01-12 21:30:55:INFO:-------------updating local masks-------------
2022-01-12 21:30:57:INFO:-------------Aggregating local models-------------
2022-01-12 21:30:59:INFO:-------------Round number: 21-------------
2022-01-12 21:30:59:INFO:-------------Sending models-------------
2022-01-12 21:30:59:INFO:-------------Evaluating models-------------
2022-01-12 21:30:59:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 21:30:59:INFO:Accuracy = [1.0, 1.0, 0.9873737373737373, 0.9868686868686869, 0.998989898989899, 0.998989898989899, 0.997979797979798, 0.9974747474747475, 0.9873737373737373, 0.9873737373737373]
2022-01-12 21:30:59:INFO:Loss = [0.0010019164040818167, 0.0012434185342921997, 0.03047137682202594, 0.03135734809511816, 0.005469723522055758, 0.005412791787191486, 0.005356501558800128, 0.005281110275087724, 0.029634679477828166, 0.030026433261773122]
2022-01-12 21:30:59:INFO:-------------Training local models-------------
2022-01-12 21:35:45:INFO:-------------updating local masks-------------
2022-01-12 21:35:47:INFO:-------------Aggregating local models-------------
2022-01-12 21:35:49:INFO:-------------Round number: 22-------------
2022-01-12 21:35:49:INFO:-------------Sending models-------------
2022-01-12 21:35:49:INFO:-------------Evaluating models-------------
2022-01-12 21:35:49:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 21:35:49:INFO:Accuracy = [1.0, 1.0, 0.9873737373737373, 0.9868686868686869, 0.998989898989899, 0.998989898989899, 0.997979797979798, 0.9974747474747475, 0.9873737373737373, 0.9873737373737373]
2022-01-12 21:35:49:INFO:Loss = [0.0009549435200107947, 0.001180811226882412, 0.0299005711478917, 0.03075057570188463, 0.005298423532032316, 0.005241576970898549, 0.005192120364844955, 0.0051257073534589385, 0.02928634483379772, 0.02963527390222795]
2022-01-12 21:35:49:INFO:-------------Training local models-------------
2022-01-12 21:40:36:INFO:-------------updating local masks-------------
2022-01-12 21:40:37:INFO:-------------Aggregating local models-------------
2022-01-12 21:40:39:INFO:-------------Round number: 23-------------
2022-01-12 21:40:39:INFO:-------------Sending models-------------
2022-01-12 21:40:39:INFO:-------------Evaluating models-------------
2022-01-12 21:40:39:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 21:40:39:INFO:Accuracy = [1.0, 1.0, 0.9873737373737373, 0.9873737373737373, 0.998989898989899, 0.998989898989899, 0.997979797979798, 0.997979797979798, 0.9883838383838384, 0.9878787878787879]
2022-01-12 21:40:39:INFO:Loss = [0.0009127294752676854, 0.0011247090609171522, 0.029366789669806204, 0.03017989187693743, 0.005144831499476115, 0.0050889241220122335, 0.005043202878085948, 0.004984637773832035, 0.028987060544066922, 0.029299122952958133]
2022-01-12 21:40:39:INFO:-------------Training local models-------------
2022-01-12 21:45:27:INFO:-------------updating local masks-------------
2022-01-12 21:45:28:INFO:-------------Aggregating local models-------------
2022-01-12 21:45:30:INFO:-------------Round number: 24-------------
2022-01-12 21:45:30:INFO:-------------Sending models-------------
2022-01-12 21:45:30:INFO:-------------Evaluating models-------------
2022-01-12 21:45:31:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 21:45:31:INFO:Accuracy = [1.0, 1.0, 0.9873737373737373, 0.9873737373737373, 0.998989898989899, 0.998989898989899, 0.997979797979798, 0.9984848484848485, 0.9878787878787879, 0.9883838383838384]
2022-01-12 21:45:31:INFO:Loss = [0.0008746923706958757, 0.001074246900349284, 0.0288871314331614, 0.02966651402765259, 0.005009029349402585, 0.004954895355729953, 0.004906685199213568, 0.004854926493162841, 0.02872941192230924, 0.029004797017228388]
2022-01-12 21:45:31:INFO:-------------Training local models-------------
2022-01-12 21:50:17:INFO:-------------updating local masks-------------
2022-01-12 21:50:19:INFO:-------------Aggregating local models-------------
2022-01-12 21:50:21:INFO:-------------Round number: 25-------------
2022-01-12 21:50:21:INFO:-------------Sending models-------------
2022-01-12 21:50:21:INFO:-------------Evaluating models-------------
2022-01-12 21:50:21:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 21:50:21:INFO:Accuracy = [1.0, 1.0, 0.9883838383838384, 0.9873737373737373, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.9878787878787879, 0.9883838383838384]
2022-01-12 21:50:21:INFO:Loss = [0.0008403754205886284, 0.0010288139522537786, 0.028454478863237785, 0.029201195029390597, 0.004885009293943629, 0.004832281104847995, 0.004781696887463719, 0.004736037980524777, 0.02852393792805981, 0.028765684423618067]
2022-01-12 21:50:21:INFO:-------------Training local models-------------
2022-01-12 21:55:09:INFO:-------------updating local masks-------------
2022-01-12 21:55:11:INFO:-------------Aggregating local models-------------
2022-01-12 21:55:12:INFO:-------------Round number: 26-------------
2022-01-12 21:55:12:INFO:-------------Sending models-------------
2022-01-12 21:55:12:INFO:-------------Evaluating models-------------
2022-01-12 21:55:12:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 21:55:12:INFO:Accuracy = [1.0, 1.0, 0.9883838383838384, 0.9873737373737373, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.9878787878787879, 0.9883838383838384]
2022-01-12 21:55:12:INFO:Loss = [0.0008091827634177547, 0.0009876260171086419, 0.02804270608359013, 0.028750558760982654, 0.004774434515712353, 0.004723444155307435, 0.004667038213014937, 0.004626844445473663, 0.02835900971651537, 0.02857163048686587]
2022-01-12 21:55:12:INFO:-------------Training local models-------------
2022-01-12 21:59:59:INFO:-------------updating local masks-------------
2022-01-12 22:00:01:INFO:-------------Aggregating local models-------------
2022-01-12 22:00:03:INFO:-------------Round number: 27-------------
2022-01-12 22:00:03:INFO:-------------Sending models-------------
2022-01-12 22:00:03:INFO:-------------Evaluating models-------------
2022-01-12 22:00:03:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 22:00:03:INFO:Accuracy = [1.0, 1.0, 0.9883838383838384, 0.9873737373737373, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.9878787878787879, 0.9893939393939394]
2022-01-12 22:00:03:INFO:Loss = [0.0007808497136475217, 0.0009503150103476152, 0.027669578825218123, 0.028342730074096708, 0.004674273576185644, 0.0046247590898120606, 0.004562133091451989, 0.004526619664837272, 0.0282090539593525, 0.028393969652001895]
2022-01-12 22:00:03:INFO:-------------Training local models-------------
2022-01-12 22:04:50:INFO:-------------updating local masks-------------
2022-01-12 22:04:52:INFO:-------------Aggregating local models-------------
2022-01-12 22:04:54:INFO:-------------Round number: 28-------------
2022-01-12 22:04:54:INFO:-------------Sending models-------------
2022-01-12 22:04:55:INFO:-------------Evaluating models-------------
2022-01-12 22:04:55:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 22:04:55:INFO:Accuracy = [1.0, 1.0, 0.9883838383838384, 0.9878787878787879, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.9878787878787879, 0.9893939393939394]
2022-01-12 22:04:55:INFO:Loss = [0.0007548822585970746, 0.0009162268392413013, 0.02734050156348604, 0.027979377827746663, 0.00458223678989004, 0.0045340809875496135, 0.004465278668291344, 0.004433817150930561, 0.028082624396728248, 0.028243007450282215]
2022-01-12 22:04:55:INFO:-------------Training local models-------------
2022-01-12 22:09:43:INFO:-------------updating local masks-------------
2022-01-12 22:09:45:INFO:-------------Aggregating local models-------------
2022-01-12 22:09:46:INFO:-------------Round number: 29-------------
2022-01-12 22:09:46:INFO:-------------Sending models-------------
2022-01-12 22:09:47:INFO:-------------Evaluating models-------------
2022-01-12 22:09:47:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 22:09:47:INFO:Accuracy = [1.0, 1.0, 0.9883838383838384, 0.9878787878787879, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.9883838383838384, 0.9893939393939394]
2022-01-12 22:09:47:INFO:Loss = [0.0007308759544317545, 0.0008847919127899763, 0.027033335749308548, 0.027641645716591088, 0.004496290105754554, 0.004449292650273069, 0.004375361918832685, 0.004347542359129066, 0.02796855934971201, 0.028105222212972802]
2022-01-12 22:09:47:INFO:-------------Training local models-------------
2022-01-12 22:14:35:INFO:-------------updating local masks-------------
2022-01-12 22:14:37:INFO:-------------Aggregating local models-------------
2022-01-12 22:14:39:INFO:-------------Round number: 30-------------
2022-01-12 22:14:39:INFO:-------------Sending models-------------
2022-01-12 22:14:39:INFO:-------------Evaluating models-------------
2022-01-12 22:14:39:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 22:14:39:INFO:Accuracy = [1.0, 1.0, 0.9883838383838384, 0.9878787878787879, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.9883838383838384, 0.9888888888888889]
2022-01-12 22:14:39:INFO:Loss = [0.0007086124056256423, 0.0008557162363168307, 0.02675280186327342, 0.02733421427493717, 0.0044173926263164215, 0.004371161597467135, 0.004291539503949502, 0.004266840899432245, 0.02786730910341092, 0.027981134418212494]
2022-01-12 22:14:39:INFO:-------------Training local models-------------
2022-01-12 22:19:28:INFO:-------------updating local masks-------------
2022-01-12 22:19:30:INFO:-------------Aggregating local models-------------
2022-01-12 22:19:32:INFO:-------------Round number: 31-------------
2022-01-12 22:19:32:INFO:-------------Sending models-------------
2022-01-12 22:19:32:INFO:-------------Evaluating models-------------
2022-01-12 22:19:32:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 22:19:32:INFO:Accuracy = [1.0, 1.0, 0.9888888888888889, 0.9883838383838384, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.9888888888888889, 0.9888888888888889]
2022-01-12 22:19:32:INFO:Loss = [0.000687937370240994, 0.0008288113235969583, 0.02647309420547875, 0.02702856364270738, 0.004344550265649918, 0.004298428689666748, 0.004213666389691156, 0.004191622175224466, 0.027793324542019972, 0.027886946748519836]
2022-01-12 22:19:32:INFO:-------------Training local models-------------
2022-01-12 22:24:20:INFO:-------------updating local masks-------------
2022-01-12 22:24:22:INFO:-------------Aggregating local models-------------
2022-01-12 22:24:24:INFO:-------------Round number: 32-------------
2022-01-12 22:24:24:INFO:-------------Sending models-------------
2022-01-12 22:24:24:INFO:-------------Evaluating models-------------
2022-01-12 22:24:24:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 22:24:24:INFO:Accuracy = [1.0, 1.0, 0.9888888888888889, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.9888888888888889, 0.9888888888888889]
2022-01-12 22:24:24:INFO:Loss = [0.0006686856954499921, 0.000803864592036016, 0.026217542911981948, 0.026749396997435514, 0.00427929007826863, 0.0042332565517077606, 0.004141335293375831, 0.00412166426548988, 0.027735378602007376, 0.027809368440707336]
2022-01-12 22:24:24:INFO:-------------Training local models-------------
2022-01-12 22:29:12:INFO:-------------updating local masks-------------
2022-01-12 22:29:14:INFO:-------------Aggregating local models-------------
2022-01-12 22:29:16:INFO:-------------Round number: 33-------------
2022-01-12 22:29:16:INFO:-------------Sending models-------------
2022-01-12 22:29:16:INFO:-------------Evaluating models-------------
2022-01-12 22:29:16:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 22:29:16:INFO:Accuracy = [1.0, 1.0, 0.9893939393939394, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.9888888888888889, 0.9883838383838384]
2022-01-12 22:29:16:INFO:Loss = [0.0006507005333204312, 0.0007806137471396306, 0.025979367011747644, 0.026489615440681003, 0.004222383068174002, 0.004175712247550366, 0.004073875846199481, 0.004056326241205703, 0.02769530916728473, 0.02775458678316507]
2022-01-12 22:29:16:INFO:-------------Training local models-------------
2022-01-12 22:34:03:INFO:-------------updating local masks-------------
2022-01-12 22:34:05:INFO:-------------Aggregating local models-------------
2022-01-12 22:34:07:INFO:-------------Round number: 34-------------
2022-01-12 22:34:07:INFO:-------------Sending models-------------
2022-01-12 22:34:07:INFO:-------------Evaluating models-------------
2022-01-12 22:34:07:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 22:34:07:INFO:Accuracy = [1.0, 1.0, 0.98989898989899, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9888888888888889, 0.9888888888888889]
2022-01-12 22:34:07:INFO:Loss = [0.0006339046981053678, 0.0007589692603770262, 0.02576145271678531, 0.026255218831237923, 0.004168228849985006, 0.00412072630825247, 0.004010317895795243, 0.003994660632621033, 0.027651327731998916, 0.027695026651373623]
2022-01-12 22:34:07:INFO:-------------Training local models-------------
2022-01-12 22:38:55:INFO:-------------updating local masks-------------
2022-01-12 22:38:57:INFO:-------------Aggregating local models-------------
2022-01-12 22:38:59:INFO:-------------Round number: 35-------------
2022-01-12 22:38:59:INFO:-------------Sending models-------------
2022-01-12 22:38:59:INFO:-------------Evaluating models-------------
2022-01-12 22:38:59:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 22:38:59:INFO:Accuracy = [1.0, 1.0, 0.98989898989899, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9893939393939394, 0.9888888888888889]
2022-01-12 22:38:59:INFO:Loss = [0.0006182176384754712, 0.0007388216421017517, 0.025559586164461214, 0.026035959660287454, 0.004116728308955234, 0.0040684973551466065, 0.003950542341342291, 0.0039365984535503565, 0.02761560661911246, 0.027646181423292684]
2022-01-12 22:38:59:INFO:-------------Training local models-------------
2022-01-12 22:43:49:INFO:-------------updating local masks-------------
2022-01-12 22:43:51:INFO:-------------Aggregating local models-------------
2022-01-12 22:43:53:INFO:-------------Round number: 36-------------
2022-01-12 22:43:53:INFO:-------------Sending models-------------
2022-01-12 22:43:53:INFO:-------------Evaluating models-------------
2022-01-12 22:43:53:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 22:43:53:INFO:Accuracy = [1.0, 1.0, 0.98989898989899, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9893939393939394, 0.9893939393939394]
2022-01-12 22:43:53:INFO:Loss = [0.0006034899920000544, 0.0007199361572433686, 0.025360743782041045, 0.02582070712596301, 0.004067327977765047, 0.004018562576125951, 0.0038943257316412824, 0.003881943779515036, 0.02757061923355356, 0.027587722691495942]
2022-01-12 22:43:53:INFO:-------------Training local models-------------
2022-01-12 22:48:42:INFO:-------------updating local masks-------------
2022-01-12 22:48:44:INFO:-------------Aggregating local models-------------
2022-01-12 22:48:46:INFO:-------------Round number: 37-------------
2022-01-12 22:48:46:INFO:-------------Sending models-------------
2022-01-12 22:48:46:INFO:-------------Evaluating models-------------
2022-01-12 22:48:46:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 22:48:46:INFO:Accuracy = [1.0, 1.0, 0.98989898989899, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9904040404040404, 0.98989898989899]
2022-01-12 22:48:46:INFO:Loss = [0.0005896663906627729, 0.0007022411828662793, 0.02518701329618584, 0.02563372743646812, 0.004020578647210604, 0.003971280212319489, 0.00384132060372771, 0.003830491729117645, 0.02753756576367052, 0.027543589509892774]
2022-01-12 22:48:46:INFO:-------------Training local models-------------
2022-01-12 22:53:35:INFO:-------------updating local masks-------------
2022-01-12 22:53:37:INFO:-------------Aggregating local models-------------
2022-01-12 22:53:39:INFO:-------------Round number: 38-------------
2022-01-12 22:53:39:INFO:-------------Sending models-------------
2022-01-12 22:53:39:INFO:-------------Evaluating models-------------
2022-01-12 22:53:39:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 22:53:39:INFO:Accuracy = [1.0, 1.0, 0.98989898989899, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9904040404040404, 0.9904040404040404]
2022-01-12 22:53:39:INFO:Loss = [0.0005765794443376385, 0.0006855322492305681, 0.025017699998582, 0.025451098326785274, 0.00397626896019482, 0.003926507970207221, 0.003791079569993893, 0.003781637488842681, 0.027513170229361672, 0.027508987159982474]
2022-01-12 22:53:39:INFO:-------------Training local models-------------
2022-01-12 22:58:27:INFO:-------------updating local masks-------------
2022-01-12 22:58:30:INFO:-------------Aggregating local models-------------
2022-01-12 22:58:31:INFO:-------------Round number: 39-------------
2022-01-12 22:58:31:INFO:-------------Sending models-------------
2022-01-12 22:58:31:INFO:-------------Evaluating models-------------
2022-01-12 22:58:32:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 22:58:32:INFO:Accuracy = [1.0, 1.0, 0.98989898989899, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9904040404040404, 0.9904040404040404]
2022-01-12 22:58:32:INFO:Loss = [0.0005642650338179947, 0.0006698725655161355, 0.024855248434792112, 0.02527407347437236, 0.003935822384144815, 0.0038856516113644993, 0.0037437560405132993, 0.00373551760341724, 0.027477605729064186, 0.027464653899069807]
2022-01-12 22:58:32:INFO:-------------Training local models-------------
2022-01-12 23:03:20:INFO:-------------updating local masks-------------
2022-01-12 23:03:22:INFO:-------------Aggregating local models-------------
2022-01-12 23:03:24:INFO:-------------Round number: 40-------------
2022-01-12 23:03:24:INFO:-------------Sending models-------------
2022-01-12 23:03:24:INFO:-------------Evaluating models-------------
2022-01-12 23:03:24:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 23:03:24:INFO:Accuracy = [1.0, 1.0, 0.98989898989899, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.98989898989899, 0.9904040404040404]
2022-01-12 23:03:24:INFO:Loss = [0.0005526595584700717, 0.0006551482044516079, 0.024709551267606555, 0.02511363886833167, 0.003897802457837003, 0.003847486113115126, 0.003699228557455383, 0.0036920872863622136, 0.027453125972376504, 0.027432914496590327]
2022-01-12 23:03:24:INFO:-------------Training local models-------------
2022-01-12 23:08:12:INFO:-------------updating local masks-------------
2022-01-12 23:08:14:INFO:-------------Aggregating local models-------------
2022-01-12 23:08:16:INFO:-------------Round number: 41-------------
2022-01-12 23:08:16:INFO:-------------Sending models-------------
2022-01-12 23:08:16:INFO:-------------Evaluating models-------------
2022-01-12 23:08:16:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 23:08:16:INFO:Accuracy = [1.0, 1.0, 0.98989898989899, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9904040404040404, 0.9904040404040404]
2022-01-12 23:08:16:INFO:Loss = [0.00054165826442859, 0.0006412128797305143, 0.02457787064163175, 0.02496938446717071, 0.003859916267115617, 0.0038093282594167653, 0.0036572271887181534, 0.003651034395265051, 0.027435416515677068, 0.027407606083015523]
2022-01-12 23:08:16:INFO:-------------Training local models-------------
2022-01-12 23:13:04:INFO:-------------updating local masks-------------
2022-01-12 23:13:07:INFO:-------------Aggregating local models-------------
2022-01-12 23:13:09:INFO:-------------Round number: 42-------------
2022-01-12 23:13:09:INFO:-------------Sending models-------------
2022-01-12 23:13:09:INFO:-------------Evaluating models-------------
2022-01-12 23:13:09:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 23:13:09:INFO:Accuracy = [1.0, 1.0, 0.98989898989899, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9904040404040404, 0.9904040404040404]
2022-01-12 23:13:09:INFO:Loss = [0.0005311991950183063, 0.0006280040812454918, 0.024448194007031403, 0.02482615215116532, 0.003823892307113368, 0.003772917815369896, 0.0036174471965061844, 0.0036121324816654906, 0.027421430253560523, 0.027386052498804193]
2022-01-12 23:13:09:INFO:-------------Training local models-------------
2022-01-12 23:17:57:INFO:-------------updating local masks-------------
2022-01-12 23:18:00:INFO:-------------Aggregating local models-------------
2022-01-12 23:18:01:INFO:-------------Round number: 43-------------
2022-01-12 23:18:01:INFO:-------------Sending models-------------
2022-01-12 23:18:01:INFO:-------------Evaluating models-------------
2022-01-12 23:18:02:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 23:18:02:INFO:Accuracy = [1.0, 1.0, 0.9904040404040404, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9904040404040404, 0.9904040404040404]
2022-01-12 23:18:02:INFO:Loss = [0.0005212771996439462, 0.0006155116027351904, 0.02431841317206404, 0.02468353136928731, 0.003789136492969651, 0.0037375160093734397, 0.0035798476857429834, 0.0035753800391637816, 0.027400463885994278, 0.027358177072603965]
2022-01-12 23:18:02:INFO:-------------Training local models-------------
2022-01-12 23:22:51:INFO:-------------updating local masks-------------
2022-01-12 23:22:53:INFO:-------------Aggregating local models-------------
2022-01-12 23:22:55:INFO:-------------Round number: 44-------------
2022-01-12 23:22:55:INFO:-------------Sending models-------------
2022-01-12 23:22:55:INFO:-------------Evaluating models-------------
2022-01-12 23:22:55:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 23:22:55:INFO:Accuracy = [1.0, 1.0, 0.9904040404040404, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9904040404040404, 0.9904040404040404]
2022-01-12 23:22:55:INFO:Loss = [0.0005118729290831716, 0.0006036978681007931, 0.024194714900914557, 0.02454891015430059, 0.0037564469393578065, 0.003704186446792837, 0.003543964963818776, 0.003540212575757727, 0.027385235528200987, 0.027338323560052048]
2022-01-12 23:22:55:INFO:-------------Training local models-------------
2022-01-12 23:27:44:INFO:-------------updating local masks-------------
2022-01-12 23:27:47:INFO:-------------Aggregating local models-------------
2022-01-12 23:27:48:INFO:-------------Round number: 45-------------
2022-01-12 23:27:48:INFO:-------------Sending models-------------
2022-01-12 23:27:48:INFO:-------------Evaluating models-------------
2022-01-12 23:27:49:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 23:27:49:INFO:Accuracy = [1.0, 1.0, 0.9904040404040404, 0.98989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9904040404040404, 0.9904040404040404]
2022-01-12 23:27:49:INFO:Loss = [0.0005029097595465231, 0.0005924704885039705, 0.024070263079646784, 0.024413573547886386, 0.003724607558466563, 0.0036716985280525645, 0.0035099684820832206, 0.003506920668378095, 0.02737553358412256, 0.027325038662341036]
2022-01-12 23:27:49:INFO:-------------Training local models-------------
2022-01-12 23:32:39:INFO:-------------updating local masks-------------
2022-01-12 23:32:41:INFO:-------------Aggregating local models-------------
2022-01-12 23:32:43:INFO:-------------Round number: 46-------------
2022-01-12 23:32:43:INFO:-------------Sending models-------------
2022-01-12 23:32:44:INFO:-------------Evaluating models-------------
2022-01-12 23:32:44:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 23:32:44:INFO:Accuracy = [1.0, 1.0, 0.9904040404040404, 0.98989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9904040404040404, 0.9904040404040404]
2022-01-12 23:32:44:INFO:Loss = [0.0004943613578110341, 0.0005818085094256505, 0.023950870468680212, 0.024284201375690147, 0.0036951248011532836, 0.0036415346467754605, 0.003477693426218754, 0.0034753726201893417, 0.02737423667986701, 0.02731997823765311]
2022-01-12 23:32:44:INFO:-------------Training local models-------------
2022-01-12 23:37:32:INFO:-------------updating local masks-------------
2022-01-12 23:37:35:INFO:-------------Aggregating local models-------------
2022-01-12 23:37:37:INFO:-------------Round number: 47-------------
2022-01-12 23:37:37:INFO:-------------Sending models-------------
2022-01-12 23:37:37:INFO:-------------Evaluating models-------------
2022-01-12 23:37:37:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 23:37:37:INFO:Accuracy = [1.0, 1.0, 0.9904040404040404, 0.9904040404040404, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9904040404040404, 0.9904040404040404]
2022-01-12 23:37:37:INFO:Loss = [0.00048620396744147664, 0.0005716642831255814, 0.023845449813087165, 0.02417011427075678, 0.0036669619843671558, 0.0036125874946127154, 0.0034467802444483786, 0.003445211792607763, 0.02735326825668748, 0.027296588685618704]
2022-01-12 23:37:37:INFO:-------------Training local models-------------
2022-01-12 23:42:28:INFO:-------------updating local masks-------------
2022-01-12 23:42:31:INFO:-------------Aggregating local models-------------
2022-01-12 23:42:33:INFO:-------------Round number: 48-------------
2022-01-12 23:42:33:INFO:-------------Sending models-------------
2022-01-12 23:42:33:INFO:-------------Evaluating models-------------
2022-01-12 23:42:33:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 23:42:33:INFO:Accuracy = [1.0, 1.0, 0.9904040404040404, 0.9904040404040404, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9904040404040404, 0.9904040404040404]
2022-01-12 23:42:33:INFO:Loss = [0.0004784011010427764, 0.00056198182549387, 0.02375156776191888, 0.024068961135473195, 0.0036386301353246897, 0.003583310926643033, 0.003417355435084748, 0.003416512074824887, 0.027345081131931116, 0.027286599511832967]
2022-01-12 23:42:33:INFO:-------------Training local models-------------
2022-01-12 23:47:21:INFO:-------------updating local masks-------------
2022-01-12 23:47:24:INFO:-------------Aggregating local models-------------
2022-01-12 23:47:26:INFO:-------------Round number: 49-------------
2022-01-12 23:47:26:INFO:-------------Sending models-------------
2022-01-12 23:47:26:INFO:-------------Evaluating models-------------
2022-01-12 23:47:26:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 23:47:26:INFO:Accuracy = [1.0, 1.0, 0.9904040404040404, 0.9904040404040404, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9904040404040404, 0.9904040404040404]
2022-01-12 23:47:26:INFO:Loss = [0.0004709331751288082, 0.0005527405872418618, 0.023651872981070188, 0.023962083578618433, 0.0036112535273474865, 0.0035549921912803773, 0.0033894488209350103, 0.0033893281608130803, 0.027338847434009838, 0.02727860220185003]
2022-01-12 23:47:26:INFO:-------------Training local models-------------
2022-01-12 23:52:14:INFO:-------------updating local masks-------------
2022-01-12 23:52:17:INFO:-------------Aggregating local models-------------
2022-01-12 23:52:19:INFO:-------------Round number: 50-------------
2022-01-12 23:52:19:INFO:-------------Sending models-------------
2022-01-12 23:52:19:INFO:-------------Evaluating models-------------
2022-01-12 23:52:19:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 23:52:19:INFO:Accuracy = [1.0, 1.0, 0.9904040404040404, 0.9904040404040404, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9904040404040404, 0.9904040404040404]
2022-01-12 23:52:19:INFO:Loss = [0.0004637500504950459, 0.0005438339152404829, 0.023558862558886836, 0.023864709683440573, 0.003585394277951024, 0.003528141083477914, 0.0033627756791302643, 0.0033633317027299127, 0.027325417576831212, 0.02726394848044892]
2022-01-12 23:52:19:INFO:-------------Training local models-------------
2022-01-12 23:57:08:INFO:-------------updating local masks-------------
2022-01-12 23:57:11:INFO:-------------Aggregating local models-------------
2022-01-12 23:57:12:INFO:-------------Round number: 51-------------
2022-01-12 23:57:12:INFO:-------------Sending models-------------
2022-01-12 23:57:12:INFO:-------------Evaluating models-------------
2022-01-12 23:57:12:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 23:57:12:INFO:Accuracy = [1.0, 1.0, 0.9904040404040404, 0.9904040404040404, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9904040404040404, 0.9904040404040404]
2022-01-12 23:57:12:INFO:Loss = [0.00045683043844282927, 0.0005352450228817149, 0.02347039941359246, 0.02377234234061395, 0.0035596533985385163, 0.003501489749889901, 0.0033371936630360185, 0.003338402502643044, 0.027321043863642012, 0.02725842361991031]
2022-01-12 23:57:12:INFO:-------------Training local models-------------
