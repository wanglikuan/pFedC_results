2022-01-06 12:05:21:INFO:-------------Round number: 0-------------
2022-01-06 12:05:21:INFO:-------------Sending models-------------
2022-01-06 12:05:21:INFO:-------------Evaluating models-------------
2022-01-06 12:05:21:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 12:05:21:INFO:Accuracy = [0.901010101010101, 0.8868686868686869, 0.896969696969697, 0.898989898989899, 0.901010101010101, 0.08888888888888889, 0.09494949494949495, 0.10303030303030303, 0.09696969696969697, 0.898989898989899]
2022-01-06 12:05:21:INFO:Loss = [0.6694116484637213, 0.653408883798002, 0.6615643211988488, 0.6542965058425461, 0.6641762230733428, 0.7379018910304465, 0.7407228308795678, 0.7419946313205391, 0.7473327146335081, 0.669854687109138]
2022-01-06 12:05:21:INFO:-------------Training local models-------------
2022-01-06 12:10:09:INFO:-------------Aggregating local models-------------
2022-01-06 12:10:09:INFO:-------------Round number: 1-------------
2022-01-06 12:10:09:INFO:-------------Sending models-------------
2022-01-06 12:10:09:INFO:-------------Evaluating models-------------
2022-01-06 12:10:09:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 12:10:09:INFO:Accuracy = [0.9707070707070707, 0.9535353535353536, 0.897979797979798, 0.897979797979798, 0.9616161616161616, 0.9570707070707071, 0.9252525252525252, 0.9262626262626262, 0.9217171717171717, 0.9065656565656566]
2022-01-06 12:10:09:INFO:Loss = [0.07262695909564788, 0.0947774959925675, 0.19510987750254571, 0.19190025064891975, 0.14834377042880997, 0.15541895831102562, 0.15501993254480903, 0.1475990754305244, 0.18349695685989872, 0.21461993462307322]
2022-01-06 12:10:09:INFO:-------------Training local models-------------
2022-01-06 12:14:58:INFO:-------------Aggregating local models-------------
2022-01-06 12:14:59:INFO:-------------Round number: 2-------------
2022-01-06 12:14:59:INFO:-------------Sending models-------------
2022-01-06 12:14:59:INFO:-------------Evaluating models-------------
2022-01-06 12:14:59:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 12:14:59:INFO:Accuracy = [0.9974747474747475, 0.9954545454545455, 0.9171717171717172, 0.9207070707070707, 0.9747474747474747, 0.9767676767676767, 0.9611111111111111, 0.9671717171717171, 0.943939393939394, 0.9424242424242424]
2022-01-06 12:14:59:INFO:Loss = [0.025935592332965402, 0.035545190024152025, 0.13938061678241187, 0.13828247917308636, 0.07841664183928368, 0.08415818807993536, 0.07464246354036437, 0.06796365636853605, 0.12763768038283235, 0.1484013867767932]
2022-01-06 12:14:59:INFO:-------------Training local models-------------
2022-01-06 12:19:47:INFO:-------------Aggregating local models-------------
2022-01-06 12:19:47:INFO:-------------Round number: 3-------------
2022-01-06 12:19:47:INFO:-------------Sending models-------------
2022-01-06 12:19:47:INFO:-------------Evaluating models-------------
2022-01-06 12:19:48:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 12:19:48:INFO:Accuracy = [1.0, 0.9984848484848485, 0.9368686868686869, 0.9388888888888889, 0.9883838383838384, 0.9868686868686869, 0.9843434343434343, 0.9888888888888889, 0.953030303030303, 0.95]
2022-01-06 12:19:48:INFO:Loss = [0.013332401675694255, 0.018157278742544785, 0.10806687498245285, 0.10755077116358955, 0.045361423874955925, 0.04854134901099241, 0.04457742314914481, 0.040435569804053606, 0.09878010891352644, 0.11356979507524896]
2022-01-06 12:19:48:INFO:-------------Training local models-------------
2022-01-06 12:24:35:INFO:-------------Aggregating local models-------------
2022-01-06 12:24:36:INFO:-------------Round number: 4-------------
2022-01-06 12:24:36:INFO:-------------Sending models-------------
2022-01-06 12:24:36:INFO:-------------Evaluating models-------------
2022-01-06 12:24:36:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 12:24:36:INFO:Accuracy = [1.0, 1.0, 0.9505050505050505, 0.951010101010101, 0.9944444444444445, 0.9944444444444445, 0.9939393939393939, 0.9934343434343434, 0.9585858585858585, 0.9575757575757575]
2022-01-06 12:24:36:INFO:Loss = [0.00855790101070512, 0.011524358626326893, 0.08748031729794663, 0.08734946799613864, 0.030648062452897334, 0.03229280166631339, 0.029960420343823815, 0.027190630042877265, 0.08180001705029163, 0.09434188364586332]
2022-01-06 12:24:36:INFO:-------------Training local models-------------
2022-01-06 12:29:24:INFO:-------------Aggregating local models-------------
2022-01-06 12:29:25:INFO:-------------Round number: 5-------------
2022-01-06 12:29:25:INFO:-------------Sending models-------------
2022-01-06 12:29:25:INFO:-------------Evaluating models-------------
2022-01-06 12:29:25:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 12:29:25:INFO:Accuracy = [1.0, 1.0, 0.9656565656565657, 0.9656565656565657, 0.9959595959595959, 0.9949494949494949, 0.9954545454545455, 0.9964646464646465, 0.9651515151515152, 0.9611111111111111]
2022-01-06 12:29:25:INFO:Loss = [0.006176199465743125, 0.008251970598322451, 0.07310536169097759, 0.07348233718841603, 0.022927072946016907, 0.023815978039996792, 0.021879084320016312, 0.02009091115657492, 0.0697385333394373, 0.08076121799493176]
2022-01-06 12:29:25:INFO:-------------Training local models-------------
2022-01-06 12:34:13:INFO:-------------Aggregating local models-------------
2022-01-06 12:34:13:INFO:-------------Round number: 6-------------
2022-01-06 12:34:13:INFO:-------------Sending models-------------
2022-01-06 12:34:13:INFO:-------------Evaluating models-------------
2022-01-06 12:34:14:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 12:34:14:INFO:Accuracy = [1.0, 1.0, 0.9702020202020202, 0.9696969696969697, 0.9959595959595959, 0.9959595959595959, 0.9974747474747475, 0.997979797979798, 0.9707070707070707, 0.9636363636363636]
2022-01-06 12:34:14:INFO:Loss = [0.004774192101092811, 0.006341993542460988, 0.06303187637809474, 0.06383589229354225, 0.018276675640928178, 0.01877422235721506, 0.01722856238773951, 0.016018588356470874, 0.060687617093311136, 0.07033391817269442]
2022-01-06 12:34:14:INFO:-------------Training local models-------------
2022-01-06 12:39:02:INFO:-------------Aggregating local models-------------
2022-01-06 12:39:02:INFO:-------------Round number: 7-------------
2022-01-06 12:39:02:INFO:-------------Sending models-------------
2022-01-06 12:39:02:INFO:-------------Evaluating models-------------
2022-01-06 12:39:02:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 12:39:02:INFO:Accuracy = [1.0, 1.0, 0.9737373737373738, 0.9722222222222222, 0.996969696969697, 0.9974747474747475, 0.996969696969697, 0.9974747474747475, 0.9752525252525253, 0.9707070707070707]
2022-01-06 12:39:02:INFO:Loss = [0.0038581903337740874, 0.005099856949704135, 0.05600035701330982, 0.05707456982458502, 0.015218411169262988, 0.015500270075919084, 0.014311297594101022, 0.013440139542334958, 0.0537059625365017, 0.06177359234805941]
2022-01-06 12:39:02:INFO:-------------Training local models-------------
2022-01-06 12:43:50:INFO:-------------Aggregating local models-------------
2022-01-06 12:43:50:INFO:-------------Round number: 8-------------
2022-01-06 12:43:50:INFO:-------------Sending models-------------
2022-01-06 12:43:50:INFO:-------------Evaluating models-------------
2022-01-06 12:43:51:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 12:43:51:INFO:Accuracy = [1.0, 1.0, 0.9767676767676767, 0.9767676767676767, 0.997979797979798, 0.997979797979798, 0.9974747474747475, 0.9974747474747475, 0.9813131313131314, 0.9752525252525253]
2022-01-06 12:43:51:INFO:Loss = [0.00321841419260241, 0.004234226901411088, 0.05100710030422884, 0.05223203794461131, 0.013081829798319072, 0.013237356987924108, 0.012322142336154803, 0.011662953031374873, 0.04847286465923793, 0.05483969091230503]
2022-01-06 12:43:51:INFO:-------------Training local models-------------
2022-01-06 12:48:38:INFO:-------------Aggregating local models-------------
2022-01-06 12:48:38:INFO:-------------Round number: 9-------------
2022-01-06 12:48:38:INFO:-------------Sending models-------------
2022-01-06 12:48:38:INFO:-------------Evaluating models-------------
2022-01-06 12:48:38:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 12:48:38:INFO:Accuracy = [1.0, 1.0, 0.9777777777777777, 0.9782828282828283, 0.9984848484848485, 0.997979797979798, 0.9974747474747475, 0.9974747474747475, 0.9818181818181818, 0.9777777777777777]
2022-01-06 12:48:38:INFO:Loss = [0.0027510535694403584, 0.003602284786227921, 0.04728883110237252, 0.048578568334969624, 0.011517847128613144, 0.011594523254645555, 0.010886274559221658, 0.010369144754142988, 0.04459164624014661, 0.049426309428324176]
2022-01-06 12:48:38:INFO:-------------Training local models-------------
2022-01-06 12:53:26:INFO:-------------Aggregating local models-------------
2022-01-06 12:53:26:INFO:-------------Round number: 10-------------
2022-01-06 12:53:26:INFO:-------------Sending models-------------
2022-01-06 12:53:26:INFO:-------------Evaluating models-------------
2022-01-06 12:53:26:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 12:53:26:INFO:Accuracy = [1.0, 1.0, 0.9823232323232324, 0.9803030303030303, 0.998989898989899, 0.9984848484848485, 0.9974747474747475, 0.9974747474747475, 0.9838383838383838, 0.9808080808080808]
2022-01-06 12:53:26:INFO:Loss = [0.002396547479432716, 0.003123279600704061, 0.04438196092254142, 0.04570092853587773, 0.01033434086421039, 0.010363219590384908, 0.009800865211758663, 0.009384353839002392, 0.041672405994155046, 0.04529280036986533]
2022-01-06 12:53:26:INFO:-------------Training local models-------------
2022-01-06 12:58:13:INFO:-------------Aggregating local models-------------
2022-01-06 12:58:13:INFO:-------------Round number: 11-------------
2022-01-06 12:58:13:INFO:-------------Sending models-------------
2022-01-06 12:58:13:INFO:-------------Evaluating models-------------
2022-01-06 12:58:13:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 12:58:13:INFO:Accuracy = [1.0, 1.0, 0.9828282828282828, 0.9803030303030303, 0.9994949494949495, 0.9984848484848485, 0.9974747474747475, 0.9974747474747475, 0.9843434343434343, 0.9833333333333333]
2022-01-06 12:58:13:INFO:Loss = [0.0021197401353885946, 0.0027491985844487012, 0.04202463775700472, 0.04333647186401202, 0.009405456392914398, 0.009403917916834053, 0.008953700076087232, 0.0086117288127578, 0.03936051001098781, 0.042084794887606136]
2022-01-06 12:58:13:INFO:-------------Training local models-------------
2022-01-06 13:02:57:INFO:-------------Aggregating local models-------------
2022-01-06 13:02:57:INFO:-------------Round number: 12-------------
2022-01-06 13:02:57:INFO:-------------Sending models-------------
2022-01-06 13:02:57:INFO:-------------Evaluating models-------------
2022-01-06 13:02:58:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 13:02:58:INFO:Accuracy = [1.0, 1.0, 0.9833333333333333, 0.9818181818181818, 0.9994949494949495, 0.9984848484848485, 0.9974747474747475, 0.9974747474747475, 0.9853535353535353, 0.9838383838383838]
2022-01-06 13:02:58:INFO:Loss = [0.001898713743433502, 0.0024504701106872577, 0.040049792662532786, 0.04133766046425356, 0.008653506934073945, 0.008631792191943422, 0.008272493189570289, 0.007987565565770528, 0.03749000915163608, 0.039565080834070225]
2022-01-06 13:02:58:INFO:-------------Training local models-------------
2022-01-06 13:07:41:INFO:-------------Aggregating local models-------------
2022-01-06 13:07:42:INFO:-------------Round number: 13-------------
2022-01-06 13:07:42:INFO:-------------Sending models-------------
2022-01-06 13:07:42:INFO:-------------Evaluating models-------------
2022-01-06 13:07:42:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 13:07:42:INFO:Accuracy = [1.0, 1.0, 0.9838383838383838, 0.9823232323232324, 0.9994949494949495, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9858585858585859, 0.9863636363636363]
2022-01-06 13:07:42:INFO:Loss = [0.0017207009241430587, 0.0022101355780011884, 0.03836994198891169, 0.0396275663047944, 0.008037960817381819, 0.00800227452067463, 0.007716800559894476, 0.007476793191315003, 0.03594347480726778, 0.03755109816861064]
2022-01-06 13:07:42:INFO:-------------Training local models-------------
2022-01-06 13:12:26:INFO:-------------Aggregating local models-------------
2022-01-06 13:12:26:INFO:-------------Round number: 14-------------
2022-01-06 13:12:26:INFO:-------------Sending models-------------
2022-01-06 13:12:26:INFO:-------------Evaluating models-------------
2022-01-06 13:12:26:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 13:12:26:INFO:Accuracy = [1.0, 1.0, 0.9848484848484849, 0.9833333333333333, 0.9994949494949495, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9863636363636363, 0.9868686868686869]
2022-01-06 13:12:26:INFO:Loss = [0.0015738687766618871, 0.0020120072798395405, 0.03690289717695747, 0.038106093674650766, 0.00752530410937845, 0.007479239437911974, 0.0072523513016428546, 0.007048640473878935, 0.0346271637155859, 0.035896651714324664]
2022-01-06 13:12:26:INFO:-------------Training local models-------------
2022-01-06 13:17:10:INFO:-------------Aggregating local models-------------
2022-01-06 13:17:11:INFO:-------------Round number: 15-------------
2022-01-06 13:17:11:INFO:-------------Sending models-------------
2022-01-06 13:17:11:INFO:-------------Evaluating models-------------
2022-01-06 13:17:11:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 13:17:11:INFO:Accuracy = [1.0, 1.0, 0.9848484848484849, 0.9843434343434343, 0.9994949494949495, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9868686868686869, 0.9863636363636363]
2022-01-06 13:17:11:INFO:Loss = [0.0014513639072553052, 0.0018468368258309606, 0.035618366092335284, 0.036769016899364425, 0.007088189037177022, 0.007036103809389375, 0.006858612295826503, 0.006684596659073981, 0.033502809009389074, 0.03452828573259981]
2022-01-06 13:17:11:INFO:-------------Training local models-------------
2022-01-06 13:21:54:INFO:-------------Aggregating local models-------------
2022-01-06 13:21:55:INFO:-------------Round number: 16-------------
2022-01-06 13:21:55:INFO:-------------Sending models-------------
2022-01-06 13:21:55:INFO:-------------Evaluating models-------------
2022-01-06 13:21:55:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 13:21:55:INFO:Accuracy = [1.0, 1.0, 0.9848484848484849, 0.9848484848484849, 0.9994949494949495, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9873737373737373, 0.9863636363636363]
2022-01-06 13:21:55:INFO:Loss = [0.0013474473225263258, 0.0017067886838049162, 0.034490061210858076, 0.035590131167478056, 0.006718026954901018, 0.006662305785556038, 0.006520596990230843, 0.006370996189589002, 0.03256365119903586, 0.03340916729054762]
2022-01-06 13:21:55:INFO:-------------Training local models-------------
2022-01-06 13:26:39:INFO:-------------Aggregating local models-------------
2022-01-06 13:26:40:INFO:-------------Round number: 17-------------
2022-01-06 13:26:40:INFO:-------------Sending models-------------
2022-01-06 13:26:40:INFO:-------------Evaluating models-------------
2022-01-06 13:26:40:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 13:26:40:INFO:Accuracy = [1.0, 1.0, 0.9863636363636363, 0.9858585858585859, 0.998989898989899, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9873737373737373, 0.9863636363636363]
2022-01-06 13:26:40:INFO:Loss = [0.0012582039517865544, 0.0015866921026882305, 0.03348173768559222, 0.034534284193616274, 0.006396760119373952, 0.00633956865649544, 0.00622676674436, 0.006097365428818974, 0.031780898511752094, 0.032488069658531016]
2022-01-06 13:26:40:INFO:-------------Training local models-------------
2022-01-06 13:31:24:INFO:-------------Aggregating local models-------------
2022-01-06 13:31:24:INFO:-------------Round number: 18-------------
2022-01-06 13:31:24:INFO:-------------Sending models-------------
2022-01-06 13:31:24:INFO:-------------Evaluating models-------------
2022-01-06 13:31:24:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 13:31:24:INFO:Accuracy = [1.0, 1.0, 0.9868686868686869, 0.9863636363636363, 0.998989898989899, 0.998989898989899, 0.997979797979798, 0.9974747474747475, 0.9873737373737373, 0.9873737373737373]
2022-01-06 13:31:24:INFO:Loss = [0.0011810712722680446, 0.0014831113921698286, 0.032594677765405096, 0.033606399064702794, 0.006119456806239517, 0.0060619199325638055, 0.005969471785099795, 0.005857064492646705, 0.03113522473812727, 0.03172943235161559]
2022-01-06 13:31:24:INFO:-------------Training local models-------------
2022-01-06 13:36:08:INFO:-------------Aggregating local models-------------
2022-01-06 13:36:08:INFO:-------------Round number: 19-------------
2022-01-06 13:36:08:INFO:-------------Sending models-------------
2022-01-06 13:36:08:INFO:-------------Evaluating models-------------
2022-01-06 13:36:08:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 13:36:08:INFO:Accuracy = [1.0, 1.0, 0.9873737373737373, 0.9868686868686869, 0.998989898989899, 0.998989898989899, 0.997979797979798, 0.9974747474747475, 0.9878787878787879, 0.9873737373737373]
2022-01-06 13:36:08:INFO:Loss = [0.0011136417513589183, 0.0013927518913106089, 0.031802228423453704, 0.032769322705449536, 0.005876206759542886, 0.005819155290270709, 0.0057415433994196284, 0.00564350258572438, 0.0305527893759265, 0.031062674084045505]
2022-01-06 13:36:08:INFO:-------------Training local models-------------
2022-01-06 13:40:52:INFO:-------------Aggregating local models-------------
2022-01-06 13:40:52:INFO:-------------Round number: 20-------------
2022-01-06 13:40:52:INFO:-------------Sending models-------------
2022-01-06 13:40:53:INFO:-------------Evaluating models-------------
2022-01-06 13:40:53:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 13:40:53:INFO:Accuracy = [1.0, 1.0, 0.9873737373737373, 0.9868686868686869, 0.998989898989899, 0.998989898989899, 0.997979797979798, 0.9974747474747475, 0.9873737373737373, 0.9878787878787879]
2022-01-06 13:40:53:INFO:Loss = [0.00105441507077576, 0.0013135256350094529, 0.031104669009650338, 0.03203159976887165, 0.0056617469526790585, 0.0056051438275990404, 0.005538621873167377, 0.005452773555773111, 0.03006031510976938, 0.03050291268454469]
2022-01-06 13:40:53:INFO:-------------Training local models-------------
2022-01-06 13:45:37:INFO:-------------Aggregating local models-------------
2022-01-06 13:45:37:INFO:-------------Round number: 21-------------
2022-01-06 13:45:37:INFO:-------------Sending models-------------
2022-01-06 13:45:37:INFO:-------------Evaluating models-------------
2022-01-06 13:45:37:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 13:45:37:INFO:Accuracy = [1.0, 1.0, 0.9873737373737373, 0.9868686868686869, 0.998989898989899, 0.998989898989899, 0.997979797979798, 0.9974747474747475, 0.9873737373737373, 0.9873737373737373]
2022-01-06 13:45:37:INFO:Loss = [0.0010019184535059425, 0.0012434194484391048, 0.030474093942231977, 0.031360680218507825, 0.005470149695541506, 0.005413217309857525, 0.005356495162402897, 0.005281109390029951, 0.029634213339032253, 0.03002617422209387]
2022-01-06 13:45:37:INFO:-------------Training local models-------------
2022-01-06 13:50:21:INFO:-------------Aggregating local models-------------
2022-01-06 13:50:22:INFO:-------------Round number: 22-------------
2022-01-06 13:50:22:INFO:-------------Sending models-------------
2022-01-06 13:50:22:INFO:-------------Evaluating models-------------
2022-01-06 13:50:22:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 13:50:22:INFO:Accuracy = [1.0, 1.0, 0.9873737373737373, 0.9868686868686869, 0.998989898989899, 0.998989898989899, 0.997979797979798, 0.9974747474747475, 0.9873737373737373, 0.9873737373737373]
2022-01-06 13:50:22:INFO:Loss = [0.0009549490949377122, 0.001180823992792578, 0.029901099694174576, 0.030750918960905555, 0.005298325015555196, 0.005241551163275326, 0.005192127267623113, 0.005125725190285294, 0.029284886352101552, 0.029634267902891757]
2022-01-06 13:50:22:INFO:-------------Training local models-------------
2022-01-06 13:55:06:INFO:-------------Aggregating local models-------------
2022-01-06 13:55:06:INFO:-------------Round number: 23-------------
2022-01-06 13:55:06:INFO:-------------Sending models-------------
2022-01-06 13:55:06:INFO:-------------Evaluating models-------------
2022-01-06 13:55:06:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 13:55:06:INFO:Accuracy = [1.0, 1.0, 0.9873737373737373, 0.9873737373737373, 0.998989898989899, 0.998989898989899, 0.997979797979798, 0.997979797979798, 0.9883838383838384, 0.9878787878787879]
2022-01-06 13:55:06:INFO:Loss = [0.0009127288386066952, 0.0011247047871004935, 0.02936896638656426, 0.03018212640954608, 0.005144202365927137, 0.005088357556532072, 0.005043178828069505, 0.004984620154814044, 0.02898737830903635, 0.029299249086930886]
2022-01-06 13:55:06:INFO:-------------Training local models-------------
2022-01-06 13:59:50:INFO:-------------Aggregating local models-------------
2022-01-06 13:59:51:INFO:-------------Round number: 24-------------
2022-01-06 13:59:51:INFO:-------------Sending models-------------
2022-01-06 13:59:51:INFO:-------------Evaluating models-------------
2022-01-06 13:59:51:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 13:59:51:INFO:Accuracy = [1.0, 1.0, 0.9873737373737373, 0.9873737373737373, 0.998989898989899, 0.998989898989899, 0.997979797979798, 0.9984848484848485, 0.9878787878787879, 0.9883838383838384]
2022-01-06 13:59:51:INFO:Loss = [0.0008746969563718368, 0.0010742562898990904, 0.028890804383465567, 0.029670314171342013, 0.00500869133737602, 0.004954587874584317, 0.004906683936544619, 0.004854938957032573, 0.028727066622344533, 0.029002613047946442]
2022-01-06 13:59:51:INFO:-------------Training local models-------------
2022-01-06 14:04:34:INFO:-------------Aggregating local models-------------
2022-01-06 14:04:35:INFO:-------------Round number: 25-------------
2022-01-06 14:04:35:INFO:-------------Sending models-------------
2022-01-06 14:04:35:INFO:-------------Evaluating models-------------
2022-01-06 14:04:35:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 14:04:35:INFO:Accuracy = [1.0, 1.0, 0.9883838383838384, 0.9873737373737373, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.9878787878787879, 0.9883838383838384]
2022-01-06 14:04:35:INFO:Loss = [0.0008403743174505618, 0.001028811563020384, 0.02845920595844456, 0.02920678411840095, 0.004884964133096292, 0.004832269156726066, 0.004781700794715429, 0.004736069577458436, 0.028527604515855072, 0.028769355119385925]
2022-01-06 14:04:35:INFO:-------------Training local models-------------
2022-01-06 14:09:19:INFO:-------------Aggregating local models-------------
2022-01-06 14:09:19:INFO:-------------Round number: 26-------------
2022-01-06 14:09:19:INFO:-------------Sending models-------------
2022-01-06 14:09:20:INFO:-------------Evaluating models-------------
2022-01-06 14:09:20:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 14:09:20:INFO:Accuracy = [1.0, 1.0, 0.9883838383838384, 0.9873737373737373, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.9878787878787879, 0.9883838383838384]
2022-01-06 14:09:20:INFO:Loss = [0.000809181912343848, 0.0009876217399406332, 0.028050485575254747, 0.028758333445407378, 0.0047744996648977365, 0.00472350293777635, 0.004667030682009286, 0.004626855078705109, 0.028359829719665133, 0.02857250769186728]
2022-01-06 14:09:20:INFO:-------------Training local models-------------
2022-01-06 14:14:04:INFO:-------------Aggregating local models-------------
2022-01-06 14:14:04:INFO:-------------Round number: 27-------------
2022-01-06 14:14:04:INFO:-------------Sending models-------------
2022-01-06 14:14:04:INFO:-------------Evaluating models-------------
2022-01-06 14:14:04:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 14:14:04:INFO:Accuracy = [1.0, 1.0, 0.9883838383838384, 0.9873737373737373, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.9878787878787879, 0.9893939393939394]
2022-01-06 14:14:04:INFO:Loss = [0.0007808481243358469, 0.0009503273144696552, 0.027674676063671917, 0.028348045453370132, 0.004673653316192463, 0.0046241385898813155, 0.0045621346730246905, 0.00452663683297005, 0.0282110479753707, 0.02839611889271923]
2022-01-06 14:14:04:INFO:-------------Training local models-------------
2022-01-06 14:18:48:INFO:-------------Aggregating local models-------------
2022-01-06 14:18:49:INFO:-------------Round number: 28-------------
2022-01-06 14:18:49:INFO:-------------Sending models-------------
2022-01-06 14:18:49:INFO:-------------Evaluating models-------------
2022-01-06 14:18:49:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 14:18:49:INFO:Accuracy = [1.0, 1.0, 0.9883838383838384, 0.9878787878787879, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.9878787878787879, 0.9893939393939394]
2022-01-06 14:18:49:INFO:Loss = [0.0007548814809441947, 0.0009162295027672738, 0.02734359073487157, 0.027982224601081993, 0.0045820741449525216, 0.004533984135653582, 0.004465277602091623, 0.004433835631969469, 0.028084463108438047, 0.028244922043269997]
2022-01-06 14:18:49:INFO:-------------Training local models-------------
2022-01-06 14:23:32:INFO:-------------Aggregating local models-------------
2022-01-06 14:23:33:INFO:-------------Round number: 29-------------
2022-01-06 14:23:33:INFO:-------------Sending models-------------
2022-01-06 14:23:33:INFO:-------------Evaluating models-------------
2022-01-06 14:23:33:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 14:23:33:INFO:Accuracy = [1.0, 1.0, 0.9883838383838384, 0.9878787878787879, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.9883838383838384, 0.9893939393939394]
2022-01-06 14:23:33:INFO:Loss = [0.0007308756504437152, 0.0008847904927692567, 0.027033932461168347, 0.027642292830604112, 0.0044959554062252854, 0.004449092186881201, 0.0043753487167950056, 0.004347545024768007, 0.027969891152484577, 0.02810668730722829]
2022-01-06 14:23:33:INFO:-------------Training local models-------------
2022-01-06 14:28:17:INFO:-------------Aggregating local models-------------
2022-01-06 14:28:17:INFO:-------------Round number: 30-------------
2022-01-06 14:28:17:INFO:-------------Sending models-------------
2022-01-06 14:28:18:INFO:-------------Evaluating models-------------
2022-01-06 14:28:18:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 14:28:18:INFO:Accuracy = [1.0, 1.0, 0.9883838383838384, 0.9878787878787879, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.9883838383838384, 0.9888888888888889]
2022-01-06 14:28:18:INFO:Loss = [0.0007086186474565455, 0.000855725528813447, 0.026750768347881954, 0.02733155364145903, 0.004417233989505518, 0.004371075971058151, 0.00429154517746932, 0.004266859981781277, 0.027870466153112693, 0.027984473942823836]
2022-01-06 14:28:18:INFO:-------------Training local models-------------
2022-01-06 14:33:02:INFO:-------------Aggregating local models-------------
2022-01-06 14:33:02:INFO:-------------Round number: 31-------------
2022-01-06 14:33:02:INFO:-------------Sending models-------------
2022-01-06 14:33:02:INFO:-------------Evaluating models-------------
2022-01-06 14:33:02:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 14:33:02:INFO:Accuracy = [1.0, 1.0, 0.9888888888888889, 0.9883838383838384, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.9888888888888889, 0.9888888888888889]
2022-01-06 14:33:02:INFO:Loss = [0.0006879651031009747, 0.0008288547139980235, 0.026473394735108336, 0.02702826759832349, 0.0043446461567079745, 0.004298545690534126, 0.004213710289096902, 0.0041916776850962605, 0.02780007952791346, 0.02789361504032738]
2022-01-06 14:33:02:INFO:-------------Training local models-------------
2022-01-06 14:37:46:INFO:-------------Aggregating local models-------------
2022-01-06 14:37:47:INFO:-------------Round number: 32-------------
2022-01-06 14:37:47:INFO:-------------Sending models-------------
2022-01-06 14:37:47:INFO:-------------Evaluating models-------------
2022-01-06 14:37:47:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 14:37:47:INFO:Accuracy = [1.0, 1.0, 0.9888888888888889, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.9888888888888889, 0.9888888888888889]
2022-01-06 14:37:47:INFO:Loss = [0.0006687114449978437, 0.0008039051974283395, 0.026218574043001226, 0.026750241075049672, 0.004279134719611032, 0.004233101048251256, 0.004141380928692774, 0.00412172045857777, 0.027740029850103768, 0.027814089195806337]
2022-01-06 14:37:47:INFO:-------------Training local models-------------
2022-01-06 14:42:31:INFO:-------------Aggregating local models-------------
2022-01-06 14:42:31:INFO:-------------Round number: 33-------------
2022-01-06 14:42:31:INFO:-------------Sending models-------------
2022-01-06 14:42:31:INFO:-------------Evaluating models-------------
2022-01-06 14:42:31:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 14:42:31:INFO:Accuracy = [1.0, 1.0, 0.9893939393939394, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.9984848484848485, 0.9984848484848485, 0.9888888888888889, 0.9883838383838384]
2022-01-06 14:42:31:INFO:Loss = [0.0006507044192109577, 0.0007806273054199545, 0.025980379267393158, 0.026490724294886935, 0.004221071640471325, 0.004174435353420311, 0.004073920163781705, 0.004056370825984608, 0.027695593267956363, 0.027754355318703725]
2022-01-06 14:42:31:INFO:-------------Training local models-------------
2022-01-06 14:47:15:INFO:-------------Aggregating local models-------------
2022-01-06 14:47:16:INFO:-------------Round number: 34-------------
2022-01-06 14:47:16:INFO:-------------Sending models-------------
2022-01-06 14:47:16:INFO:-------------Evaluating models-------------
2022-01-06 14:47:16:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 14:47:16:INFO:Accuracy = [1.0, 1.0, 0.98989898989899, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9888888888888889, 0.9883838383838384]
2022-01-06 14:47:16:INFO:Loss = [0.0006339080629013643, 0.0007589801086791652, 0.02576163995178436, 0.026254973445642777, 0.00416815492291532, 0.004120753137493636, 0.004010370113248446, 0.003994712118822123, 0.027647961843425523, 0.027692084007452135]
2022-01-06 14:47:16:INFO:-------------Training local models-------------
2022-01-06 14:52:00:INFO:-------------Aggregating local models-------------
2022-01-06 14:52:01:INFO:-------------Round number: 35-------------
2022-01-06 14:52:01:INFO:-------------Sending models-------------
2022-01-06 14:52:01:INFO:-------------Evaluating models-------------
2022-01-06 14:52:01:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 14:52:01:INFO:Accuracy = [1.0, 1.0, 0.98989898989899, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9893939393939394, 0.9888888888888889]
2022-01-06 14:52:01:INFO:Loss = [0.0006182196224527257, 0.0007388342628271655, 0.02555761113444073, 0.026033303767676305, 0.004116958958149204, 0.0040687038086285945, 0.003950609679043857, 0.003936666888139279, 0.027612598711916368, 0.027642969878123574]
2022-01-06 14:52:01:INFO:-------------Training local models-------------
2022-01-06 14:56:45:INFO:-------------Aggregating local models-------------
2022-01-06 14:56:45:INFO:-------------Round number: 36-------------
2022-01-06 14:56:45:INFO:-------------Sending models-------------
2022-01-06 14:56:45:INFO:-------------Evaluating models-------------
2022-01-06 14:56:45:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 14:56:45:INFO:Accuracy = [1.0, 1.0, 0.98989898989899, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9893939393939394, 0.9893939393939394]
2022-01-06 14:56:45:INFO:Loss = [0.0006034871500257092, 0.0007199438212079589, 0.025362649513783364, 0.025821982008706026, 0.004067394365355163, 0.004018677224080926, 0.0038943813437182337, 0.003882003192361159, 0.027569595296314, 0.027586451177208947]
2022-01-06 14:56:45:INFO:-------------Training local models-------------
2022-01-06 15:01:29:INFO:-------------Aggregating local models-------------
2022-01-06 15:01:30:INFO:-------------Round number: 37-------------
2022-01-06 15:01:30:INFO:-------------Sending models-------------
2022-01-06 15:01:30:INFO:-------------Evaluating models-------------
2022-01-06 15:01:30:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 15:01:30:INFO:Accuracy = [1.0, 1.0, 0.98989898989899, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9904040404040404, 0.98989898989899]
2022-01-06 15:01:30:INFO:Loss = [0.0005896636806956123, 0.0007022439560791504, 0.025189120412761265, 0.025635819088410877, 0.004020298505144977, 0.00397108099219769, 0.0038413647981073926, 0.0038305394752744105, 0.02753514260449917, 0.02754071851438376]
2022-01-06 15:01:30:INFO:-------------Training local models-------------
2022-01-06 15:06:14:INFO:-------------Aggregating local models-------------
2022-01-06 15:06:15:INFO:-------------Round number: 38-------------
2022-01-06 15:06:15:INFO:-------------Sending models-------------
2022-01-06 15:06:15:INFO:-------------Evaluating models-------------
2022-01-06 15:06:15:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 15:06:15:INFO:Accuracy = [1.0, 1.0, 0.98989898989899, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9904040404040404, 0.9904040404040404]
2022-01-06 15:06:15:INFO:Loss = [0.0005765648352767451, 0.0006855184612798651, 0.025019143868068035, 0.025452257285870115, 0.003975862347121592, 0.003926199806459169, 0.003791100719651943, 0.003781664688007496, 0.02751046308752517, 0.027505877848970423]
2022-01-06 15:06:15:INFO:-------------Training local models-------------
2022-01-06 15:10:58:INFO:-------------Aggregating local models-------------
2022-01-06 15:10:59:INFO:-------------Round number: 39-------------
2022-01-06 15:10:59:INFO:-------------Sending models-------------
2022-01-06 15:10:59:INFO:-------------Evaluating models-------------
2022-01-06 15:10:59:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 15:10:59:INFO:Accuracy = [1.0, 1.0, 0.98989898989899, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.98989898989899, 0.9904040404040404]
2022-01-06 15:10:59:INFO:Loss = [0.0005642567237851156, 0.0006698717480843458, 0.02485679573210934, 0.02527546373403311, 0.003935508252674701, 0.003885458456650006, 0.0037438029111923022, 0.0037355734084430327, 0.027476790042541638, 0.027463178518594603]
2022-01-06 15:10:59:INFO:-------------Training local models-------------
2022-01-06 15:15:43:INFO:-------------Aggregating local models-------------
2022-01-06 15:15:43:INFO:-------------Round number: 40-------------
2022-01-06 15:15:43:INFO:-------------Sending models-------------
2022-01-06 15:15:43:INFO:-------------Evaluating models-------------
2022-01-06 15:15:44:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 15:15:44:INFO:Accuracy = [1.0, 1.0, 0.98989898989899, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.98989898989899, 0.9904040404040404]
2022-01-06 15:15:44:INFO:Loss = [0.0005526563552113584, 0.0006551563833812851, 0.02471149442999101, 0.025115448139315804, 0.003897431178327936, 0.003847227181039202, 0.0036992776200019182, 0.0036921439560547247, 0.027448608624962793, 0.027427592853231857]
2022-01-06 15:15:44:INFO:-------------Training local models-------------
2022-01-06 15:20:27:INFO:-------------Aggregating local models-------------
2022-01-06 15:20:27:INFO:-------------Round number: 41-------------
2022-01-06 15:20:27:INFO:-------------Sending models-------------
2022-01-06 15:20:28:INFO:-------------Evaluating models-------------
2022-01-06 15:20:28:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 15:20:28:INFO:Accuracy = [1.0, 1.0, 0.98989898989899, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9904040404040404, 0.9904040404040404]
2022-01-06 15:20:28:INFO:Loss = [0.0005416559284383012, 0.000641222973820851, 0.02457770672324731, 0.02496867621736112, 0.0038596391818414718, 0.003809156601798322, 0.00365727143442641, 0.0036510860720264104, 0.02742983874201919, 0.027401211473884222]
2022-01-06 15:20:28:INFO:-------------Training local models-------------
2022-01-06 15:25:11:INFO:-------------Aggregating local models-------------
2022-01-06 15:25:12:INFO:-------------Round number: 42-------------
2022-01-06 15:25:12:INFO:-------------Sending models-------------
2022-01-06 15:25:12:INFO:-------------Evaluating models-------------
2022-01-06 15:25:12:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 15:25:12:INFO:Accuracy = [1.0, 1.0, 0.98989898989899, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9904040404040404, 0.9904040404040404]
2022-01-06 15:25:12:INFO:Loss = [0.0005311840446114674, 0.000627996317376124, 0.024450646643148357, 0.024828733041397415, 0.0038235549800116463, 0.003772676538096446, 0.003617463493218097, 0.003612139117923116, 0.02741587796447335, 0.027379548319799822]
2022-01-06 15:25:12:INFO:-------------Training local models-------------
2022-01-06 15:29:55:INFO:-------------Aggregating local models-------------
2022-01-06 15:29:56:INFO:-------------Round number: 43-------------
2022-01-06 15:29:56:INFO:-------------Sending models-------------
2022-01-06 15:29:56:INFO:-------------Evaluating models-------------
2022-01-06 15:29:56:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 15:29:56:INFO:Accuracy = [1.0, 1.0, 0.9904040404040404, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9904040404040404, 0.9904040404040404]
2022-01-06 15:29:56:INFO:Loss = [0.0005212616567212425, 0.000615506171479038, 0.024320260683671588, 0.024685411789086533, 0.0037890176953265893, 0.003737476454261923, 0.003579870296659529, 0.003575407778344291, 0.02739509443656631, 0.02735240354475242]
2022-01-06 15:29:56:INFO:-------------Training local models-------------
2022-01-06 15:34:40:INFO:-------------Aggregating local models-------------
2022-01-06 15:34:40:INFO:-------------Round number: 44-------------
2022-01-06 15:34:40:INFO:-------------Sending models-------------
2022-01-06 15:34:40:INFO:-------------Evaluating models-------------
2022-01-06 15:34:41:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 15:34:41:INFO:Accuracy = [1.0, 1.0, 0.9904040404040404, 0.9888888888888889, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9904040404040404, 0.9904040404040404]
2022-01-06 15:34:41:INFO:Loss = [0.0005118593341621543, 0.0006036950831692208, 0.024195792658388705, 0.02455063007996844, 0.0037562559693267556, 0.0037040966774829847, 0.0035439936495278764, 0.003540243237898951, 0.027378395358960236, 0.02733138856891479]
2022-01-06 15:34:41:INFO:-------------Training local models-------------
2022-01-06 15:39:24:INFO:-------------Aggregating local models-------------
2022-01-06 15:39:25:INFO:-------------Round number: 45-------------
2022-01-06 15:39:25:INFO:-------------Sending models-------------
2022-01-06 15:39:25:INFO:-------------Evaluating models-------------
2022-01-06 15:39:25:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 15:39:25:INFO:Accuracy = [1.0, 1.0, 0.9904040404040404, 0.98989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9904040404040404, 0.9904040404040404]
2022-01-06 15:39:25:INFO:Loss = [0.000502913206891566, 0.0005924955145644043, 0.02407019492010743, 0.02441426280195656, 0.0037246133224691606, 0.0036717891515304427, 0.003510016352916092, 0.0035069672065348107, 0.027372881997669334, 0.027321800032893747]
2022-01-06 15:39:25:INFO:-------------Training local models-------------
2022-01-06 15:44:08:INFO:-------------Aggregating local models-------------
2022-01-06 15:44:09:INFO:-------------Round number: 46-------------
2022-01-06 15:44:09:INFO:-------------Sending models-------------
2022-01-06 15:44:09:INFO:-------------Evaluating models-------------
2022-01-06 15:44:09:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 15:44:09:INFO:Accuracy = [1.0, 1.0, 0.9904040404040404, 0.98989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9904040404040404, 0.9904040404040404]
2022-01-06 15:44:09:INFO:Loss = [0.0004943575742175318, 0.0005818174822504968, 0.023954921498603433, 0.024289805859528068, 0.0036951441096559822, 0.003641681513600457, 0.003477717545503783, 0.003475400348088442, 0.027361067026044975, 0.02730692371768038]
2022-01-06 15:44:09:INFO:-------------Training local models-------------
2022-01-06 15:48:53:INFO:-------------Aggregating local models-------------
2022-01-06 15:48:53:INFO:-------------Round number: 47-------------
2022-01-06 15:48:53:INFO:-------------Sending models-------------
2022-01-06 15:48:53:INFO:-------------Evaluating models-------------
2022-01-06 15:48:53:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 15:48:53:INFO:Accuracy = [1.0, 1.0, 0.9904040404040404, 0.9904040404040404, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9904040404040404, 0.9904040404040404]
2022-01-06 15:48:53:INFO:Loss = [0.0004861995024949658, 0.0005716689969135173, 0.023846429350961637, 0.024171827801471566, 0.003666642909379931, 0.003612415926312164, 0.003446805740848026, 0.0034452358411726893, 0.027347481703604026, 0.027290346051321274]
2022-01-06 15:48:53:INFO:-------------Training local models-------------
2022-01-06 15:53:37:INFO:-------------Aggregating local models-------------
2022-01-06 15:53:37:INFO:-------------Round number: 48-------------
2022-01-06 15:53:37:INFO:-------------Sending models-------------
2022-01-06 15:53:38:INFO:-------------Evaluating models-------------
2022-01-06 15:53:38:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 15:53:38:INFO:Accuracy = [1.0, 1.0, 0.9904040404040404, 0.9904040404040404, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9904040404040404, 0.9904040404040404]
2022-01-06 15:53:38:INFO:Loss = [0.0004784067675659158, 0.000562003660014292, 0.02374941392848114, 0.02406720243268846, 0.0036386279415867215, 0.0035834503979017564, 0.00341739806776281, 0.003416552816222497, 0.027338474729385963, 0.02727972615719942]
2022-01-06 15:53:38:INFO:-------------Training local models-------------
2022-01-06 15:58:21:INFO:-------------Aggregating local models-------------
2022-01-06 15:58:22:INFO:-------------Round number: 49-------------
2022-01-06 15:58:22:INFO:-------------Sending models-------------
2022-01-06 15:58:22:INFO:-------------Evaluating models-------------
2022-01-06 15:58:22:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 15:58:22:INFO:Accuracy = [1.0, 1.0, 0.9904040404040404, 0.9904040404040404, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9904040404040404, 0.9904040404040404]
2022-01-06 15:58:22:INFO:Loss = [0.0004709353427284496, 0.0005527530174290543, 0.023653932159500946, 0.023964972460228204, 0.0036110891449939713, 0.003554966024129306, 0.003389478549836371, 0.003389359789742579, 0.027330976661510294, 0.027271038923688387]
2022-01-06 15:58:22:INFO:-------------Training local models-------------
2022-01-06 16:03:05:INFO:-------------Aggregating local models-------------
2022-01-06 16:03:06:INFO:-------------Round number: 50-------------
2022-01-06 16:03:06:INFO:-------------Sending models-------------
2022-01-06 16:03:06:INFO:-------------Evaluating models-------------
2022-01-06 16:03:06:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 16:03:06:INFO:Accuracy = [1.0, 1.0, 0.9904040404040404, 0.9904040404040404, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9904040404040404, 0.9904040404040404]
2022-01-06 16:03:06:INFO:Loss = [0.00046373361627488385, 0.0005438250771090459, 0.023564200437054622, 0.023870606886079386, 0.0035850794588551445, 0.003527917440020577, 0.0033627801287733784, 0.0033633311453952343, 0.02731874630877483, 0.027256896537828926]
2022-01-06 16:03:06:INFO:-------------Training local models-------------
2022-01-06 16:07:50:INFO:-------------Aggregating local models-------------
2022-01-06 16:07:50:INFO:-------------Round number: 51-------------
2022-01-06 16:07:50:INFO:-------------Sending models-------------
2022-01-06 16:07:50:INFO:-------------Evaluating models-------------
2022-01-06 16:07:50:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 16:07:50:INFO:Accuracy = [1.0, 1.0, 0.9904040404040404, 0.9904040404040404, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9904040404040404, 0.9904040404040404]
2022-01-06 16:07:50:INFO:Loss = [0.0004568126187811199, 0.0005352336003999531, 0.02347564979869698, 0.02377818321643424, 0.0035591663646291545, 0.0035010773809388946, 0.0033371949022969628, 0.003338396173427155, 0.027315131614649903, 0.027252221474086444]
2022-01-06 16:07:50:INFO:-------------Training local models-------------
2022-01-06 16:12:34:INFO:-------------Aggregating local models-------------
2022-01-06 16:12:34:INFO:-------------Round number: 52-------------
2022-01-06 16:12:34:INFO:-------------Sending models-------------
2022-01-06 16:12:34:INFO:-------------Evaluating models-------------
2022-01-06 16:12:34:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 16:12:34:INFO:Accuracy = [1.0, 1.0, 0.9904040404040404, 0.9904040404040404, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9904040404040404, 0.9904040404040404]
2022-01-06 16:12:34:INFO:Loss = [0.0004502040900174185, 0.0005270535817507694, 0.023394972115225628, 0.023692796732589297, 0.00353438822187147, 0.003475439361797974, 0.003312870905905253, 0.0033147036196683674, 0.027305923400507883, 0.02724186528381012]
2022-01-06 16:12:34:INFO:-------------Training local models-------------
2022-01-06 16:17:18:INFO:-------------Aggregating local models-------------
2022-01-06 16:17:18:INFO:-------------Round number: 53-------------
2022-01-06 16:17:18:INFO:-------------Sending models-------------
2022-01-06 16:17:18:INFO:-------------Evaluating models-------------
2022-01-06 16:17:18:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 16:17:18:INFO:Accuracy = [1.0, 1.0, 0.9904040404040404, 0.9904040404040404, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9904040404040404, 0.9904040404040404]
2022-01-06 16:17:18:INFO:Loss = [0.00044386281333205226, 0.0005192216553133231, 0.023317749014539445, 0.023611087660188934, 0.0035104903986944973, 0.003450748494390729, 0.0032896897196168897, 0.0032921285141367324, 0.027301112558697323, 0.027235949856369207]
2022-01-06 16:17:18:INFO:-------------Training local models-------------
2022-01-06 16:22:02:INFO:-------------Aggregating local models-------------
2022-01-06 16:22:02:INFO:-------------Round number: 54-------------
2022-01-06 16:22:02:INFO:-------------Sending models-------------
2022-01-06 16:22:03:INFO:-------------Evaluating models-------------
2022-01-06 16:22:03:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 16:22:03:INFO:Accuracy = [1.0, 1.0, 0.990909090909091, 0.9904040404040404, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.990909090909091, 0.9904040404040404]
2022-01-06 16:22:03:INFO:Loss = [0.00043776086234294156, 0.0005116919682268877, 0.023231264092593313, 0.023520955287323078, 0.0034864457911708362, 0.0034259120242789536, 0.003267451195630991, 0.0032704988716496432, 0.027302051425464345, 0.02723669795911216]
2022-01-06 16:22:03:INFO:-------------Training local models-------------
2022-01-06 16:26:46:INFO:-------------Aggregating local models-------------
2022-01-06 16:26:47:INFO:-------------Round number: 55-------------
2022-01-06 16:26:47:INFO:-------------Sending models-------------
2022-01-06 16:26:47:INFO:-------------Evaluating models-------------
2022-01-06 16:26:47:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 16:26:47:INFO:Accuracy = [1.0, 1.0, 0.990909090909091, 0.9904040404040404, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.990909090909091, 0.9904040404040404]
2022-01-06 16:26:47:INFO:Loss = [0.000431879528045873, 0.0005044433156941486, 0.023149934445010706, 0.023437365547153897, 0.0034641186555938587, 0.0034028896272456674, 0.0032461053761330227, 0.0032497829926925455, 0.02730685679116872, 0.0272414908211633]
2022-01-06 16:26:47:INFO:-------------Training local models-------------
2022-01-06 16:31:30:INFO:-------------Aggregating local models-------------
2022-01-06 16:31:31:INFO:-------------Round number: 56-------------
2022-01-06 16:31:31:INFO:-------------Sending models-------------
2022-01-06 16:31:31:INFO:-------------Evaluating models-------------
2022-01-06 16:31:31:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 16:31:31:INFO:Accuracy = [1.0, 1.0, 0.9904040404040404, 0.9904040404040404, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.990909090909091, 0.9904040404040404]
2022-01-06 16:31:31:INFO:Loss = [0.00042622853393138463, 0.0004974960810604806, 0.023075846020030367, 0.023361677221228918, 0.0034427814809716456, 0.003380883880939596, 0.0032255357456336363, 0.0032297894046825256, 0.0273071571299854, 0.027242001153890576]
2022-01-06 16:31:31:INFO:-------------Training local models-------------
2022-01-06 16:36:14:INFO:-------------Aggregating local models-------------
2022-01-06 16:36:15:INFO:-------------Round number: 57-------------
2022-01-06 16:36:15:INFO:-------------Sending models-------------
2022-01-06 16:36:15:INFO:-------------Evaluating models-------------
2022-01-06 16:36:15:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 16:36:15:INFO:Accuracy = [1.0, 1.0, 0.9904040404040404, 0.9904040404040404, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.990909090909091, 0.9904040404040404]
2022-01-06 16:36:15:INFO:Loss = [0.00042076988181794845, 0.0004907929636204364, 0.02299725180428324, 0.023281043828438035, 0.003421921085977962, 0.0033594375238853807, 0.0032057217036313575, 0.0032105220474587634, 0.02731344025774943, 0.02724915077865951]
2022-01-06 16:36:15:INFO:-------------Training local models-------------
2022-01-06 16:40:58:INFO:-------------Aggregating local models-------------
2022-01-06 16:40:59:INFO:-------------Round number: 58-------------
2022-01-06 16:40:59:INFO:-------------Sending models-------------
2022-01-06 16:40:59:INFO:-------------Evaluating models-------------
2022-01-06 16:40:59:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 16:40:59:INFO:Accuracy = [1.0, 1.0, 0.9904040404040404, 0.9904040404040404, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.990909090909091, 0.9904040404040404]
2022-01-06 16:40:59:INFO:Loss = [0.00041553141952567555, 0.00048438478803989417, 0.022920974546628493, 0.023202128207864887, 0.0034028705340865095, 0.003339788022273724, 0.003186667822641116, 0.003191966399033, 0.027322679036786562, 0.027259295504272172]
2022-01-06 16:40:59:INFO:-------------Training local models-------------
2022-01-06 16:45:42:INFO:-------------Aggregating local models-------------
2022-01-06 16:45:43:INFO:-------------Round number: 59-------------
2022-01-06 16:45:43:INFO:-------------Sending models-------------
2022-01-06 16:45:43:INFO:-------------Evaluating models-------------
2022-01-06 16:45:43:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 16:45:43:INFO:Accuracy = [1.0, 1.0, 0.9904040404040404, 0.9904040404040404, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.990909090909091, 0.9904040404040404]
2022-01-06 16:45:43:INFO:Loss = [0.0004104755026756638, 0.0004782036147155326, 0.022845443146516944, 0.02312480893834535, 0.0033843020145100998, 0.003320651139131429, 0.0031683134702817748, 0.0031740767770132134, 0.027330610376070628, 0.027268004758099613]
2022-01-06 16:45:43:INFO:-------------Training local models-------------
2022-01-06 16:50:26:INFO:-------------Aggregating local models-------------
2022-01-06 16:50:27:INFO:-------------Round number: 60-------------
2022-01-06 16:50:27:INFO:-------------Sending models-------------
2022-01-06 16:50:27:INFO:-------------Evaluating models-------------
2022-01-06 16:50:27:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 16:50:27:INFO:Accuracy = [1.0, 1.0, 0.9904040404040404, 0.9904040404040404, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.990909090909091, 0.9904040404040404]
2022-01-06 16:50:27:INFO:Loss = [0.00040559841686215326, 0.00047225731911447553, 0.022771713096935486, 0.023048637853090175, 0.003365548009252153, 0.0033013002193856113, 0.003150729796230147, 0.0031569138350039222, 0.02734068931645243, 0.02727896391880502]
2022-01-06 16:50:27:INFO:-------------Training local models-------------
2022-01-06 16:55:11:INFO:-------------Aggregating local models-------------
2022-01-06 16:55:11:INFO:-------------Round number: 61-------------
2022-01-06 16:55:11:INFO:-------------Sending models-------------
2022-01-06 16:55:11:INFO:-------------Evaluating models-------------
2022-01-06 16:55:11:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 16:55:11:INFO:Accuracy = [1.0, 1.0, 0.9904040404040404, 0.9904040404040404, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.990909090909091, 0.9904040404040404]
2022-01-06 16:55:11:INFO:Loss = [0.0004008900758366728, 0.00046651391039080354, 0.022702955214063333, 0.02297779253858056, 0.0033475148979445605, 0.0032824868129120496, 0.0031337561294085296, 0.003140330140637951, 0.02735197945930023, 0.027290966274131738]
2022-01-06 16:55:11:INFO:-------------Training local models-------------
2022-01-06 16:59:55:INFO:-------------Aggregating local models-------------
2022-01-06 16:59:55:INFO:-------------Round number: 62-------------
2022-01-06 16:59:55:INFO:-------------Sending models-------------
2022-01-06 16:59:55:INFO:-------------Evaluating models-------------
2022-01-06 16:59:55:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 16:59:55:INFO:Accuracy = [1.0, 1.0, 0.9904040404040404, 0.9904040404040404, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.990909090909091, 0.9904040404040404]
2022-01-06 16:59:55:INFO:Loss = [0.00039634330594965673, 0.0004609816469658681, 0.022632927281429516, 0.022906100266259777, 0.0033302859302790293, 0.003264602985237074, 0.0031174596104640595, 0.0031243981183013032, 0.027363475024092143, 0.027303303348345263]
2022-01-06 16:59:55:INFO:-------------Training local models-------------
2022-01-06 17:04:39:INFO:-------------Aggregating local models-------------
2022-01-06 17:04:40:INFO:-------------Round number: 63-------------
2022-01-06 17:04:40:INFO:-------------Sending models-------------
2022-01-06 17:04:40:INFO:-------------Evaluating models-------------
2022-01-06 17:04:40:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 17:04:40:INFO:Accuracy = [1.0, 1.0, 0.9904040404040404, 0.990909090909091, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.990909090909091, 0.9904040404040404]
2022-01-06 17:04:40:INFO:Loss = [0.00039194324669708036, 0.0004556332021636972, 0.022567986890074585, 0.02284062170993003, 0.003313145056587257, 0.0032468328555856863, 0.0031018297064173282, 0.003109138867962383, 0.027383249353421676, 0.02732443304993274]
2022-01-06 17:04:40:INFO:-------------Training local models-------------
2022-01-06 17:09:23:INFO:-------------Aggregating local models-------------
2022-01-06 17:09:24:INFO:-------------Round number: 64-------------
2022-01-06 17:09:24:INFO:-------------Sending models-------------
2022-01-06 17:09:24:INFO:-------------Evaluating models-------------
2022-01-06 17:09:24:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 17:09:24:INFO:Accuracy = [1.0, 1.0, 0.9904040404040404, 0.990909090909091, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.990909090909091, 0.9904040404040404]
2022-01-06 17:09:24:INFO:Loss = [0.00038765993401348813, 0.00045042785917611024, 0.022504125780852344, 0.022776249094243608, 0.0032969803703660244, 0.003229949250488411, 0.003086659392776177, 0.003094311992496079, 0.027399479520035946, 0.027341698176326763]
2022-01-06 17:09:24:INFO:-------------Training local models-------------
2022-01-06 17:14:07:INFO:-------------Aggregating local models-------------
2022-01-06 17:14:08:INFO:-------------Round number: 65-------------
2022-01-06 17:14:08:INFO:-------------Sending models-------------
2022-01-06 17:14:08:INFO:-------------Evaluating models-------------
2022-01-06 17:14:08:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 17:14:08:INFO:Accuracy = [1.0, 1.0, 0.9904040404040404, 0.990909090909091, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.990909090909091, 0.9904040404040404]
2022-01-06 17:14:08:INFO:Loss = [0.0003835079367178483, 0.00044539417866862915, 0.02243971018923629, 0.022710578048276094, 0.003281060276886553, 0.0032133137078744767, 0.003071986931776925, 0.0030799590646488975, 0.027420469706995583, 0.027363475463153927]
2022-01-06 17:14:08:INFO:-------------Training local models-------------
2022-01-06 17:18:52:INFO:-------------Aggregating local models-------------
2022-01-06 17:18:52:INFO:-------------Round number: 66-------------
2022-01-06 17:18:52:INFO:-------------Sending models-------------
2022-01-06 17:18:52:INFO:-------------Evaluating models-------------
2022-01-06 17:18:52:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 17:18:52:INFO:Accuracy = [1.0, 1.0, 0.990909090909091, 0.990909090909091, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.990909090909091, 0.9904040404040404]
2022-01-06 17:18:52:INFO:Loss = [0.0003794518295652586, 0.00044047582586327654, 0.02237723006812229, 0.022647569250004766, 0.00326522367124033, 0.0031966853435972213, 0.003057753560534191, 0.003066042461494987, 0.027436822746182376, 0.0273806043461438]
2022-01-06 17:18:52:INFO:-------------Training local models-------------
2022-01-06 17:23:36:INFO:-------------Aggregating local models-------------
2022-01-06 17:23:37:INFO:-------------Round number: 67-------------
2022-01-06 17:23:37:INFO:-------------Sending models-------------
2022-01-06 17:23:37:INFO:-------------Evaluating models-------------
2022-01-06 17:23:37:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 17:23:37:INFO:Accuracy = [1.0, 1.0, 0.990909090909091, 0.990909090909091, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.990909090909091, 0.9904040404040404]
2022-01-06 17:23:37:INFO:Loss = [0.0003754943007758508, 0.00043569213975562813, 0.022314228207669474, 0.02258315868228954, 0.0032500401705112033, 0.0031808094927622036, 0.0030439770596822568, 0.0030525609572550545, 0.027456455967872863, 0.027401076670879904]
2022-01-06 17:23:37:INFO:-------------Training local models-------------
2022-01-06 17:28:20:INFO:-------------Aggregating local models-------------
2022-01-06 17:28:21:INFO:-------------Round number: 68-------------
2022-01-06 17:28:21:INFO:-------------Sending models-------------
2022-01-06 17:28:21:INFO:-------------Evaluating models-------------
2022-01-06 17:28:21:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 17:28:21:INFO:Accuracy = [1.0, 1.0, 0.990909090909091, 0.990909090909091, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.990909090909091, 0.9904040404040404]
2022-01-06 17:28:21:INFO:Loss = [0.00037165039717696017, 0.0004310497939256649, 0.022251373196684084, 0.022518804986697376, 0.0032354214558836247, 0.0031655265195566777, 0.0030307317251285757, 0.0030395666160359844, 0.027474649964657292, 0.02742000810654608]
2022-01-06 17:28:21:INFO:-------------Training local models-------------
2022-01-06 17:33:04:INFO:-------------Aggregating local models-------------
2022-01-06 17:33:05:INFO:-------------Round number: 69-------------
2022-01-06 17:33:05:INFO:-------------Sending models-------------
2022-01-06 17:33:05:INFO:-------------Evaluating models-------------
2022-01-06 17:33:05:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 17:33:05:INFO:Accuracy = [1.0, 1.0, 0.990909090909091, 0.990909090909091, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.990909090909091, 0.9904040404040404]
2022-01-06 17:33:05:INFO:Loss = [0.000367948207161989, 0.0004265708519174362, 0.022192901349769797, 0.022460279012181554, 0.0032208795958679113, 0.003150258140693849, 0.0030179546249219313, 0.0030270437220908685, 0.027492778109141604, 0.027439416352305183]
2022-01-06 17:33:05:INFO:-------------Training local models-------------
2022-01-06 17:37:48:INFO:-------------Aggregating local models-------------
2022-01-06 17:37:49:INFO:-------------Round number: 70-------------
2022-01-06 17:37:49:INFO:-------------Sending models-------------
2022-01-06 17:37:49:INFO:-------------Evaluating models-------------
2022-01-06 17:37:49:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 17:37:49:INFO:Accuracy = [1.0, 1.0, 0.990909090909091, 0.990909090909091, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.990909090909091, 0.9904040404040404]
2022-01-06 17:37:49:INFO:Loss = [0.00036434453665211235, 0.000422218290246618, 0.02213568174304259, 0.022402837372893107, 0.0032065948394514945, 0.003135226762538198, 0.003005547937314215, 0.0030148864283822178, 0.02751068547036681, 0.027458136854901834]
2022-01-06 17:37:49:INFO:-------------Training local models-------------
2022-01-06 17:42:32:INFO:-------------Aggregating local models-------------
2022-01-06 17:42:33:INFO:-------------Round number: 71-------------
2022-01-06 17:42:33:INFO:-------------Sending models-------------
2022-01-06 17:42:33:INFO:-------------Evaluating models-------------
2022-01-06 17:42:33:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 17:42:33:INFO:Accuracy = [1.0, 1.0, 0.990909090909091, 0.990909090909091, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.990909090909091, 0.9904040404040404]
2022-01-06 17:42:33:INFO:Loss = [0.0003608716369027124, 0.00041801918940642153, 0.022079900412852727, 0.022347464215876373, 0.003193392855545692, 0.003121257136705816, 0.0029935312733336233, 0.0030031088092514297, 0.027531012364682403, 0.027479800864131737]
2022-01-06 17:42:33:INFO:-------------Training local models-------------
2022-01-06 17:47:17:INFO:-------------Aggregating local models-------------
2022-01-06 17:47:17:INFO:-------------Round number: 72-------------
2022-01-06 17:47:17:INFO:-------------Sending models-------------
2022-01-06 17:47:17:INFO:-------------Evaluating models-------------
2022-01-06 17:47:18:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 17:47:18:INFO:Accuracy = [1.0, 1.0, 0.990909090909091, 0.990909090909091, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.990909090909091, 0.9904040404040404]
2022-01-06 17:47:18:INFO:Loss = [0.0003574842372105158, 0.0004139337032360014, 0.022028692763834817, 0.02229622490047248, 0.0031798658541043147, 0.0031068663794122597, 0.0029818882233742286, 0.002991700292032975, 0.02755049981569663, 0.027500361925794636]
2022-01-06 17:47:18:INFO:-------------Training local models-------------
2022-01-06 17:52:01:INFO:-------------Aggregating local models-------------
2022-01-06 17:52:02:INFO:-------------Round number: 73-------------
2022-01-06 17:52:02:INFO:-------------Sending models-------------
2022-01-06 17:52:02:INFO:-------------Evaluating models-------------
2022-01-06 17:52:02:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 17:52:02:INFO:Accuracy = [1.0, 1.0, 0.990909090909091, 0.990909090909091, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.990909090909091, 0.9904040404040404]
2022-01-06 17:52:02:INFO:Loss = [0.00035421973465638463, 0.0004099904354245724, 0.021978496846063397, 0.022246750078865618, 0.0031663090001667585, 0.003092361419209802, 0.002970607294988403, 0.0029806341177308323, 0.02756772880777061, 0.027518321836062874]
2022-01-06 17:52:02:INFO:-------------Training local models-------------
2022-01-06 17:56:45:INFO:-------------Aggregating local models-------------
2022-01-06 17:56:46:INFO:-------------Round number: 74-------------
2022-01-06 17:56:46:INFO:-------------Sending models-------------
2022-01-06 17:56:46:INFO:-------------Evaluating models-------------
2022-01-06 17:56:46:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 17:56:46:INFO:Accuracy = [1.0, 1.0, 0.990909090909091, 0.990909090909091, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.990909090909091, 0.9904040404040404]
2022-01-06 17:56:46:INFO:Loss = [0.0003510263133519935, 0.00040614397153930065, 0.021928430607374937, 0.022197275622450278, 0.0031530772716253366, 0.0030781733246261532, 0.00295966630721082, 0.002969901448531428, 0.02758817079960441, 0.027539919724743164]
2022-01-06 17:56:46:INFO:-------------Training local models-------------
2022-01-06 18:01:29:INFO:-------------Aggregating local models-------------
2022-01-06 18:01:30:INFO:-------------Round number: 75-------------
2022-01-06 18:01:30:INFO:-------------Sending models-------------
2022-01-06 18:01:30:INFO:-------------Evaluating models-------------
2022-01-06 18:01:30:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 18:01:30:INFO:Accuracy = [1.0, 1.0, 0.990909090909091, 0.990909090909091, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.990909090909091, 0.9904040404040404]
2022-01-06 18:01:30:INFO:Loss = [0.0003479241103827871, 0.0004024048891450447, 0.021876567815367037, 0.0221458714001735, 0.0031406509488767892, 0.0030648027263584544, 0.0029490490664203306, 0.002959472455591877, 0.02760557357251405, 0.027558507323720557]
2022-01-06 18:01:30:INFO:-------------Training local models-------------
2022-01-06 18:06:13:INFO:-------------Aggregating local models-------------
2022-01-06 18:06:14:INFO:-------------Round number: 76-------------
2022-01-06 18:06:14:INFO:-------------Sending models-------------
2022-01-06 18:06:14:INFO:-------------Evaluating models-------------
2022-01-06 18:06:14:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 18:06:14:INFO:Accuracy = [1.0, 1.0, 0.990909090909091, 0.990909090909091, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.990909090909091, 0.9904040404040404]
2022-01-06 18:06:14:INFO:Loss = [0.00034491143523513476, 0.0003987753735775113, 0.02182440334638177, 0.022093789502790548, 0.0031284269040199176, 0.0030515779272314424, 0.0029387538617921755, 0.0029493473650125616, 0.027626027484397624, 0.027579437382624892]
2022-01-06 18:06:14:INFO:-------------Training local models-------------
2022-01-06 18:10:58:INFO:-------------Aggregating local models-------------
2022-01-06 18:10:58:INFO:-------------Round number: 77-------------
2022-01-06 18:10:58:INFO:-------------Sending models-------------
2022-01-06 18:10:58:INFO:-------------Evaluating models-------------
2022-01-06 18:10:59:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 18:10:59:INFO:Accuracy = [1.0, 1.0, 0.990909090909091, 0.990909090909091, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.990909090909091, 0.9904040404040404]
2022-01-06 18:10:59:INFO:Loss = [0.0003419626979324896, 0.00039522801488592357, 0.021773486512763222, 0.02204329781994749, 0.00311623347716346, 0.003038452826692237, 0.0029289164717802765, 0.002939693208919389, 0.027641707868625794, 0.02759573887006267]
2022-01-06 18:10:59:INFO:-------------Training local models-------------
2022-01-06 18:15:42:INFO:-------------Aggregating local models-------------
2022-01-06 18:15:43:INFO:-------------Round number: 78-------------
2022-01-06 18:15:43:INFO:-------------Sending models-------------
2022-01-06 18:15:43:INFO:-------------Evaluating models-------------
2022-01-06 18:15:43:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 18:15:43:INFO:Accuracy = [1.0, 1.0, 0.990909090909091, 0.990909090909091, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.990909090909091, 0.9904040404040404]
2022-01-06 18:15:43:INFO:Loss = [0.0003391159605267934, 0.0003918068648283335, 0.02172388991152316, 0.021994022852274583, 0.0031040580985137066, 0.0030253045470044065, 0.002919404555087576, 0.00293036900622261, 0.027661137708151047, 0.027615487979762817]
2022-01-06 18:15:43:INFO:-------------Training local models-------------
2022-01-06 18:20:26:INFO:-------------Aggregating local models-------------
2022-01-06 18:20:27:INFO:-------------Round number: 79-------------
2022-01-06 18:20:27:INFO:-------------Sending models-------------
2022-01-06 18:20:27:INFO:-------------Evaluating models-------------
2022-01-06 18:20:27:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 18:20:27:INFO:Accuracy = [1.0, 1.0, 0.990909090909091, 0.990909090909091, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.990909090909091, 0.9904040404040404]
2022-01-06 18:20:27:INFO:Loss = [0.0003363276463653275, 0.0003884585777334657, 0.0216766352501132, 0.021947415220112284, 0.003091963840543398, 0.003012291435484855, 0.0029101590928362524, 0.0029213009392959873, 0.027679832826018384, 0.02763494504011172]
2022-01-06 18:20:27:INFO:-------------Training local models-------------
2022-01-06 18:25:11:INFO:-------------Aggregating local models-------------
2022-01-06 18:25:11:INFO:-------------Round number: 80-------------
2022-01-06 18:25:11:INFO:-------------Sending models-------------
2022-01-06 18:25:11:INFO:-------------Evaluating models-------------
2022-01-06 18:25:11:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 18:25:11:INFO:Accuracy = [1.0, 1.0, 0.990909090909091, 0.990909090909091, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.990909090909091, 0.9904040404040404]
2022-01-06 18:25:11:INFO:Loss = [0.00033362520973260145, 0.0003852233417523846, 0.021630270230221554, 0.02190134075922609, 0.0030810382021811186, 0.0030004735017189316, 0.0029011944356464696, 0.002912504254467734, 0.027698380794845434, 0.027653994863595297]
2022-01-06 18:25:11:INFO:-------------Training local models-------------
2022-01-06 18:29:55:INFO:-------------Aggregating local models-------------
2022-01-06 18:29:55:INFO:-------------Round number: 81-------------
2022-01-06 18:29:55:INFO:-------------Sending models-------------
2022-01-06 18:29:56:INFO:-------------Evaluating models-------------
2022-01-06 18:29:56:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 18:29:56:INFO:Accuracy = [1.0, 1.0, 0.990909090909091, 0.990909090909091, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.990909090909091, 0.9904040404040404]
2022-01-06 18:29:56:INFO:Loss = [0.0003309952740451219, 0.0003820743082395333, 0.02158615774298155, 0.021857690828499636, 0.003069932580472761, 0.002988430715626549, 0.0028924553973144677, 0.002903919441072356, 0.02771339895769213, 0.027669879297723174]
2022-01-06 18:29:56:INFO:-------------Training local models-------------
2022-01-06 18:34:39:INFO:-------------Aggregating local models-------------
2022-01-06 18:34:40:INFO:-------------Round number: 82-------------
2022-01-06 18:34:40:INFO:-------------Sending models-------------
2022-01-06 18:34:40:INFO:-------------Evaluating models-------------
2022-01-06 18:34:40:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 18:34:40:INFO:Accuracy = [1.0, 1.0, 0.990909090909091, 0.990909090909091, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.990909090909091, 0.9904040404040404]
2022-01-06 18:34:40:INFO:Loss = [0.00032846184169671927, 0.00037903702773613564, 0.021541432190861087, 0.021813315251117245, 0.003059041853355831, 0.0029766467644503332, 0.0028839615987121163, 0.002895579001292068, 0.027736740500767146, 0.02769379156979259]
2022-01-06 18:34:40:INFO:-------------Training local models-------------
2022-01-06 18:39:23:INFO:-------------Aggregating local models-------------
2022-01-06 18:39:24:INFO:-------------Round number: 83-------------
2022-01-06 18:39:24:INFO:-------------Sending models-------------
2022-01-06 18:39:24:INFO:-------------Evaluating models-------------
2022-01-06 18:39:24:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-06 18:39:24:INFO:Accuracy = [1.0, 1.0, 0.990909090909091, 0.990909090909091, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.998989898989899, 0.9904040404040404, 0.9904040404040404]
2022-01-06 18:39:24:INFO:Loss = [0.00032598765190579635, 0.0003760775797333065, 0.02149993722870123, 0.021771824659923698, 0.003048163230307935, 0.0029649268992969413, 0.0028757029172084003, 0.002887463270071932, 0.02775658442336807, 0.02771442999743764]
2022-01-06 18:39:24:INFO:-------------Training local models-------------
