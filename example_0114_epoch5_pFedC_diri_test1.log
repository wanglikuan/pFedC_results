2022-01-14 22:19:41:INFO:-------------Round number: 0-------------
2022-01-14 22:19:41:INFO:-------------Sending models-------------
2022-01-14 22:19:41:INFO:-------------Evaluating models-------------
2022-01-14 22:19:41:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:19:41:INFO:Accuracy = [0.893455098934551, 0.9147640791476408, 0.878016960208741, 0.9130245705588171, 0.9254185692541856, 0.07653837790824092, 0.10219612959338986, 0.12198303979125896, 0.10437051532941943, 0.8804087845183736]
2022-01-14 22:19:41:INFO:Loss = [0.6699720200934496, 0.6503740993757097, 0.6630385297618501, 0.6528492484773908, 0.6616784489188513, 0.7392249353089055, 0.7397243823142486, 0.7396344595511184, 0.7461297097323277, 0.6709170513216323]
2022-01-14 22:19:41:INFO:-------------Training local models-------------
2022-01-14 22:19:57:INFO:-------------Aggregating local models-------------
2022-01-14 22:19:58:INFO:-------------Round number: 1-------------
2022-01-14 22:19:58:INFO:-------------Sending models-------------
2022-01-14 22:19:58:INFO:-------------Evaluating models-------------
2022-01-14 22:19:58:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:19:58:INFO:Accuracy = [0.8086540552293977, 0.8949771689497716, 0.8454011741682974, 0.8756251358991085, 0.8804087845183736, 0.7116764514024788, 0.7451619917373342, 0.6773211567732116, 0.8003913894324853, 0.6066536203522505]
2022-01-14 22:19:58:INFO:Loss = [0.5404072582695789, 0.5652020256541092, 0.584963410937234, 0.5408171402951846, 0.5552282347306399, 0.6399712662485325, 0.6195938899662734, 0.6314411114987977, 0.5971160715858582, 0.6797369146222626]
2022-01-14 22:19:58:INFO:-------------Training local models-------------
2022-01-14 22:20:14:INFO:-------------Aggregating local models-------------
2022-01-14 22:20:15:INFO:-------------Round number: 2-------------
2022-01-14 22:20:15:INFO:-------------Sending models-------------
2022-01-14 22:20:15:INFO:-------------Evaluating models-------------
2022-01-14 22:20:15:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:20:15:INFO:Accuracy = [0.8417047184170472, 0.8873668188736682, 0.8614916286149162, 0.8867145031528593, 0.8586649271580779, 0.8310502283105022, 0.8317025440313112, 0.8043052837573386, 0.852576647097195, 0.6927592954990215]
2022-01-14 22:20:15:INFO:Loss = [0.4527441794006144, 0.49082353719552463, 0.5173093325568427, 0.4504228487649698, 0.4761322085450177, 0.5567001014215631, 0.5327811296749799, 0.5486598680507465, 0.5135741799447712, 0.6330705294792588]
2022-01-14 22:20:15:INFO:-------------Training local models-------------
2022-01-14 22:20:31:INFO:-------------Aggregating local models-------------
2022-01-14 22:20:31:INFO:-------------Round number: 3-------------
2022-01-14 22:20:31:INFO:-------------Sending models-------------
2022-01-14 22:20:31:INFO:-------------Evaluating models-------------
2022-01-14 22:20:31:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:20:31:INFO:Accuracy = [0.8510545770819743, 0.8869319417264623, 0.868014785823005, 0.8851924331376386, 0.8534464013916069, 0.8606218743205044, 0.8571428571428571, 0.8349641226353555, 0.8673624701021961, 0.7497282017829963]
2022-01-14 22:20:31:INFO:Loss = [0.4163980570810726, 0.43369573744179557, 0.4791442817058815, 0.39653293965908853, 0.42081427982651715, 0.4951800619112095, 0.47963590097637326, 0.49794676547388483, 0.46804039058370495, 0.5847857272295777]
2022-01-14 22:20:31:INFO:-------------Training local models-------------
2022-01-14 22:20:47:INFO:-------------Aggregating local models-------------
2022-01-14 22:20:48:INFO:-------------Round number: 4-------------
2022-01-14 22:20:48:INFO:-------------Sending models-------------
2022-01-14 22:20:48:INFO:-------------Evaluating models-------------
2022-01-14 22:20:48:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:20:48:INFO:Accuracy = [0.8534464013916069, 0.8869319417264623, 0.8701891715590345, 0.8838878016960209, 0.8540987171124157, 0.8660578386605784, 0.8612741900413133, 0.8408349641226354, 0.8758425744727114, 0.7834311806914547]
2022-01-14 22:20:48:INFO:Loss = [0.403487269570806, 0.39061185433427054, 0.46043470043346374, 0.3636109235154387, 0.3833569093030428, 0.4504380295294916, 0.44831038788236416, 0.46573041144140415, 0.44116062473543805, 0.5518532053695655]
2022-01-14 22:20:48:INFO:-------------Training local models-------------
2022-01-14 22:21:04:INFO:-------------Aggregating local models-------------
2022-01-14 22:21:05:INFO:-------------Round number: 5-------------
2022-01-14 22:21:05:INFO:-------------Sending models-------------
2022-01-14 22:21:05:INFO:-------------Evaluating models-------------
2022-01-14 22:21:05:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:21:05:INFO:Accuracy = [0.8519243313763861, 0.8873668188736682, 0.8691019786910198, 0.8851924331376386, 0.8562731028484453, 0.868014785823005, 0.8590998043052838, 0.8456186127419004, 0.8795390302239617, 0.812133072407045]
2022-01-14 22:21:05:INFO:Loss = [0.39986456944893745, 0.3562989934005538, 0.45125075100647105, 0.3417587908919213, 0.35693516614529963, 0.41695369544914296, 0.4287725276961537, 0.44287902363710663, 0.42321594463951706, 0.5294281568383881]
2022-01-14 22:21:05:INFO:-------------Training local models-------------
2022-01-14 22:21:21:INFO:-------------Aggregating local models-------------
2022-01-14 22:21:21:INFO:-------------Round number: 6-------------
2022-01-14 22:21:21:INFO:-------------Sending models-------------
2022-01-14 22:21:21:INFO:-------------Evaluating models-------------
2022-01-14 22:21:21:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:21:21:INFO:Accuracy = [0.8480104370515329, 0.8869319417264623, 0.8660578386605784, 0.8847575559904327, 0.857795172863666, 0.867579908675799, 0.8586649271580779, 0.8482278756251359, 0.882800608828006, 0.8253968253968254]
2022-01-14 22:21:21:INFO:Loss = [0.3998802514148584, 0.3280161918955222, 0.44673504201915243, 0.3262903006610876, 0.33723144739449906, 0.39156665383496086, 0.4157792563536201, 0.425744316430293, 0.4105196320161201, 0.5132346417553193]
2022-01-14 22:21:21:INFO:-------------Training local models-------------
2022-01-14 22:21:37:INFO:-------------Aggregating local models-------------
2022-01-14 22:21:38:INFO:-------------Round number: 7-------------
2022-01-14 22:21:38:INFO:-------------Sending models-------------
2022-01-14 22:21:38:INFO:-------------Evaluating models-------------
2022-01-14 22:21:38:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:21:38:INFO:Accuracy = [0.8445314198738856, 0.8845401174168297, 0.8632311372037399, 0.883235485975212, 0.8608393128941074, 0.8695368558382257, 0.8608393128941074, 0.8486627527723418, 0.8836703631224179, 0.8351815612089585]
2022-01-14 22:21:38:INFO:Loss = [0.40143526562293746, 0.3043808946610761, 0.44449384303840056, 0.31487018787116783, 0.32185573203768236, 0.37235835138615203, 0.4065437975183055, 0.41253095995946654, 0.401362044682674, 0.501156419188361]
2022-01-14 22:21:38:INFO:-------------Training local models-------------
2022-01-14 22:21:54:INFO:-------------Aggregating local models-------------
2022-01-14 22:21:55:INFO:-------------Round number: 8-------------
2022-01-14 22:21:55:INFO:-------------Sending models-------------
2022-01-14 22:21:55:INFO:-------------Evaluating models-------------
2022-01-14 22:21:55:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:21:55:INFO:Accuracy = [0.837138508371385, 0.8845401174168297, 0.8610567514677103, 0.8825831702544031, 0.8645357686453576, 0.8701891715590345, 0.8610567514677103, 0.8504022613611655, 0.8838878016960209, 0.8430093498586649]
2022-01-14 22:21:55:INFO:Loss = [0.4036879859511137, 0.28455771654896933, 0.4433466874724803, 0.3062109150023652, 0.30948759509207185, 0.35798530492856273, 0.39955522676159905, 0.4022059774588835, 0.3947584458012608, 0.4920010694986479]
2022-01-14 22:21:55:INFO:-------------Training local models-------------
2022-01-14 22:22:11:INFO:-------------Aggregating local models-------------
2022-01-14 22:22:11:INFO:-------------Round number: 9-------------
2022-01-14 22:22:11:INFO:-------------Sending models-------------
2022-01-14 22:22:11:INFO:-------------Evaluating models-------------
2022-01-14 22:22:11:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:22:11:INFO:Accuracy = [0.8319199826049141, 0.8860621874320505, 0.8606218743205044, 0.8819308545335942, 0.8686671015438139, 0.8710589258534464, 0.8610567514677103, 0.8517068928027832, 0.8841052402696238, 0.8493150684931506]
2022-01-14 22:22:11:INFO:Loss = [0.40622500841515746, 0.2678729356488302, 0.44266713668648366, 0.2995163976150227, 0.29932449010463447, 0.3473255727039158, 0.3939310078126214, 0.3940102586103107, 0.38998198011417406, 0.4849274436744575]
2022-01-14 22:22:11:INFO:-------------Training local models-------------
2022-01-14 22:22:27:INFO:-------------Aggregating local models-------------
2022-01-14 22:22:28:INFO:-------------Round number: 10-------------
2022-01-14 22:22:28:INFO:-------------Sending models-------------
2022-01-14 22:22:28:INFO:-------------Evaluating models-------------
2022-01-14 22:22:28:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:22:28:INFO:Accuracy = [0.8282235268536638, 0.8912807131985214, 0.8593172428788867, 0.8814959773863883, 0.8717112415742553, 0.8699717329854316, 0.862796260056534, 0.852794085670798, 0.8841052402696238, 0.8543161556860187]
2022-01-14 22:22:28:INFO:Loss = [0.40871856222344327, 0.25381309536102836, 0.44219473315450253, 0.29418641990963973, 0.29085538632945795, 0.33951914203937456, 0.38924307834335153, 0.38741157051223624, 0.3865587183817651, 0.47944454437599254]
2022-01-14 22:22:28:INFO:-------------Training local models-------------
2022-01-14 22:22:44:INFO:-------------Aggregating local models-------------
2022-01-14 22:22:45:INFO:-------------Round number: 11-------------
2022-01-14 22:22:45:INFO:-------------Sending models-------------
2022-01-14 22:22:45:INFO:-------------Evaluating models-------------
2022-01-14 22:22:45:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:22:45:INFO:Accuracy = [0.8203957382039574, 0.8954120460969776, 0.8593172428788867, 0.8817134159599913, 0.8738856273102849, 0.868014785823005, 0.8625788214829311, 0.8547510328332246, 0.8841052402696238, 0.8569254185692542]
2022-01-14 22:22:45:INFO:Loss = [0.41095066324285845, 0.24193792781243995, 0.4417614956919179, 0.2898191799054088, 0.2837183636956032, 0.33384079137336276, 0.3852207669548838, 0.38196561695344844, 0.3841011227823585, 0.47517974599491164]
2022-01-14 22:22:45:INFO:-------------Training local models-------------
2022-01-14 22:23:01:INFO:-------------Aggregating local models-------------
2022-01-14 22:23:01:INFO:-------------Round number: 12-------------
2022-01-14 22:23:01:INFO:-------------Sending models-------------
2022-01-14 22:23:01:INFO:-------------Evaluating models-------------
2022-01-14 22:23:01:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:23:01:INFO:Accuracy = [0.8166992824527071, 0.8995433789954338, 0.8619265057621222, 0.8825831702544031, 0.8756251358991085, 0.8669275929549902, 0.8623613829093281, 0.8564905414220483, 0.8841052402696238, 0.8582300500108719]
2022-01-14 22:23:01:INFO:Loss = [0.4127953193034223, 0.23187810439247072, 0.4413359516323954, 0.2861239892172612, 0.27767469728171945, 0.3297270047708222, 0.38170841455809523, 0.3773790459470772, 0.38235528566274135, 0.47186463887317853]
2022-01-14 22:23:01:INFO:-------------Training local models-------------
2022-01-14 22:23:17:INFO:-------------Aggregating local models-------------
2022-01-14 22:23:18:INFO:-------------Round number: 13-------------
2022-01-14 22:23:18:INFO:-------------Sending models-------------
2022-01-14 22:23:18:INFO:-------------Evaluating models-------------
2022-01-14 22:23:18:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:23:18:INFO:Accuracy = [0.8140900195694716, 0.9017177647314634, 0.8636660143509458, 0.883235485975212, 0.8788867145031528, 0.8643183300717547, 0.8641008914981517, 0.8584474885844748, 0.8841052402696238, 0.8595346814524897]
2022-01-14 22:23:18:INFO:Loss = [0.4141609799088499, 0.22331864673321916, 0.4408845869728303, 0.28287533306913415, 0.2725169161210296, 0.3267528292728873, 0.3785788758580313, 0.37339546440280996, 0.3810958434871367, 0.46924540401477094]
2022-01-14 22:23:18:INFO:-------------Training local models-------------
2022-01-14 22:23:34:INFO:-------------Aggregating local models-------------
2022-01-14 22:23:35:INFO:-------------Round number: 14-------------
2022-01-14 22:23:35:INFO:-------------Sending models-------------
2022-01-14 22:23:35:INFO:-------------Evaluating models-------------
2022-01-14 22:23:35:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:23:35:INFO:Accuracy = [0.8106110023918243, 0.9023700804522722, 0.8658404000869754, 0.8845401174168297, 0.8812785388127854, 0.8638834529245488, 0.8651880843661666, 0.8610567514677103, 0.8841052402696238, 0.8601869971732985]
2022-01-14 22:23:35:INFO:Loss = [0.4150142275445183, 0.21600489185780375, 0.4404036772096577, 0.27992608965163723, 0.2680847252371605, 0.32461007861033725, 0.3757448786153586, 0.36986830587648495, 0.3801845212926297, 0.46713845712436713]
2022-01-14 22:23:35:INFO:-------------Training local models-------------
2022-01-14 22:23:51:INFO:-------------Aggregating local models-------------
2022-01-14 22:23:51:INFO:-------------Round number: 15-------------
2022-01-14 22:23:51:INFO:-------------Sending models-------------
2022-01-14 22:23:51:INFO:-------------Evaluating models-------------
2022-01-14 22:23:51:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:23:51:INFO:Accuracy = [0.8110458795390302, 0.903457273320287, 0.8669275929549902, 0.8860621874320505, 0.8821482931071972, 0.8614916286149162, 0.8669275929549902, 0.8634485757773429, 0.8841052402696238, 0.8604044357469015]
2022-01-14 22:23:51:INFO:Loss = [0.41537630808928294, 0.20973650644107872, 0.43987790075403943, 0.277186373487349, 0.2642478803523042, 0.32308483053408654, 0.3731332635715568, 0.36665048143931933, 0.3794990844771859, 0.46538350743487245]
2022-01-14 22:23:51:INFO:-------------Training local models-------------
2022-01-14 22:24:07:INFO:-------------Aggregating local models-------------
2022-01-14 22:24:08:INFO:-------------Round number: 16-------------
2022-01-14 22:24:08:INFO:-------------Sending models-------------
2022-01-14 22:24:08:INFO:-------------Evaluating models-------------
2022-01-14 22:24:08:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:24:08:INFO:Accuracy = [0.812133072407045, 0.9030223961730811, 0.8673624701021961, 0.8873668188736682, 0.883235485975212, 0.8599695585996956, 0.867797347249402, 0.8649706457925636, 0.8841052402696238, 0.8606218743205044]
2022-01-14 22:24:08:INFO:Loss = [0.4152672601681284, 0.204349756474131, 0.43931627170140036, 0.2745955616420418, 0.2609014534944303, 0.32202615002427387, 0.3707001848943381, 0.36367522634715277, 0.3789667693966326, 0.46385242468648097]
2022-01-14 22:24:08:INFO:-------------Training local models-------------
2022-01-14 22:24:24:INFO:-------------Aggregating local models-------------
2022-01-14 22:24:25:INFO:-------------Round number: 17-------------
2022-01-14 22:24:25:INFO:-------------Sending models-------------
2022-01-14 22:24:25:INFO:-------------Evaluating models-------------
2022-01-14 22:24:25:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:24:25:INFO:Accuracy = [0.8130028267014568, 0.903457273320287, 0.868232224396608, 0.8884540117416829, 0.8845401174168297, 0.8597521200260926, 0.8710589258534464, 0.8673624701021961, 0.8841052402696238, 0.8606218743205044]
2022-01-14 22:24:25:INFO:Loss = [0.41476864294710125, 0.19970158686064335, 0.4386988147803843, 0.27212697661324453, 0.25796465803999685, 0.32131806613318903, 0.3684133428356898, 0.3608842392755414, 0.3785327128476902, 0.4624666439593697]
2022-01-14 22:24:25:INFO:-------------Training local models-------------
2022-01-14 22:24:41:INFO:-------------Aggregating local models-------------
2022-01-14 22:24:41:INFO:-------------Round number: 18-------------
2022-01-14 22:24:41:INFO:-------------Sending models-------------
2022-01-14 22:24:41:INFO:-------------Evaluating models-------------
2022-01-14 22:24:41:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:24:41:INFO:Accuracy = [0.8151772124374864, 0.9023700804522722, 0.8688845401174168, 0.8914981517721243, 0.8854098717112415, 0.8588823657316808, 0.8723635572950641, 0.8688845401174168, 0.8841052402696238, 0.8606218743205044]
2022-01-14 22:24:41:INFO:Loss = [0.413940245708411, 0.1956773704865789, 0.4380179454024114, 0.26974882927307486, 0.25537222194047754, 0.32086192131136443, 0.36624175681124876, 0.3582354517613893, 0.37815126035424046, 0.4611533757047673]
2022-01-14 22:24:41:INFO:-------------Training local models-------------
2022-01-14 22:24:57:INFO:-------------Aggregating local models-------------
2022-01-14 22:24:58:INFO:-------------Round number: 19-------------
2022-01-14 22:24:58:INFO:-------------Sending models-------------
2022-01-14 22:24:58:INFO:-------------Evaluating models-------------
2022-01-14 22:24:58:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-14 22:24:58:INFO:Accuracy = [0.8182213524679278, 0.9023700804522722, 0.8693194172646227, 0.8943248532289628, 0.8862796260056534, 0.8582300500108719, 0.8745379430310937, 0.8712763644270494, 0.8841052402696238, 0.8608393128941074]
2022-01-14 22:24:58:INFO:Loss = [0.412822946003523, 0.19217914056547664, 0.4373021496682193, 0.26745233002749974, 0.2530669198539752, 0.32060124987914956, 0.36416966485774505, 0.35572599801244015, 0.37780828391371696, 0.4598806584879649]
2022-01-14 22:24:58:INFO:-------------Training local models-------------
2022-01-14 22:25:14:INFO:-------------Aggregating local models-------------
