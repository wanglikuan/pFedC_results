2022-01-12 10:55:16:INFO:-------------Round number: 0-------------
2022-01-12 10:55:16:INFO:-------------Sending models-------------
2022-01-12 10:55:16:INFO:-------------Evaluating models-------------
2022-01-12 10:55:16:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 10:55:16:INFO:Accuracy = [0.901010101010101, 0.8868686868686869, 0.896969696969697, 0.898989898989899, 0.901010101010101, 0.08888888888888889, 0.09494949494949495, 0.10303030303030303, 0.09696969696969697, 0.898989898989899]
2022-01-12 10:55:16:INFO:Loss = [0.6694116484637213, 0.653408883798002, 0.6615643211988488, 0.6542965058425461, 0.6641762230733428, 0.7379018910304465, 0.7407228308795678, 0.7419946313205391, 0.7473327146335081, 0.669854687109138]
2022-01-12 10:55:16:INFO:-------------Training local models-------------
2022-01-12 11:00:03:INFO:-------------updating local masks-------------
2022-01-12 11:00:03:INFO:-------------Aggregating local models-------------
2022-01-12 11:00:04:INFO:-------------Round number: 1-------------
2022-01-12 11:00:04:INFO:-------------Sending models-------------
2022-01-12 11:00:05:INFO:-------------Evaluating models-------------
2022-01-12 11:00:05:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-12 11:00:05:INFO:Accuracy = [0.9707070707070707, 0.9535353535353536, 0.897979797979798, 0.897979797979798, 0.9616161616161616, 0.9570707070707071, 0.9252525252525252, 0.9262626262626262, 0.9217171717171717, 0.9065656565656566]
2022-01-12 11:00:05:INFO:Loss = [0.07262696149615533, 0.09477750308402447, 0.1951098732824315, 0.1919002569452248, 0.14834374393656324, 0.15541892897906817, 0.15501992793829, 0.14759906926874372, 0.18349696431271356, 0.21461993114049124]
2022-01-12 11:00:05:INFO:-------------Training local models-------------
2022-01-12 11:04:52:INFO:-------------updating local masks-------------
