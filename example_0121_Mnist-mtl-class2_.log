2022-01-21 17:10:02:INFO:-------------Round number: 0-------------
2022-01-21 17:10:02:INFO:-------------Sending models-------------
2022-01-21 17:10:02:INFO:-------------Evaluating models-------------
2022-01-21 17:10:02:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 17:10:02:INFO:Accuracy = [0.901010101010101, 0.8868686868686869, 0.896969696969697, 0.898989898989899, 0.901010101010101, 0.08888888888888889, 0.09494949494949495, 0.10303030303030303, 0.09696969696969697, 0.898989898989899]
2022-01-21 17:10:02:INFO:Loss = [0.6694116484637213, 0.653408883798002, 0.6615643211988488, 0.6542965058425461, 0.6641762230733428, 0.7379018910304465, 0.7407228308795678, 0.7419946313205391, 0.7473327146335081, 0.669854687109138]
2022-01-21 17:10:02:INFO:-------------Training local models-------------
2022-01-21 17:19:40:INFO:-------------Aggregating local models-------------
2022-01-21 17:19:41:INFO:-------------Round number: 1-------------
2022-01-21 17:19:41:INFO:-------------Sending models-------------
2022-01-21 17:19:41:INFO:-------------Evaluating models-------------
2022-01-21 17:19:42:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 17:19:42:INFO:Accuracy = [0.9247474747474748, 0.9252525252525252, 0.897979797979798, 0.897979797979798, 0.9207070707070707, 0.9106060606060606, 0.9035353535353535, 0.9035353535353535, 0.9202020202020202, 0.9363636363636364]
2022-01-21 17:19:42:INFO:Loss = [0.1527403525203805, 0.19343576087860972, 0.24620499422096392, 0.22797694781541147, 0.21598888189164978, 0.23222373723701545, 0.22704537375359748, 0.22633104402844728, 0.21572900662584363, 0.2964766114714998]
2022-01-21 17:19:42:INFO:-------------Training local models-------------
2022-01-21 17:29:21:INFO:-------------Aggregating local models-------------
2022-01-21 17:29:22:INFO:-------------Round number: 2-------------
2022-01-21 17:29:22:INFO:-------------Sending models-------------
2022-01-21 17:29:23:INFO:-------------Evaluating models-------------
2022-01-21 17:29:23:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 17:29:23:INFO:Accuracy = [0.9606060606060606, 0.9474747474747475, 0.9040404040404041, 0.9030303030303031, 0.9585858585858585, 0.9393939393939394, 0.9191919191919192, 0.9267676767676768, 0.9222222222222223, 0.9202020202020202]
2022-01-21 17:29:23:INFO:Loss = [0.07412150592138671, 0.09611789189594223, 0.1791544806449721, 0.17304651239908048, 0.13213449307221148, 0.1426662944292537, 0.1409472687739051, 0.13287169865515985, 0.1564289192540919, 0.19168235513903764]
2022-01-21 17:29:23:INFO:-------------Training local models-------------
2022-01-21 17:39:02:INFO:-------------Aggregating local models-------------
2022-01-21 17:39:03:INFO:-------------Round number: 3-------------
2022-01-21 17:39:03:INFO:-------------Sending models-------------
2022-01-21 17:39:04:INFO:-------------Evaluating models-------------
2022-01-21 17:39:04:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 17:39:04:INFO:Accuracy = [0.9873737373737373, 0.9777777777777777, 0.9121212121212121, 0.9126262626262627, 0.9727272727272728, 0.9696969696969697, 0.955050505050505, 0.9585858585858585, 0.9424242424242424, 0.9227272727272727]
2022-01-21 17:39:04:INFO:Loss = [0.04353148717811858, 0.05825779003918999, 0.14908107417503919, 0.14456867255609143, 0.09082201977831904, 0.09977893422562346, 0.09386535410503527, 0.0862153790012764, 0.12546790546627076, 0.15079034869253372]
2022-01-21 17:39:04:INFO:-------------Training local models-------------
2022-01-21 17:48:47:INFO:-------------Aggregating local models-------------
2022-01-21 17:48:49:INFO:-------------Round number: 4-------------
2022-01-21 17:48:49:INFO:-------------Sending models-------------
2022-01-21 17:48:49:INFO:-------------Evaluating models-------------
2022-01-21 17:48:49:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 17:48:49:INFO:Accuracy = [0.9954545454545455, 0.9924242424242424, 0.9202020202020202, 0.9217171717171717, 0.9833333333333333, 0.9818181818181818, 0.9702020202020202, 0.9732323232323232, 0.954040404040404, 0.9388888888888889]
2022-01-21 17:48:49:INFO:Loss = [0.02753634178438318, 0.03747290530115027, 0.12895109933269483, 0.12526186836575925, 0.06482327113338426, 0.07166917300201021, 0.06753169972116758, 0.06187860623861644, 0.10566821171716326, 0.12498123803060747]
2022-01-21 17:48:49:INFO:-------------Training local models-------------
2022-01-21 17:58:40:INFO:-------------Aggregating local models-------------
2022-01-21 17:58:41:INFO:-------------Round number: 5-------------
2022-01-21 17:58:41:INFO:-------------Sending models-------------
2022-01-21 17:58:42:INFO:-------------Evaluating models-------------
2022-01-21 17:58:42:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 17:58:42:INFO:Accuracy = [0.9984848484848485, 0.9974747474747475, 0.9338383838383838, 0.9343434343434344, 0.990909090909091, 0.9893939393939394, 0.9772727272727273, 0.9868686868686869, 0.9580808080808081, 0.9525252525252526]
2022-01-21 17:58:42:INFO:Loss = [0.018953105067008768, 0.025845968826777404, 0.11321219558412482, 0.11025939870618678, 0.04872905478978558, 0.053646755735436924, 0.05236772219838593, 0.04785837024224527, 0.09278525129434502, 0.10864051222175623]
2022-01-21 17:58:42:INFO:-------------Training local models-------------
2022-01-21 18:08:26:INFO:-------------Aggregating local models-------------
2022-01-21 18:08:27:INFO:-------------Round number: 6-------------
2022-01-21 18:08:27:INFO:-------------Sending models-------------
2022-01-21 18:08:28:INFO:-------------Evaluating models-------------
2022-01-21 18:08:28:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 18:08:28:INFO:Accuracy = [0.9994949494949495, 0.9984848484848485, 0.9424242424242424, 0.943939393939394, 0.9944444444444445, 0.9934343434343434, 0.9893939393939394, 0.9924242424242424, 0.9611111111111111, 0.9585858585858585]
2022-01-21 18:08:28:INFO:Loss = [0.014052946042831554, 0.01908501727686433, 0.10073245003974686, 0.09833339546028656, 0.038493724956266545, 0.04196917453990671, 0.04224070512291016, 0.03842656300947037, 0.0832470561366239, 0.09746179767535068]
2022-01-21 18:08:28:INFO:-------------Training local models-------------
2022-01-21 18:18:09:INFO:-------------Aggregating local models-------------
2022-01-21 18:18:10:INFO:-------------Round number: 7-------------
2022-01-21 18:18:10:INFO:-------------Sending models-------------
2022-01-21 18:18:11:INFO:-------------Evaluating models-------------
2022-01-21 18:18:11:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 18:18:11:INFO:Accuracy = [1.0, 1.0, 0.9474747474747475, 0.9484848484848485, 0.9949494949494949, 0.9944444444444445, 0.9929292929292929, 0.9939393939393939, 0.9626262626262626, 0.9616161616161616]
2022-01-21 18:18:11:INFO:Loss = [0.011013244179129187, 0.014878028310774213, 0.09064690744227405, 0.08868604641721697, 0.031661126248607875, 0.03414989583758106, 0.03478877903947094, 0.03157512289025077, 0.07555082754200827, 0.08875522879040518]
2022-01-21 18:18:11:INFO:-------------Training local models-------------
2022-01-21 18:27:52:INFO:-------------Aggregating local models-------------
2022-01-21 18:27:54:INFO:-------------Round number: 8-------------
2022-01-21 18:27:54:INFO:-------------Sending models-------------
2022-01-21 18:27:54:INFO:-------------Evaluating models-------------
2022-01-21 18:27:54:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 18:27:54:INFO:Accuracy = [1.0, 1.0, 0.952020202020202, 0.9525252525252526, 0.9949494949494949, 0.9949494949494949, 0.9949494949494949, 0.9949494949494949, 0.9646464646464646, 0.9631313131313132]
2022-01-21 18:27:54:INFO:Loss = [0.008982346492003405, 0.012075582715257004, 0.08225141732863532, 0.0806957515742985, 0.026840198490735746, 0.02866364459232592, 0.029175316300413645, 0.026519320949011323, 0.06915109093955688, 0.08148252740849252]
2022-01-21 18:27:54:INFO:-------------Training local models-------------
2022-01-21 18:37:35:INFO:-------------Aggregating local models-------------
2022-01-21 18:37:37:INFO:-------------Round number: 9-------------
2022-01-21 18:37:37:INFO:-------------Sending models-------------
2022-01-21 18:37:37:INFO:-------------Evaluating models-------------
2022-01-21 18:37:37:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 18:37:37:INFO:Accuracy = [1.0, 1.0, 0.9555555555555556, 0.956060606060606, 0.9949494949494949, 0.9949494949494949, 0.9949494949494949, 0.9954545454545455, 0.9671717171717171, 0.9646464646464646]
2022-01-21 18:37:37:INFO:Loss = [0.007545024777363958, 0.01010128793117327, 0.07516736190856053, 0.07401207108209333, 0.023284953668292592, 0.02464999696213371, 0.024949598841891258, 0.02277161997741187, 0.06375542909112428, 0.07526946436881907]
2022-01-21 18:37:37:INFO:-------------Training local models-------------
2022-01-21 18:47:14:INFO:-------------Aggregating local models-------------
2022-01-21 18:47:15:INFO:-------------Round number: 10-------------
2022-01-21 18:47:15:INFO:-------------Sending models-------------
2022-01-21 18:47:16:INFO:-------------Evaluating models-------------
2022-01-21 18:47:16:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 18:47:16:INFO:Accuracy = [1.0, 1.0, 0.9626262626262626, 0.9641414141414142, 0.9949494949494949, 0.9954545454545455, 0.9954545454545455, 0.9974747474747475, 0.9712121212121212, 0.9651515151515152]
2022-01-21 18:47:16:INFO:Loss = [0.006480746659317355, 0.008646552795938197, 0.06912615151683132, 0.06835051500204671, 0.020567056395138752, 0.021606272559614753, 0.02175153622414324, 0.019956342391613896, 0.059104377909012566, 0.06986368787292664]
2022-01-21 18:47:16:INFO:-------------Training local models-------------
2022-01-21 18:56:44:INFO:-------------Aggregating local models-------------
2022-01-21 18:56:46:INFO:-------------Round number: 11-------------
2022-01-21 18:56:46:INFO:-------------Sending models-------------
2022-01-21 18:56:46:INFO:-------------Evaluating models-------------
2022-01-21 18:56:46:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 18:56:46:INFO:Accuracy = [1.0, 1.0, 0.9676767676767677, 0.9676767676767677, 0.996969696969697, 0.9964646464646465, 0.996969696969697, 0.9974747474747475, 0.9747474747474747, 0.9661616161616161]
2022-01-21 18:56:46:INFO:Loss = [0.005664587552180618, 0.00753505735915634, 0.06404520781504078, 0.06360662628449981, 0.018432626960169396, 0.019235484155966206, 0.019293455582175573, 0.017795819629467625, 0.05505264736312169, 0.06510022677598178]
2022-01-21 18:56:46:INFO:-------------Training local models-------------
2022-01-21 19:06:15:INFO:-------------Aggregating local models-------------
2022-01-21 19:06:16:INFO:-------------Round number: 12-------------
2022-01-21 19:06:16:INFO:-------------Sending models-------------
2022-01-21 19:06:16:INFO:-------------Evaluating models-------------
2022-01-21 19:06:17:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 19:06:17:INFO:Accuracy = [1.0, 1.0, 0.9707070707070707, 0.9702020202020202, 0.9974747474747475, 0.996969696969697, 0.9974747474747475, 0.9974747474747475, 0.9772727272727273, 0.9681818181818181]
2022-01-21 19:06:17:INFO:Loss = [0.005020366891227296, 0.006660530792938479, 0.05980976014972766, 0.05965629066765424, 0.016715848271798513, 0.017343553590777595, 0.017366830035564936, 0.016100995579685643, 0.05151579332005261, 0.06084946859010608]
2022-01-21 19:06:17:INFO:-------------Training local models-------------
2022-01-21 19:15:45:INFO:-------------Aggregating local models-------------
2022-01-21 19:15:46:INFO:-------------Round number: 13-------------
2022-01-21 19:15:46:INFO:-------------Sending models-------------
2022-01-21 19:15:46:INFO:-------------Evaluating models-------------
2022-01-21 19:15:46:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 19:15:46:INFO:Accuracy = [1.0, 1.0, 0.9737373737373738, 0.9732323232323232, 0.997979797979798, 0.9974747474747475, 0.996969696969697, 0.9974747474747475, 0.9782828282828283, 0.9722222222222222]
2022-01-21 19:15:46:INFO:Loss = [0.004500287409970005, 0.005955957714144865, 0.056273803399652926, 0.05635454329190778, 0.01531054090872828, 0.015805273571650198, 0.015826184456818736, 0.014741235751158327, 0.048439575549017524, 0.05702338308028905]
2022-01-21 19:15:46:INFO:-------------Training local models-------------
2022-01-21 19:25:16:INFO:-------------Aggregating local models-------------
2022-01-21 19:25:17:INFO:-------------Round number: 14-------------
2022-01-21 19:25:17:INFO:-------------Sending models-------------
2022-01-21 19:25:17:INFO:-------------Evaluating models-------------
2022-01-21 19:25:17:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 19:25:17:INFO:Accuracy = [1.0, 1.0, 0.9752525252525253, 0.9747474747474747, 0.997979797979798, 0.9974747474747475, 0.996969696969697, 0.9974747474747475, 0.9823232323232324, 0.9747474747474747]
2022-01-21 19:25:17:INFO:Loss = [0.004072428027384284, 0.005376982996463681, 0.05331935668915376, 0.053590853844475025, 0.014142694213645736, 0.014534420835417507, 0.014568355703794614, 0.013626399629683506, 0.04578289850894979, 0.053578894190823026]
2022-01-21 19:25:17:INFO:-------------Training local models-------------
2022-01-21 19:32:57:INFO:-------------Aggregating local models-------------
2022-01-21 19:32:58:INFO:-------------Round number: 15-------------
2022-01-21 19:32:58:INFO:-------------Sending models-------------
2022-01-21 19:32:58:INFO:-------------Evaluating models-------------
2022-01-21 19:32:58:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 19:32:58:INFO:Accuracy = [1.0, 1.0, 0.9777777777777777, 0.9752525252525253, 0.997979797979798, 0.997979797979798, 0.996969696969697, 0.9974747474747475, 0.9828282828282828, 0.9787878787878788]
2022-01-21 19:32:58:INFO:Loss = [0.0037146772388803933, 0.004893588224270691, 0.050830962750008285, 0.05125486738754188, 0.013160335742298166, 0.013471323588784816, 0.013522329477894925, 0.0126954422204172, 0.04350181477578125, 0.050494265917855]
2022-01-21 19:32:58:INFO:-------------Training local models-------------
2022-01-21 19:37:41:INFO:-------------Aggregating local models-------------
2022-01-21 19:37:42:INFO:-------------Round number: 16-------------
2022-01-21 19:37:42:INFO:-------------Sending models-------------
2022-01-21 19:37:42:INFO:-------------Evaluating models-------------
2022-01-21 19:37:42:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 19:37:42:INFO:Accuracy = [1.0, 1.0, 0.9777777777777777, 0.9767676767676767, 0.997979797979798, 0.997979797979798, 0.996969696969697, 0.9974747474747475, 0.9843434343434343, 0.9803030303030303]
2022-01-21 19:37:42:INFO:Loss = [0.0034117592576858257, 0.004484721335771757, 0.04872582107494265, 0.04927409426489965, 0.012324545729738975, 0.012571326533898081, 0.01263888736416861, 0.01190638171189648, 0.04154737373557344, 0.04775097157470729]
2022-01-21 19:37:42:INFO:-------------Training local models-------------
2022-01-21 19:42:25:INFO:-------------Aggregating local models-------------
2022-01-21 19:42:25:INFO:-------------Round number: 17-------------
2022-01-21 19:42:25:INFO:-------------Sending models-------------
2022-01-21 19:42:25:INFO:-------------Evaluating models-------------
2022-01-21 19:42:25:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 19:42:25:INFO:Accuracy = [1.0, 1.0, 0.9792929292929293, 0.9792929292929293, 0.9984848484848485, 0.9984848484848485, 0.996969696969697, 0.9974747474747475, 0.9848484848484849, 0.9818181818181818]
2022-01-21 19:42:25:INFO:Loss = [0.0031531172913159336, 0.004135814995118041, 0.04691354858557014, 0.04755529301562799, 0.011603764040009625, 0.011798544537775499, 0.011884867403179412, 0.011230286671174455, 0.03986902225078666, 0.045329074940871746]
2022-01-21 19:42:25:INFO:-------------Training local models-------------
2022-01-21 19:47:09:INFO:-------------Aggregating local models-------------
2022-01-21 19:47:09:INFO:-------------Round number: 18-------------
2022-01-21 19:47:09:INFO:-------------Sending models-------------
2022-01-21 19:47:09:INFO:-------------Evaluating models-------------
2022-01-21 19:47:10:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 19:47:10:INFO:Accuracy = [1.0, 1.0, 0.9797979797979798, 0.9797979797979798, 0.998989898989899, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9863636363636363, 0.9823232323232324]
2022-01-21 19:47:10:INFO:Loss = [0.0029295190577595166, 0.0038342702398876274, 0.04533459844868489, 0.04604701136805222, 0.01097738320133449, 0.011129800593981701, 0.011233597928719863, 0.010644343778984315, 0.038432093248301304, 0.043211643791724014]
2022-01-21 19:47:10:INFO:-------------Training local models-------------
2022-01-21 19:51:53:INFO:-------------Aggregating local models-------------
2022-01-21 19:51:53:INFO:-------------Round number: 19-------------
2022-01-21 19:51:53:INFO:-------------Sending models-------------
2022-01-21 19:51:53:INFO:-------------Evaluating models-------------
2022-01-21 19:51:53:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 19:51:53:INFO:Accuracy = [1.0, 1.0, 0.9803030303030303, 0.9803030303030303, 0.998989898989899, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9863636363636363, 0.9833333333333333]
2022-01-21 19:51:53:INFO:Loss = [0.0027350189856158317, 0.003572042547639652, 0.04393985528713345, 0.04470076437486421, 0.010430707314809858, 0.010547919659806249, 0.010665861485360455, 0.010132102909736922, 0.037179028984202445, 0.041351349688560766]
2022-01-21 19:51:53:INFO:-------------Training local models-------------
2022-01-21 19:56:36:INFO:-------------Aggregating local models-------------
2022-01-21 19:56:37:INFO:-------------Round number: 20-------------
2022-01-21 19:56:37:INFO:-------------Sending models-------------
2022-01-21 19:56:37:INFO:-------------Evaluating models-------------
2022-01-21 19:56:37:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 19:56:37:INFO:Accuracy = [1.0, 1.0, 0.9808080808080808, 0.9813131313131314, 0.998989898989899, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9863636363636363, 0.9848484848484849]
2022-01-21 19:56:37:INFO:Loss = [0.002564211844921117, 0.003341787049797895, 0.04269656853807233, 0.04349364434365087, 0.009947445560814084, 0.010036515332504136, 0.01016645261095049, 0.009680194724874448, 0.03607735814674548, 0.039718292728436855]
2022-01-21 19:56:37:INFO:-------------Training local models-------------
2022-01-21 20:01:20:INFO:-------------Aggregating local models-------------
2022-01-21 20:01:21:INFO:-------------Round number: 21-------------
2022-01-21 20:01:21:INFO:-------------Sending models-------------
2022-01-21 20:01:21:INFO:-------------Evaluating models-------------
2022-01-21 20:01:21:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 20:01:21:INFO:Accuracy = [1.0, 1.0, 0.9813131313131314, 0.9818181818181818, 0.998989898989899, 0.9994949494949495, 0.9974747474747475, 0.9974747474747475, 0.9863636363636363, 0.9853535353535353]
2022-01-21 20:01:21:INFO:Loss = [0.00241328392851324, 0.0031383917097095163, 0.04157373954226984, 0.04239910023626924, 0.009519514019954997, 0.00958497726376553, 0.009724578763526745, 0.009279386101380542, 0.035103497870545425, 0.038283367504937826]
2022-01-21 20:01:21:INFO:-------------Training local models-------------
2022-01-21 20:06:04:INFO:-------------Aggregating local models-------------
2022-01-21 20:06:05:INFO:-------------Round number: 22-------------
2022-01-21 20:06:05:INFO:-------------Sending models-------------
2022-01-21 20:06:05:INFO:-------------Evaluating models-------------
2022-01-21 20:06:05:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 20:06:05:INFO:Accuracy = [1.0, 1.0, 0.9818181818181818, 0.9823232323232324, 0.998989898989899, 0.9994949494949495, 0.9974747474747475, 0.9974747474747475, 0.9873737373737373, 0.9858585858585859]
2022-01-21 20:06:05:INFO:Loss = [0.002279083331034994, 0.0029575278724701323, 0.04055027895274271, 0.041395412080674585, 0.009135459123258397, 0.009181355150220116, 0.009330434454419776, 0.008921307458865957, 0.03423311655593959, 0.03701583740609813]
2022-01-21 20:06:05:INFO:-------------Training local models-------------
2022-01-21 20:10:48:INFO:-------------Aggregating local models-------------
2022-01-21 20:10:49:INFO:-------------Round number: 23-------------
2022-01-21 20:10:49:INFO:-------------Sending models-------------
2022-01-21 20:10:49:INFO:-------------Evaluating models-------------
2022-01-21 20:10:49:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 20:10:49:INFO:Accuracy = [1.0, 1.0, 0.9823232323232324, 0.9823232323232324, 0.9994949494949495, 0.9994949494949495, 0.9974747474747475, 0.9974747474747475, 0.9878787878787879, 0.9863636363636363]
2022-01-21 20:10:49:INFO:Loss = [0.0021593839485013642, 0.002796194931483978, 0.03961247399925887, 0.040468311857587494, 0.008789904561663115, 0.00881930086439072, 0.008977351802832805, 0.008600139499285066, 0.03346121414038182, 0.03590194523318922]
2022-01-21 20:10:49:INFO:-------------Training local models-------------
2022-01-21 20:15:32:INFO:-------------Aggregating local models-------------
2022-01-21 20:15:32:INFO:-------------Round number: 24-------------
2022-01-21 20:15:32:INFO:-------------Sending models-------------
2022-01-21 20:15:32:INFO:-------------Evaluating models-------------
2022-01-21 20:15:32:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 20:15:32:INFO:Accuracy = [1.0, 1.0, 0.9828282828282828, 0.9823232323232324, 0.9994949494949495, 0.9994949494949495, 0.9974747474747475, 0.9974747474747475, 0.9883838383838384, 0.9863636363636363]
2022-01-21 20:15:32:INFO:Loss = [0.0020515279683744245, 0.002650793819471305, 0.03876142761449716, 0.03962421621247565, 0.008474774648471572, 0.008491078482297274, 0.008657906566260882, 0.008309030426828417, 0.03277182808234662, 0.03492156535564455]
2022-01-21 20:15:32:INFO:-------------Training local models-------------
2022-01-21 20:20:15:INFO:-------------Aggregating local models-------------
2022-01-21 20:20:16:INFO:-------------Round number: 25-------------
2022-01-21 20:20:16:INFO:-------------Sending models-------------
2022-01-21 20:20:16:INFO:-------------Evaluating models-------------
2022-01-21 20:20:16:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 20:20:16:INFO:Accuracy = [1.0, 1.0, 0.9833333333333333, 0.9833333333333333, 0.9994949494949495, 0.9994949494949495, 0.9974747474747475, 0.9974747474747475, 0.9878787878787879, 0.9878787878787879]
2022-01-21 20:20:16:INFO:Loss = [0.0019546838914546315, 0.0025204159599120936, 0.03796714430354768, 0.038832310434126424, 0.008188363129158112, 0.008193124880067031, 0.008368727224804003, 0.008045269640680282, 0.03214364867222556, 0.034043752843254796]
2022-01-21 20:20:16:INFO:-------------Training local models-------------
2022-01-21 20:24:59:INFO:-------------Aggregating local models-------------
2022-01-21 20:25:00:INFO:-------------Round number: 26-------------
2022-01-21 20:25:00:INFO:-------------Sending models-------------
2022-01-21 20:25:00:INFO:-------------Evaluating models-------------
2022-01-21 20:25:00:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 20:25:00:INFO:Accuracy = [1.0, 1.0, 0.9838383838383838, 0.9843434343434343, 0.9994949494949495, 0.9994949494949495, 0.9974747474747475, 0.9974747474747475, 0.9878787878787879, 0.9878787878787879]
2022-01-21 20:25:00:INFO:Loss = [0.0018670136382541093, 0.002402404935120939, 0.03723056348861781, 0.03809268958536238, 0.007926548418426955, 0.00792138417534509, 0.008106104652379697, 0.007805546112965635, 0.03156913716040362, 0.03325616821969037]
2022-01-21 20:25:00:INFO:-------------Training local models-------------
2022-01-21 20:29:43:INFO:-------------Aggregating local models-------------
2022-01-21 20:29:43:INFO:-------------Round number: 27-------------
2022-01-21 20:29:43:INFO:-------------Sending models-------------
2022-01-21 20:29:43:INFO:-------------Evaluating models-------------
2022-01-21 20:29:44:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 20:29:44:INFO:Accuracy = [1.0, 1.0, 0.9838383838383838, 0.9843434343434343, 0.9994949494949495, 0.9994949494949495, 0.9974747474747475, 0.9974747474747475, 0.9883838383838384, 0.9878787878787879]
2022-01-21 20:29:44:INFO:Loss = [0.00178737484788548, 0.0022952599626156795, 0.036549864276964925, 0.0374056833093375, 0.007685332970096638, 0.007671658579835426, 0.007865954277010381, 0.007586002382492432, 0.03104757780861521, 0.03255369622337354]
2022-01-21 20:29:44:INFO:-------------Training local models-------------
2022-01-21 20:34:26:INFO:-------------Aggregating local models-------------
2022-01-21 20:34:27:INFO:-------------Round number: 28-------------
2022-01-21 20:34:27:INFO:-------------Sending models-------------
2022-01-21 20:34:27:INFO:-------------Evaluating models-------------
2022-01-21 20:34:27:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 20:34:27:INFO:Accuracy = [1.0, 1.0, 0.9838383838383838, 0.9843434343434343, 0.9994949494949495, 0.9994949494949495, 0.9974747474747475, 0.9974747474747475, 0.9883838383838384, 0.9878787878787879]
2022-01-21 20:34:27:INFO:Loss = [0.0017148414376983183, 0.002197664309862761, 0.035916691447382985, 0.03676429768782676, 0.00746294979153482, 0.007442027690220386, 0.007645587862535107, 0.007384281950439661, 0.030569121010319007, 0.03192001980753801]
2022-01-21 20:34:27:INFO:-------------Training local models-------------
2022-01-21 20:39:17:INFO:-------------Aggregating local models-------------
2022-01-21 20:39:17:INFO:-------------Round number: 29-------------
2022-01-21 20:39:17:INFO:-------------Sending models-------------
2022-01-21 20:39:17:INFO:-------------Evaluating models-------------
2022-01-21 20:39:17:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 20:39:17:INFO:Accuracy = [1.0, 1.0, 0.9843434343434343, 0.9843434343434343, 0.9994949494949495, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9883838383838384, 0.9878787878787879]
2022-01-21 20:39:17:INFO:Loss = [0.0016483996334077668, 0.0021083005522601213, 0.03533205407108075, 0.03617648313242667, 0.007258670770460587, 0.0072313698559056975, 0.0074423895961977776, 0.0071981287477022055, 0.03014169383427405, 0.03135534248572323]
2022-01-21 20:39:17:INFO:-------------Training local models-------------
2022-01-21 20:44:19:INFO:-------------Aggregating local models-------------
2022-01-21 20:44:20:INFO:-------------Round number: 30-------------
2022-01-21 20:44:20:INFO:-------------Sending models-------------
2022-01-21 20:44:21:INFO:-------------Evaluating models-------------
2022-01-21 20:44:21:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 20:44:21:INFO:Accuracy = [1.0, 1.0, 0.9848484848484849, 0.9838383838383838, 0.9994949494949495, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9883838383838384, 0.9878787878787879]
2022-01-21 20:44:21:INFO:Loss = [0.0015874402942088893, 0.002026332212258377, 0.03478311413396803, 0.03562138083132852, 0.007069747270262186, 0.0070370045687858955, 0.007254823330297979, 0.007026091823813704, 0.029763363265216197, 0.03085561791236302]
2022-01-21 20:44:21:INFO:-------------Training local models-------------
2022-01-21 20:49:06:INFO:-------------Aggregating local models-------------
2022-01-21 20:49:06:INFO:-------------Round number: 31-------------
2022-01-21 20:49:06:INFO:-------------Sending models-------------
2022-01-21 20:49:06:INFO:-------------Evaluating models-------------
2022-01-21 20:49:07:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 20:49:07:INFO:Accuracy = [1.0, 1.0, 0.9853535353535353, 0.9843434343434343, 0.9994949494949495, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9883838383838384, 0.9883838383838384]
2022-01-21 20:49:07:INFO:Loss = [0.00153127630807711, 0.0019508390731502775, 0.03426381593056827, 0.03509408239074357, 0.006895075491951447, 0.006857833535115898, 0.007081072321953898, 0.006866563006468538, 0.02941447678621802, 0.030401837955904547]
2022-01-21 20:49:07:INFO:-------------Training local models-------------
2022-01-21 20:54:50:INFO:-------------Aggregating local models-------------
2022-01-21 20:54:51:INFO:-------------Round number: 32-------------
2022-01-21 20:54:51:INFO:-------------Sending models-------------
2022-01-21 20:54:51:INFO:-------------Evaluating models-------------
2022-01-21 20:54:52:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 20:54:52:INFO:Accuracy = [1.0, 1.0, 0.9853535353535353, 0.9848484848484849, 0.9994949494949495, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9883838383838384, 0.9888888888888889]
2022-01-21 20:54:52:INFO:Loss = [0.0014794596819035976, 0.0018811991524037722, 0.03378112350385918, 0.03460254719549002, 0.006731890896414619, 0.006690861531193021, 0.0069194948703910205, 0.006718151621893724, 0.029097348025577664, 0.029993590243446472]
2022-01-21 20:54:52:INFO:-------------Training local models-------------
2022-01-21 21:00:17:INFO:-------------Aggregating local models-------------
2022-01-21 21:00:17:INFO:-------------Round number: 33-------------
2022-01-21 21:00:17:INFO:-------------Sending models-------------
2022-01-21 21:00:17:INFO:-------------Evaluating models-------------
2022-01-21 21:00:17:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 21:00:17:INFO:Accuracy = [1.0, 1.0, 0.9853535353535353, 0.9843434343434343, 0.9994949494949495, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9883838383838384, 0.9888888888888889]
2022-01-21 21:00:17:INFO:Loss = [0.0014314670234108979, 0.001816725519533102, 0.033324363571679866, 0.034134485825482196, 0.006580677400379133, 0.006536480072011755, 0.006768649754913629, 0.00657936671444931, 0.02880791720096448, 0.029625152383982133]
2022-01-21 21:00:17:INFO:-------------Training local models-------------
2022-01-21 21:05:00:INFO:-------------Aggregating local models-------------
2022-01-21 21:05:01:INFO:-------------Round number: 34-------------
2022-01-21 21:05:01:INFO:-------------Sending models-------------
2022-01-21 21:05:01:INFO:-------------Evaluating models-------------
2022-01-21 21:05:01:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 21:05:01:INFO:Accuracy = [1.0, 1.0, 0.9858585858585859, 0.9848484848484849, 0.9994949494949495, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9878787878787879, 0.9888888888888889]
2022-01-21 21:05:01:INFO:Loss = [0.0013869247665100218, 0.001756889797039236, 0.03289907716215098, 0.03369851401722473, 0.006439565941290118, 0.006392913306450337, 0.006627518378699086, 0.006449355839507953, 0.028541805207501655, 0.029290591851064956]
2022-01-21 21:05:01:INFO:-------------Training local models-------------
2022-01-21 21:09:51:INFO:-------------Aggregating local models-------------
2022-01-21 21:09:51:INFO:-------------Round number: 35-------------
2022-01-21 21:09:51:INFO:-------------Sending models-------------
2022-01-21 21:09:52:INFO:-------------Evaluating models-------------
2022-01-21 21:09:52:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 21:09:52:INFO:Accuracy = [1.0, 1.0, 0.9858585858585859, 0.9853535353535353, 0.9994949494949495, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9878787878787879, 0.98989898989899]
2022-01-21 21:09:52:INFO:Loss = [0.0013455060730462498, 0.0017012864674501489, 0.03249575543636868, 0.03328379280916271, 0.0063072504775239695, 0.006258677328658064, 0.006495291308587037, 0.006327604473456935, 0.0282897186048333, 0.028977066566519417]
2022-01-21 21:09:52:INFO:-------------Training local models-------------
2022-01-21 21:14:34:INFO:-------------Aggregating local models-------------
2022-01-21 21:14:35:INFO:-------------Round number: 36-------------
2022-01-21 21:14:35:INFO:-------------Sending models-------------
2022-01-21 21:14:35:INFO:-------------Evaluating models-------------
2022-01-21 21:14:35:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 21:14:35:INFO:Accuracy = [1.0, 1.0, 0.9858585858585859, 0.9853535353535353, 0.9994949494949495, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9878787878787879, 0.98989898989899]
2022-01-21 21:14:35:INFO:Loss = [0.0013068758140801983, 0.0016494782768602064, 0.03211426981907065, 0.03289154734864294, 0.006184264374336856, 0.006134124967024716, 0.00637147309127172, 0.006213483502811281, 0.02805572749536136, 0.028689339586333407]
2022-01-21 21:14:35:INFO:-------------Training local models-------------
2022-01-21 21:19:18:INFO:-------------Aggregating local models-------------
2022-01-21 21:19:18:INFO:-------------Round number: 37-------------
2022-01-21 21:19:18:INFO:-------------Sending models-------------
2022-01-21 21:19:18:INFO:-------------Evaluating models-------------
2022-01-21 21:19:19:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 21:19:19:INFO:Accuracy = [1.0, 1.0, 0.9858585858585859, 0.9863636363636363, 0.9994949494949495, 0.998989898989899, 0.9974747474747475, 0.9974747474747475, 0.9878787878787879, 0.98989898989899]
2022-01-21 21:19:19:INFO:Loss = [0.0012707735472749753, 0.0016011196244484509, 0.031751490505948, 0.03251848445739009, 0.006069015325894467, 0.006017360037021901, 0.006255271611371427, 0.006106188728973403, 0.027833406922585745, 0.028417959853671928]
2022-01-21 21:19:19:INFO:-------------Training local models-------------
2022-01-21 21:24:01:INFO:-------------Aggregating local models-------------
2022-01-21 21:24:02:INFO:-------------Round number: 38-------------
2022-01-21 21:24:02:INFO:-------------Sending models-------------
2022-01-21 21:24:02:INFO:-------------Evaluating models-------------
2022-01-21 21:24:02:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 21:24:02:INFO:Accuracy = [1.0, 1.0, 0.9858585858585859, 0.9863636363636363, 0.9994949494949495, 0.998989898989899, 0.997979797979798, 0.9974747474747475, 0.9883838383838384, 0.98989898989899]
2022-01-21 21:24:02:INFO:Loss = [0.0012369907752733038, 0.0015559216581885892, 0.031407492752465495, 0.03216529327065207, 0.0059607879631235995, 0.00590786223209844, 0.006145821978931752, 0.006004912529856988, 0.027627218474376467, 0.028167923713794372]
2022-01-21 21:24:02:INFO:-------------Training local models-------------
2022-01-21 21:28:45:INFO:-------------Aggregating local models-------------
2022-01-21 21:28:45:INFO:-------------Round number: 39-------------
2022-01-21 21:28:45:INFO:-------------Sending models-------------
2022-01-21 21:28:46:INFO:-------------Evaluating models-------------
2022-01-21 21:28:46:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 21:28:46:INFO:Accuracy = [1.0, 1.0, 0.9858585858585859, 0.9863636363636363, 0.9994949494949495, 0.998989898989899, 0.997979797979798, 0.9974747474747475, 0.9883838383838384, 0.98989898989899]
2022-01-21 21:28:46:INFO:Loss = [0.0012053223736166738, 0.0015136089364379513, 0.031081290287693263, 0.031829155826750194, 0.00585833945505411, 0.005804308163325656, 0.006042621931107597, 0.005909273895939796, 0.027436800849123626, 0.027937303122944103]
2022-01-21 21:28:46:INFO:-------------Training local models-------------
2022-01-21 21:33:29:INFO:-------------Aggregating local models-------------
