2022-01-20 23:38:16:INFO:-------------Round number: 0-------------
2022-01-20 23:38:16:INFO:-------------Sending models-------------
2022-01-20 23:38:16:INFO:-------------Evaluating models-------------
2022-01-20 23:38:16:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-20 23:38:16:INFO:Accuracy = [1.0, 0.9117647058823529, 0.8921568627450981, 0.9019607843137255, 0.8725490196078431, 0.10784313725490197, 0.09803921568627451, 0.13725490196078433, 0.08823529411764706, 0.8529411764705882]
2022-01-20 23:38:16:INFO:Loss = [0.6533998180838192, 0.6523714655754613, 0.6669588223391888, 0.6574188412404528, 0.6633901531789818, 0.7376241175567403, 0.7413790629190558, 0.7380849543739768, 0.7445044283773384, 0.672025237013312]
2022-01-20 23:38:16:INFO:-------------Training local models-------------
2022-01-20 23:40:00:INFO:-------------Aggregating local models-------------
2022-01-20 23:40:01:INFO:-------------Round number: 1-------------
2022-01-20 23:40:01:INFO:-------------Sending models-------------
2022-01-20 23:40:01:INFO:-------------Evaluating models-------------
2022-01-20 23:40:01:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-20 23:40:01:INFO:Accuracy = [0.9995098039215686, 0.8772058823529412, 0.8375, 0.8708333333333333, 0.8134803921568627, 0.8654411764705883, 0.8884803921568627, 0.7291666666666666, 0.8678921568627451, 0.7355392156862746]
2022-01-20 23:40:01:INFO:Loss = [0.2248339906663579, 0.4924907346128249, 0.5036604264203239, 0.4449996238610908, 0.5108554233230796, 0.45628850541862787, 0.48227792130965813, 0.5998787235322536, 0.4206787407690403, 0.5459830939915835]
2022-01-20 23:40:01:INFO:-------------Training local models-------------
2022-01-20 23:41:46:INFO:-------------Aggregating local models-------------
2022-01-20 23:41:47:INFO:-------------Round number: 2-------------
2022-01-20 23:41:47:INFO:-------------Sending models-------------
2022-01-20 23:41:47:INFO:-------------Evaluating models-------------
2022-01-20 23:41:47:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-20 23:41:47:INFO:Accuracy = [1.0, 0.8813725490196078, 0.8450980392156863, 0.8742647058823529, 0.8142156862745098, 0.8904411764705882, 0.8970588235294118, 0.8009803921568628, 0.8860294117647058, 0.7622549019607843]
2022-01-20 23:41:47:INFO:Loss = [0.12760734644846297, 0.444244539657352, 0.4762265132922752, 0.3833969461676829, 0.5177172050975701, 0.3829863831839141, 0.4271840702231024, 0.6145046156666735, 0.36151974720369073, 0.4841951594742782]
2022-01-20 23:41:47:INFO:-------------Training local models-------------
2022-01-20 23:43:31:INFO:-------------Aggregating local models-------------
2022-01-20 23:43:32:INFO:-------------Round number: 3-------------
2022-01-20 23:43:32:INFO:-------------Sending models-------------
2022-01-20 23:43:32:INFO:-------------Evaluating models-------------
2022-01-20 23:43:32:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-20 23:43:32:INFO:Accuracy = [1.0, 0.8818627450980392, 0.8487745098039216, 0.883578431372549, 0.8166666666666667, 0.8963235294117647, 0.8828431372549019, 0.8198529411764706, 0.8980392156862745, 0.7784313725490196]
2022-01-20 23:43:32:INFO:Loss = [0.08655268307227422, 0.43151059576912837, 0.46879479365752025, 0.35188411238749384, 0.5191370366122939, 0.35811940582432583, 0.40277806205638483, 0.6388688852243564, 0.3394508889657171, 0.4626222494441797]
2022-01-20 23:43:32:INFO:-------------Training local models-------------
2022-01-20 23:45:16:INFO:-------------Aggregating local models-------------
2022-01-20 23:45:17:INFO:-------------Round number: 4-------------
2022-01-20 23:45:17:INFO:-------------Sending models-------------
2022-01-20 23:45:17:INFO:-------------Evaluating models-------------
2022-01-20 23:45:18:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-20 23:45:18:INFO:Accuracy = [1.0, 0.8821078431372549, 0.8482843137254902, 0.8990196078431373, 0.8183823529411764, 0.8950980392156863, 0.8828431372549019, 0.8247549019607843, 0.9024509803921569, 0.7811274509803922]
2022-01-20 23:45:18:INFO:Loss = [0.06314635210597486, 0.42572581788579766, 0.46230803422775923, 0.3297893204132789, 0.5109987751599036, 0.3498407204398045, 0.3836735431470123, 0.6577815669862663, 0.32698491772673294, 0.4472179784183847]
2022-01-20 23:45:18:INFO:-------------Training local models-------------
2022-01-20 23:47:02:INFO:-------------Aggregating local models-------------
2022-01-20 23:47:03:INFO:-------------Round number: 5-------------
2022-01-20 23:47:03:INFO:-------------Sending models-------------
2022-01-20 23:47:03:INFO:-------------Evaluating models-------------
2022-01-20 23:47:03:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-20 23:47:03:INFO:Accuracy = [1.0, 0.8823529411764706, 0.845343137254902, 0.9056372549019608, 0.8215686274509804, 0.8960784313725491, 0.8870098039215686, 0.8237745098039215, 0.9049019607843137, 0.7870098039215686]
2022-01-20 23:47:03:INFO:Loss = [0.04820486945191435, 0.4216283504056799, 0.4563956206445308, 0.31311639796431157, 0.501882150504446, 0.3488980373185055, 0.37012274233697384, 0.6717049979066074, 0.31965734969879334, 0.43206036481641086]
2022-01-20 23:47:03:INFO:-------------Training local models-------------
2022-01-20 23:48:47:INFO:-------------Aggregating local models-------------
2022-01-20 23:48:48:INFO:-------------Round number: 6-------------
2022-01-20 23:48:48:INFO:-------------Sending models-------------
2022-01-20 23:48:48:INFO:-------------Evaluating models-------------
2022-01-20 23:48:48:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-20 23:48:48:INFO:Accuracy = [1.0, 0.8823529411764706, 0.8384803921568628, 0.9056372549019608, 0.8223039215686274, 0.8968137254901961, 0.8884803921568627, 0.8235294117647058, 0.9071078431372549, 0.8014705882352942]
2022-01-20 23:48:48:INFO:Loss = [0.03804947188872771, 0.41822549309946744, 0.45164742338124153, 0.3004886297664295, 0.494100468646388, 0.3500609630079684, 0.3617572925126582, 0.682318694958025, 0.31554159751919775, 0.4185503922065026]
2022-01-20 23:48:48:INFO:-------------Training local models-------------
2022-01-20 23:50:32:INFO:-------------Aggregating local models-------------
2022-01-20 23:50:33:INFO:-------------Round number: 7-------------
2022-01-20 23:50:33:INFO:-------------Sending models-------------
2022-01-20 23:50:33:INFO:-------------Evaluating models-------------
2022-01-20 23:50:33:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-20 23:50:33:INFO:Accuracy = [1.0, 0.8823529411764706, 0.8345588235294118, 0.9056372549019608, 0.8230392156862745, 0.9, 0.8916666666666667, 0.8235294117647058, 0.9073529411764706, 0.8169117647058823]
2022-01-20 23:50:33:INFO:Loss = [0.03082538145941262, 0.4150222057645556, 0.44819382527916163, 0.29083549706539247, 0.4874358887843532, 0.3512380233573198, 0.35683581691381394, 0.6907568089800942, 0.31326513871888395, 0.4074960453527085]
2022-01-20 23:50:33:INFO:-------------Training local models-------------
2022-01-20 23:52:17:INFO:-------------Aggregating local models-------------
2022-01-20 23:52:18:INFO:-------------Round number: 8-------------
2022-01-20 23:52:18:INFO:-------------Sending models-------------
2022-01-20 23:52:19:INFO:-------------Evaluating models-------------
2022-01-20 23:52:19:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-20 23:52:19:INFO:Accuracy = [1.0, 0.8823529411764706, 0.8303921568627451, 0.9058823529411765, 0.8223039215686274, 0.9002450980392157, 0.8924019607843138, 0.8232843137254902, 0.904656862745098, 0.8223039215686274]
2022-01-20 23:52:19:INFO:Loss = [0.025507303212732806, 0.4118024250401147, 0.44605343230525213, 0.28332973886783436, 0.48145653475897715, 0.3520234897230551, 0.35390749263723253, 0.6977024224801355, 0.31197996088760155, 0.39884370983139994]
2022-01-20 23:52:19:INFO:-------------Training local models-------------
2022-01-20 23:54:03:INFO:-------------Aggregating local models-------------
2022-01-20 23:54:04:INFO:-------------Round number: 9-------------
2022-01-20 23:54:04:INFO:-------------Sending models-------------
2022-01-20 23:54:04:INFO:-------------Evaluating models-------------
2022-01-20 23:54:04:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-20 23:54:04:INFO:Accuracy = [1.0, 0.8823529411764706, 0.8308823529411765, 0.9058823529411765, 0.8208333333333333, 0.9007352941176471, 0.8926470588235295, 0.8232843137254902, 0.9034313725490196, 0.8279411764705882]
2022-01-20 23:54:04:INFO:Loss = [0.021492965893783404, 0.40846028738180357, 0.44517299589500126, 0.27734059950921175, 0.475882443578859, 0.35226101587599545, 0.3522055631859557, 0.7035025665536523, 0.3112789252065305, 0.3922815166240302]
2022-01-20 23:54:04:INFO:-------------Training local models-------------
2022-01-20 23:55:48:INFO:-------------Aggregating local models-------------
2022-01-20 23:55:49:INFO:-------------Round number: 10-------------
2022-01-20 23:55:49:INFO:-------------Sending models-------------
2022-01-20 23:55:49:INFO:-------------Evaluating models-------------
2022-01-20 23:55:49:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-20 23:55:49:INFO:Accuracy = [1.0, 0.8823529411764706, 0.8306372549019608, 0.9061274509803922, 0.8200980392156862, 0.9012254901960784, 0.8931372549019608, 0.8242647058823529, 0.9029411764705882, 0.8333333333333334]
2022-01-20 23:55:49:INFO:Loss = [0.018405219817342347, 0.4050111873623203, 0.44534727882173863, 0.272481860186649, 0.4705797482154095, 0.3519445108112824, 0.3513651422736253, 0.7084593309189978, 0.31096451639142986, 0.38741486082675264]
2022-01-20 23:55:49:INFO:-------------Training local models-------------
2022-01-20 23:57:33:INFO:-------------Aggregating local models-------------
2022-01-20 23:57:34:INFO:-------------Round number: 11-------------
2022-01-20 23:57:34:INFO:-------------Sending models-------------
2022-01-20 23:57:34:INFO:-------------Evaluating models-------------
2022-01-20 23:57:34:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-20 23:57:34:INFO:Accuracy = [1.0, 0.8823529411764706, 0.8291666666666667, 0.9068627450980392, 0.8196078431372549, 0.9012254901960784, 0.8933823529411765, 0.8230392156862745, 0.9002450980392157, 0.8387254901960784]
2022-01-20 23:57:34:INFO:Loss = [0.015985448021834315, 0.4015011555770887, 0.4462773011650379, 0.26840781111626283, 0.465548928375082, 0.3511957563003342, 0.35118214917305274, 0.7127364254762035, 0.3108912634471541, 0.3838726845478602]
2022-01-20 23:57:34:INFO:-------------Training local models-------------
2022-01-20 23:59:18:INFO:-------------Aggregating local models-------------
2022-01-20 23:59:19:INFO:-------------Round number: 12-------------
2022-01-20 23:59:19:INFO:-------------Sending models-------------
2022-01-20 23:59:19:INFO:-------------Evaluating models-------------
2022-01-20 23:59:19:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-20 23:59:19:INFO:Accuracy = [1.0, 0.8823529411764706, 0.828186274509804, 0.9066176470588235, 0.821078431372549, 0.9012254901960784, 0.8941176470588236, 0.8245098039215686, 0.9004901960784314, 0.8424019607843137]
2022-01-20 23:59:19:INFO:Loss = [0.014061209176183111, 0.3979869256852943, 0.4476700667200573, 0.264915008789531, 0.46077211715130356, 0.3500629656254223, 0.3514487804689755, 0.7164358506709629, 0.31097033941620666, 0.3813306778354351]
2022-01-20 23:59:19:INFO:-------------Training local models-------------
2022-01-21 00:01:03:INFO:-------------Aggregating local models-------------
2022-01-21 00:01:04:INFO:-------------Round number: 13-------------
2022-01-21 00:01:04:INFO:-------------Sending models-------------
2022-01-21 00:01:05:INFO:-------------Evaluating models-------------
2022-01-21 00:01:05:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 00:01:05:INFO:Accuracy = [1.0, 0.8823529411764706, 0.8284313725490197, 0.9066176470588235, 0.821813725490196, 0.9024509803921569, 0.8943627450980393, 0.825735294117647, 0.9, 0.8482843137254902]
2022-01-21 00:01:05:INFO:Loss = [0.01250963116306629, 0.39453244878335253, 0.44926848279668347, 0.2618678857003996, 0.45624452000643656, 0.348628400719962, 0.35200087652386475, 0.7196807178951726, 0.31117974191689496, 0.379515567650635]
2022-01-21 00:01:05:INFO:-------------Training local models-------------
2022-01-21 00:02:49:INFO:-------------Aggregating local models-------------
2022-01-21 00:02:50:INFO:-------------Round number: 14-------------
2022-01-21 00:02:50:INFO:-------------Sending models-------------
2022-01-21 00:02:50:INFO:-------------Evaluating models-------------
2022-01-21 00:02:50:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 00:02:50:INFO:Accuracy = [1.0, 0.8825980392156862, 0.828186274509804, 0.9071078431372549, 0.8240196078431372, 0.9026960784313726, 0.8946078431372549, 0.825735294117647, 0.9007352941176471, 0.8529411764705882]
2022-01-21 00:02:50:INFO:Loss = [0.011242384412873755, 0.39121213770361946, 0.45090304785316776, 0.25919617463802624, 0.4519663453707015, 0.34697620145857844, 0.3527446963011707, 0.722572029890109, 0.3114687184821449, 0.3782177452869969]
2022-01-21 00:02:50:INFO:-------------Training local models-------------
2022-01-21 00:04:34:INFO:-------------Aggregating local models-------------
2022-01-21 00:04:35:INFO:-------------Round number: 15-------------
2022-01-21 00:04:35:INFO:-------------Sending models-------------
2022-01-21 00:04:35:INFO:-------------Evaluating models-------------
2022-01-21 00:04:35:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 00:04:35:INFO:Accuracy = [1.0, 0.8833333333333333, 0.828186274509804, 0.908578431372549, 0.8252450980392156, 0.9029411764705882, 0.8946078431372549, 0.8252450980392156, 0.9, 0.8553921568627451]
2022-01-21 00:04:35:INFO:Loss = [0.010194298652612477, 0.38808136722689274, 0.45246127187091784, 0.2568285047389366, 0.4479402264411214, 0.34526642939240176, 0.3536001987568121, 0.7252130060155383, 0.3118165870181139, 0.37727762366571993]
2022-01-21 00:04:35:INFO:-------------Training local models-------------
2022-01-21 00:06:19:INFO:-------------Aggregating local models-------------
2022-01-21 00:06:20:INFO:-------------Round number: 16-------------
2022-01-21 00:06:20:INFO:-------------Sending models-------------
2022-01-21 00:06:20:INFO:-------------Evaluating models-------------
2022-01-21 00:06:20:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 00:06:20:INFO:Accuracy = [1.0, 0.884313725490196, 0.8284313725490197, 0.9100490196078431, 0.8269607843137254, 0.903921568627451, 0.8946078431372549, 0.8237745098039215, 0.8990196078431373, 0.8602941176470589]
2022-01-21 00:06:20:INFO:Loss = [0.00931757211504851, 0.3851645369991185, 0.4538915688263289, 0.25471732677554015, 0.44416669233788864, 0.3436020718106781, 0.35455129959154874, 0.7276330864988267, 0.312192272490767, 0.3766093091815527]
2022-01-21 00:06:20:INFO:-------------Training local models-------------
2022-01-21 00:08:04:INFO:-------------Aggregating local models-------------
2022-01-21 00:08:05:INFO:-------------Round number: 17-------------
2022-01-21 00:08:05:INFO:-------------Sending models-------------
2022-01-21 00:08:05:INFO:-------------Evaluating models-------------
2022-01-21 00:08:06:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 00:08:06:INFO:Accuracy = [1.0, 0.8860294117647058, 0.8296568627450981, 0.9110294117647059, 0.828186274509804, 0.9041666666666667, 0.8950980392156863, 0.8242647058823529, 0.8977941176470589, 0.8634803921568628]
2022-01-21 00:08:06:INFO:Loss = [0.008576897336466821, 0.3824725770745335, 0.4551737675210461, 0.2528599820250426, 0.44062743168415536, 0.34210895210979325, 0.3555509399351043, 0.729907932994869, 0.3125923325138751, 0.3761432639017299]
2022-01-21 00:08:06:INFO:-------------Training local models-------------
2022-01-21 00:09:50:INFO:-------------Aggregating local models-------------
2022-01-21 00:09:51:INFO:-------------Round number: 18-------------
2022-01-21 00:09:51:INFO:-------------Sending models-------------
2022-01-21 00:09:51:INFO:-------------Evaluating models-------------
2022-01-21 00:09:51:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 00:09:51:INFO:Accuracy = [1.0, 0.8870098039215686, 0.8286764705882353, 0.9122549019607843, 0.8323529411764706, 0.9049019607843137, 0.895343137254902, 0.825735294117647, 0.8977941176470589, 0.8659313725490196]
2022-01-21 00:09:51:INFO:Loss = [0.007945249955667475, 0.37999109312887397, 0.4562975009869072, 0.2512375451978205, 0.4373044346221814, 0.3408505212990384, 0.3566066316847105, 0.7321168639167559, 0.3129971785352145, 0.37582034083293275]
2022-01-21 00:09:51:INFO:-------------Training local models-------------
2022-01-21 00:11:35:INFO:-------------Aggregating local models-------------
2022-01-21 00:11:36:INFO:-------------Round number: 19-------------
2022-01-21 00:11:36:INFO:-------------Sending models-------------
2022-01-21 00:11:36:INFO:-------------Evaluating models-------------
2022-01-21 00:11:36:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 00:11:36:INFO:Accuracy = [1.0, 0.8877450980392156, 0.8274509803921568, 0.9149509803921568, 0.8343137254901961, 0.9058823529411765, 0.8955882352941177, 0.8267156862745098, 0.8985294117647059, 0.8696078431372549]
2022-01-21 00:11:36:INFO:Loss = [0.007400943051941474, 0.37771555161966447, 0.45726541115094305, 0.24983767833442008, 0.43417245554212736, 0.3399571157471441, 0.3576459132007086, 0.7343170419620697, 0.31340711273871563, 0.37559818845543574]
2022-01-21 00:11:36:INFO:-------------Training local models-------------
2022-01-21 00:13:20:INFO:-------------Aggregating local models-------------
2022-01-21 00:13:21:INFO:-------------Round number: 20-------------
2022-01-21 00:13:21:INFO:-------------Sending models-------------
2022-01-21 00:13:21:INFO:-------------Evaluating models-------------
2022-01-21 00:13:21:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 00:13:21:INFO:Accuracy = [1.0, 0.8887254901960784, 0.8279411764705882, 0.9154411764705882, 0.836764705882353, 0.9075980392156863, 0.8958333333333334, 0.8272058823529411, 0.8985294117647059, 0.871078431372549]
2022-01-21 00:13:21:INFO:Loss = [0.006928068577133886, 0.37558857029002596, 0.45811323722135094, 0.24864495635448097, 0.43122133041969407, 0.3394719710614642, 0.3586125266783889, 0.7364842821889576, 0.31381155074660794, 0.37545472885226355]
2022-01-21 00:13:21:INFO:-------------Training local models-------------
2022-01-21 00:15:05:INFO:-------------Aggregating local models-------------
2022-01-21 00:15:06:INFO:-------------Round number: 21-------------
2022-01-21 00:15:06:INFO:-------------Sending models-------------
2022-01-21 00:15:06:INFO:-------------Evaluating models-------------
2022-01-21 00:15:06:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 00:15:06:INFO:Accuracy = [1.0, 0.8899509803921568, 0.8276960784313725, 0.9156862745098039, 0.8384803921568628, 0.9093137254901961, 0.8955882352941177, 0.8279411764705882, 0.8997549019607843, 0.8718137254901961]
2022-01-21 00:15:06:INFO:Loss = [0.006513906645647926, 0.37360093655696996, 0.4588380992850837, 0.2476323950812038, 0.42842923518893417, 0.33940904559202345, 0.3595333436866948, 0.7387006790206001, 0.3142167996619737, 0.37538967764589426]
2022-01-21 00:15:06:INFO:-------------Training local models-------------
2022-01-21 00:16:50:INFO:-------------Aggregating local models-------------
2022-01-21 00:16:51:INFO:-------------Round number: 22-------------
2022-01-21 00:16:51:INFO:-------------Sending models-------------
2022-01-21 00:16:52:INFO:-------------Evaluating models-------------
2022-01-21 00:16:52:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 00:16:52:INFO:Accuracy = [1.0, 0.8904411764705882, 0.8284313725490197, 0.9151960784313725, 0.8394607843137255, 0.9095588235294118, 0.895343137254902, 0.828921568627451, 0.8997549019607843, 0.8727941176470588]
2022-01-21 00:16:52:INFO:Loss = [0.00614924290258547, 0.3717226170114123, 0.45945661910695446, 0.24678751140120714, 0.4257658620863724, 0.3397276801143901, 0.36038825436445027, 0.740831532633142, 0.3145919164965687, 0.3753686246379991]
2022-01-21 00:16:52:INFO:-------------Training local models-------------
2022-01-21 00:18:36:INFO:-------------Aggregating local models-------------
2022-01-21 00:18:37:INFO:-------------Round number: 23-------------
2022-01-21 00:18:37:INFO:-------------Sending models-------------
2022-01-21 00:18:37:INFO:-------------Evaluating models-------------
2022-01-21 00:18:37:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 00:18:37:INFO:Accuracy = [1.0, 0.8916666666666667, 0.8284313725490197, 0.9151960784313725, 0.841421568627451, 0.9090686274509804, 0.8950980392156863, 0.8299019607843138, 0.9, 0.8737745098039216]
2022-01-21 00:18:37:INFO:Loss = [0.005825907664200035, 0.3699652283519789, 0.45999301757832406, 0.24609114635078347, 0.42320689484340085, 0.3404239479762812, 0.3611900025828029, 0.742984506099567, 0.3149629657706885, 0.3753792632978373]
2022-01-21 00:18:37:INFO:-------------Training local models-------------
2022-01-21 00:20:21:INFO:-------------Aggregating local models-------------
2022-01-21 00:20:22:INFO:-------------Round number: 24-------------
2022-01-21 00:20:22:INFO:-------------Sending models-------------
2022-01-21 00:20:22:INFO:-------------Evaluating models-------------
2022-01-21 00:20:22:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 00:20:22:INFO:Accuracy = [1.0, 0.8924019607843138, 0.828186274509804, 0.9154411764705882, 0.8433823529411765, 0.9088235294117647, 0.8948529411764706, 0.8303921568627451, 0.9004901960784314, 0.8740196078431373]
2022-01-21 00:20:22:INFO:Loss = [0.005537753275312556, 0.3682895824918067, 0.460458196744131, 0.24551980329937684, 0.42075060204632453, 0.3414301778459191, 0.361918998688149, 0.7450430263861028, 0.31531450809173595, 0.37540228513649243]
2022-01-21 00:20:22:INFO:-------------Training local models-------------
2022-01-21 00:22:06:INFO:-------------Aggregating local models-------------
2022-01-21 00:22:07:INFO:-------------Round number: 25-------------
2022-01-21 00:22:07:INFO:-------------Sending models-------------
2022-01-21 00:22:07:INFO:-------------Evaluating models-------------
2022-01-21 00:22:07:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 00:22:07:INFO:Accuracy = [1.0, 0.8928921568627451, 0.828186274509804, 0.9139705882352941, 0.8441176470588235, 0.9090686274509804, 0.8950980392156863, 0.8306372549019608, 0.9004901960784314, 0.8745098039215686]
2022-01-21 00:22:07:INFO:Loss = [0.005279699848067728, 0.3667014290244255, 0.46085844558604316, 0.2450390036569397, 0.41837331705085257, 0.3427014382231944, 0.36256009293263597, 0.7470036636120366, 0.31565532568093463, 0.37544186871188384]
2022-01-21 00:22:07:INFO:-------------Training local models-------------
2022-01-21 00:23:51:INFO:-------------Aggregating local models-------------
2022-01-21 00:23:52:INFO:-------------Round number: 26-------------
2022-01-21 00:23:52:INFO:-------------Sending models-------------
2022-01-21 00:23:52:INFO:-------------Evaluating models-------------
2022-01-21 00:23:53:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 00:23:53:INFO:Accuracy = [1.0, 0.8938725490196079, 0.8286764705882353, 0.9134803921568627, 0.8468137254901961, 0.908578431372549, 0.8950980392156863, 0.8306372549019608, 0.9007352941176471, 0.8747549019607843]
2022-01-21 00:23:53:INFO:Loss = [0.0050473242973013985, 0.3652317899760936, 0.461221668526859, 0.24465018400908722, 0.41606716352672424, 0.3441848785356235, 0.36314993631094694, 0.748892499565366, 0.3159911872173646, 0.37549686293784235]
2022-01-21 00:23:53:INFO:-------------Training local models-------------
2022-01-21 00:25:37:INFO:-------------Aggregating local models-------------
2022-01-21 00:25:38:INFO:-------------Round number: 27-------------
2022-01-21 00:25:38:INFO:-------------Sending models-------------
2022-01-21 00:25:38:INFO:-------------Evaluating models-------------
2022-01-21 00:25:38:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 00:25:38:INFO:Accuracy = [1.0, 0.8948529411764706, 0.8284313725490197, 0.913235294117647, 0.8475490196078431, 0.9090686274509804, 0.8958333333333334, 0.8313725490196079, 0.8997549019607843, 0.875]
2022-01-21 00:25:38:INFO:Loss = [0.004837064614619913, 0.3637953379280482, 0.4615292717011043, 0.2443448451784777, 0.4138323196213391, 0.34579202392613334, 0.36364566547083943, 0.7506759211514602, 0.3163211020842473, 0.37554212450620483]
2022-01-21 00:25:38:INFO:-------------Training local models-------------
2022-01-21 00:27:22:INFO:-------------Aggregating local models-------------
2022-01-21 00:27:23:INFO:-------------Round number: 28-------------
2022-01-21 00:27:23:INFO:-------------Sending models-------------
2022-01-21 00:27:23:INFO:-------------Evaluating models-------------
2022-01-21 00:27:23:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 00:27:23:INFO:Accuracy = [1.0, 0.8955882352941177, 0.8291666666666667, 0.913235294117647, 0.8477941176470588, 0.9105392156862745, 0.8958333333333334, 0.8313725490196079, 0.9002450980392157, 0.8747549019607843]
2022-01-21 00:27:23:INFO:Loss = [0.004645937813192551, 0.36242630765670636, 0.46176510558956685, 0.24408351509505427, 0.4116544139157186, 0.3474532538413198, 0.36404426150850255, 0.7523755855132442, 0.31663566741518284, 0.3755876092918162]
2022-01-21 00:27:23:INFO:-------------Training local models-------------
2022-01-21 00:29:07:INFO:-------------Aggregating local models-------------
2022-01-21 00:29:08:INFO:-------------Round number: 29-------------
2022-01-21 00:29:08:INFO:-------------Sending models-------------
2022-01-21 00:29:08:INFO:-------------Evaluating models-------------
2022-01-21 00:29:08:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 00:29:08:INFO:Accuracy = [1.0, 0.8960784313725491, 0.8279411764705882, 0.9129901960784313, 0.8485294117647059, 0.9112745098039216, 0.8958333333333334, 0.8321078431372549, 0.9002450980392157, 0.8745098039215686]
2022-01-21 00:29:08:INFO:Loss = [0.004471914040372141, 0.36112603905562807, 0.46194604784421456, 0.24386207811253638, 0.40953176256666396, 0.34918674079966094, 0.3644107234083326, 0.7539308927565193, 0.3169285071255895, 0.3756507265851742]
2022-01-21 00:29:08:INFO:-------------Training local models-------------
2022-01-21 00:30:52:INFO:-------------Aggregating local models-------------
2022-01-21 00:30:53:INFO:-------------Round number: 30-------------
2022-01-21 00:30:53:INFO:-------------Sending models-------------
2022-01-21 00:30:53:INFO:-------------Evaluating models-------------
2022-01-21 00:30:54:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 00:30:54:INFO:Accuracy = [1.0, 0.8968137254901961, 0.8279411764705882, 0.913235294117647, 0.8490196078431372, 0.9117647058823529, 0.8963235294117647, 0.8325980392156863, 0.9004901960784314, 0.875]
2022-01-21 00:30:54:INFO:Loss = [0.004312545291659441, 0.35987810279053234, 0.4620894253038226, 0.2436817516407281, 0.40746283085386764, 0.3509021209685278, 0.36467447632400996, 0.7553500662484736, 0.3172065115042428, 0.375721210803307]
2022-01-21 00:30:54:INFO:-------------Training local models-------------
2022-01-21 00:32:38:INFO:-------------Aggregating local models-------------
2022-01-21 00:32:39:INFO:-------------Round number: 31-------------
2022-01-21 00:32:39:INFO:-------------Sending models-------------
2022-01-21 00:32:39:INFO:-------------Evaluating models-------------
2022-01-21 00:32:39:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 00:32:39:INFO:Accuracy = [1.0, 0.8968137254901961, 0.8276960784313725, 0.9129901960784313, 0.8490196078431372, 0.9122549019607843, 0.8963235294117647, 0.8325980392156863, 0.9012254901960784, 0.8757352941176471]
2022-01-21 00:32:39:INFO:Loss = [0.004165978067926606, 0.3586918600206035, 0.4621912066638698, 0.24349226258231746, 0.4054390957445482, 0.3525867011471122, 0.36488884005709277, 0.7566385855259118, 0.3174717720745214, 0.3757789259406683]
2022-01-21 00:32:39:INFO:-------------Training local models-------------
2022-01-21 00:34:23:INFO:-------------Aggregating local models-------------
2022-01-21 00:34:24:INFO:-------------Round number: 32-------------
2022-01-21 00:34:24:INFO:-------------Sending models-------------
2022-01-21 00:34:24:INFO:-------------Evaluating models-------------
2022-01-21 00:34:24:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 00:34:24:INFO:Accuracy = [1.0, 0.8970588235294118, 0.8279411764705882, 0.9129901960784313, 0.85, 0.9117647058823529, 0.8960784313725491, 0.8335784313725491, 0.9014705882352941, 0.8757352941176471]
2022-01-21 00:34:24:INFO:Loss = [0.004030937870779513, 0.3575505808862634, 0.46227076126424615, 0.24334445710102207, 0.4034676305240924, 0.3542883496174552, 0.3650411006682963, 0.7578471258052113, 0.317737394374026, 0.37583656286405326]
2022-01-21 00:34:24:INFO:-------------Training local models-------------
2022-01-21 00:36:08:INFO:-------------Aggregating local models-------------
2022-01-21 00:36:09:INFO:-------------Round number: 33-------------
2022-01-21 00:36:09:INFO:-------------Sending models-------------
2022-01-21 00:36:09:INFO:-------------Evaluating models-------------
2022-01-21 00:36:09:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 00:36:09:INFO:Accuracy = [1.0, 0.8973039215686275, 0.8279411764705882, 0.9127450980392157, 0.8509803921568627, 0.9117647058823529, 0.8960784313725491, 0.8343137254901961, 0.9012254901960784, 0.8762254901960784]
2022-01-21 00:36:09:INFO:Loss = [0.00390638435555065, 0.35645904251934696, 0.46233599114017193, 0.24320107177025455, 0.4015466523574729, 0.3559449481499363, 0.365129295377604, 0.7589194211223181, 0.31797836585097045, 0.37589679617439303]
2022-01-21 00:36:09:INFO:-------------Training local models-------------
2022-01-21 00:37:53:INFO:-------------Aggregating local models-------------
2022-01-21 00:37:54:INFO:-------------Round number: 34-------------
2022-01-21 00:37:54:INFO:-------------Sending models-------------
2022-01-21 00:37:55:INFO:-------------Evaluating models-------------
2022-01-21 00:37:55:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 00:37:55:INFO:Accuracy = [1.0, 0.8980392156862745, 0.8276960784313725, 0.9125, 0.8524509803921568, 0.9115196078431372, 0.8960784313725491, 0.8343137254901961, 0.9024509803921569, 0.8764705882352941]
2022-01-21 00:37:55:INFO:Loss = [0.003791242167091125, 0.3554133035224867, 0.46239059082319156, 0.2430594171118904, 0.39966949428843707, 0.35747464952018004, 0.36514375309514646, 0.7598538413237524, 0.3182054698717205, 0.37594578119780064]
2022-01-21 00:37:55:INFO:-------------Training local models-------------
2022-01-21 00:39:39:INFO:-------------Aggregating local models-------------
2022-01-21 00:39:40:INFO:-------------Round number: 35-------------
2022-01-21 00:39:40:INFO:-------------Sending models-------------
2022-01-21 00:39:40:INFO:-------------Evaluating models-------------
2022-01-21 00:39:40:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 00:39:40:INFO:Accuracy = [1.0, 0.8987745098039216, 0.8284313725490197, 0.9125, 0.8534313725490196, 0.9122549019607843, 0.8960784313725491, 0.8343137254901961, 0.9029411764705882, 0.8769607843137255]
2022-01-21 00:39:40:INFO:Loss = [0.003684062744986138, 0.35438521880532076, 0.4624318424869082, 0.24292623947201042, 0.3978386854361423, 0.3589689989366532, 0.3651377265216034, 0.760701431476228, 0.31842112267993655, 0.3759978737478948]
2022-01-21 00:39:40:INFO:-------------Training local models-------------
2022-01-21 00:41:24:INFO:-------------Aggregating local models-------------
2022-01-21 00:41:25:INFO:-------------Round number: 36-------------
2022-01-21 00:41:25:INFO:-------------Sending models-------------
2022-01-21 00:41:25:INFO:-------------Evaluating models-------------
2022-01-21 00:41:25:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 00:41:25:INFO:Accuracy = [1.0, 0.8990196078431373, 0.8294117647058824, 0.9122549019607843, 0.8541666666666666, 0.9125, 0.8958333333333334, 0.8343137254901961, 0.9026960784313726, 0.8772058823529412]
2022-01-21 00:41:25:INFO:Loss = [0.003584403247919445, 0.35338953497828735, 0.46246444071213916, 0.24279116879972884, 0.39604152953531824, 0.3604426418246208, 0.3650975174552478, 0.7614358401310621, 0.3186121680648249, 0.37604623455577074]
2022-01-21 00:41:25:INFO:-------------Training local models-------------
2022-01-21 00:43:09:INFO:-------------Aggregating local models-------------
2022-01-21 00:43:10:INFO:-------------Round number: 37-------------
2022-01-21 00:43:10:INFO:-------------Sending models-------------
2022-01-21 00:43:10:INFO:-------------Evaluating models-------------
2022-01-21 00:43:10:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 00:43:10:INFO:Accuracy = [1.0, 0.899264705882353, 0.8296568627450981, 0.9125, 0.8556372549019607, 0.9120098039215686, 0.8958333333333334, 0.8343137254901961, 0.9029411764705882, 0.8779411764705882]
2022-01-21 00:43:10:INFO:Loss = [0.0034913617270706477, 0.3524383447300209, 0.4625171017102605, 0.24266483259385033, 0.39428095833407534, 0.36187487957410186, 0.3650246582144652, 0.7621053326110282, 0.31878156155032816, 0.37609335269400046]
2022-01-21 00:43:10:INFO:-------------Training local models-------------
2022-01-21 00:44:54:INFO:-------------Aggregating local models-------------
2022-01-21 00:44:55:INFO:-------------Round number: 38-------------
2022-01-21 00:44:55:INFO:-------------Sending models-------------
2022-01-21 00:44:55:INFO:-------------Evaluating models-------------
2022-01-21 00:44:55:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 00:44:55:INFO:Accuracy = [1.0, 0.8997549019607843, 0.8303921568627451, 0.9125, 0.8558823529411764, 0.9110294117647059, 0.8963235294117647, 0.8343137254901961, 0.9031862745098039, 0.878921568627451]
2022-01-21 00:44:55:INFO:Loss = [0.003404607701311618, 0.3515065024682782, 0.46256469420269225, 0.24256691762175428, 0.39256429089565403, 0.3632625088577305, 0.36493879674954394, 0.7626674603762141, 0.31890818735101834, 0.3761359378170478]
2022-01-21 00:44:55:INFO:-------------Training local models-------------
2022-01-21 00:46:39:INFO:-------------Aggregating local models-------------
2022-01-21 00:46:40:INFO:-------------Round number: 39-------------
2022-01-21 00:46:40:INFO:-------------Sending models-------------
2022-01-21 00:46:40:INFO:-------------Evaluating models-------------
2022-01-21 00:46:40:INFO:Average Global Accuracy and Loss for Each Task:
2022-01-21 00:46:40:INFO:Accuracy = [1.0, 0.8997549019607843, 0.8311274509803922, 0.9125, 0.8561274509803921, 0.9120098039215686, 0.8963235294117647, 0.8348039215686275, 0.9036764705882353, 0.878921568627451]
2022-01-21 00:46:40:INFO:Loss = [0.003323203077432517, 0.35061580351697663, 0.4626045462888821, 0.2424640276608532, 0.39089248768754725, 0.3645663653744622, 0.36481349721754097, 0.7631621589038439, 0.3190317099614927, 0.37617325194650236]
2022-01-21 00:46:40:INFO:-------------Training local models-------------
2022-01-21 00:48:24:INFO:-------------Aggregating local models-------------
